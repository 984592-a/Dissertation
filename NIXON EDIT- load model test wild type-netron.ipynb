{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To note: Running this on different systems (i.e. local, SCW, server) will result in slight changes needing to the code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/scipy/__init__.py:138: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.4)\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion} is required for this version of \"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.pyplot._IonContext at 0x7f3e6c884f70>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load libraries\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import sys\n",
    "import torchvision\n",
    "import torchvision.transforms as T\n",
    "import torchvision.models as models\n",
    "from PIL import Image\n",
    "from PIL import ImageEnhance\n",
    "import matplotlib.pyplot as plt\n",
    "import imagesize\n",
    "import subprocess\n",
    "sys.path\n",
    "from IPython.core.debugger import set_trace\n",
    "import scipy.ndimage\n",
    "import matplotlib.patches as patches\n",
    "# plt.rcParams['figure.figsize'] = [12,12]\n",
    "# sys.path.append('/workspace/myFile/Mask_RCNN_Tutorial/')\n",
    "from tqdm import tqdm\n",
    "from torch import nn as nn\n",
    "from torch import optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "import re\n",
    "import time\n",
    "import copy\n",
    "import pylab\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from tempfile import TemporaryDirectory\n",
    "import torch.backends.cudnn as cudnn\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "import seaborn as sn\n",
    "import pandas as pd\n",
    "import glob\n",
    "# Rather than have a messy notebook with a load of functions we can store them in separate .py files and import them\n",
    "\n",
    "cudnn.benchmark = True\n",
    "plt.ion()   # interactive mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "writer = SummaryWriter(\"Experiments/TENSORBOARD\")    # This determines the tensorboard file name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DNADataset(object):\n",
    "    def __init__(self, root, transforms, labels, imDx = False):\n",
    "        self.root, self.transforms, self.labels = root, transforms, labels\n",
    "        self.imgDir=[]\n",
    "        # load all image files, sorting them to ensure they are aligned\n",
    "        for drug in [\"A\",\"B\",\"C\",\"D\",\"E\",\"F\"]:\n",
    "            self.imgDir = self.imgDir+glob.glob(root+drug+\"04*/*.tiff\")\n",
    "            self.imgDir = self.imgDir +glob.glob(root+drug+\"05*/*.tiff\")\n",
    "            self.imgDir =self.imgDir+ glob.glob(root+drug+\"06*/*.tiff\")\n",
    "        Damagednuclei= [x for x in self.imgDir if 'Damaged_nuclei_' in x]\n",
    "        Undamagednuclei= [x for x in self.imgDir if \"No_damage_nuclei\" in x]\n",
    "        #np.random.shuffle(Undamagednuclei)\n",
    "        #Undamagednuclei=Undamagednuclei[:10000]\n",
    "        self.imgDir= Damagednuclei+Undamagednuclei\n",
    "        size80=[]\n",
    "        for x in self.imgDir:\n",
    "            img = Image.open(x) # Open image\n",
    "            w,h=img.size\n",
    "            if w<=80 and h<=80:\n",
    "                size80.append(x)\n",
    "        self.imgDir=size80              \n",
    "        \n",
    "        self.imgs = sorted(self.imgDir) # list of images\n",
    "\n",
    "        \n",
    "\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.imgs[idx]\n",
    "       \n",
    "        # Transform images into tensors\n",
    "        img = Image.open(img_path) # Open image\n",
    "        w,h=img.size\n",
    "        img = np.array(img) # Convert image into an array\n",
    "        img = np.float32(np.divide(img, 2**16)) # Ensure all values are floats\n",
    "        \n",
    "        result=np.zeros((80,80), dtype=np.float32)\n",
    "        x_center = (80 - w) // 2\n",
    "        y_center = (80 - h) // 2 # copy img image into center of result image\n",
    "        result[y_center:y_center+h, x_center:x_center+w] = img\n",
    "        img = result\n",
    "        \n",
    "        targetlab=\"\"\n",
    "        if img_path.find('No_damage_nuclei') != -1:\n",
    "            targetlab= 'Undamaged'\n",
    "        if img_path.find('Damaged_nuclei_') != -1:\n",
    "            targetlab= 'Damaged'  # Find labels corresponding to image\n",
    "        target = self.labels.index(targetlab) # Get the label and assign to a value\n",
    "        \n",
    "        # Convert label to tensor\n",
    "        #torch.to\n",
    "        \n",
    "        if self.transforms is not None:\n",
    "            img = self.transforms(img)\n",
    "#             #print('In the transforms')\n",
    "        imNo = idx\n",
    "        return img, target, imNo\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.imgs)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "imDr = \"/workspace/myFile/Output/17052023/\"  # Image patches directory\n",
    "\n",
    "labels = ['Damaged', 'Undamaged']  # Your labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For data augmentation\n",
    "def get_transform(train):\n",
    "    transforms = []\n",
    "\n",
    "    transforms.append(T.ToTensor())\n",
    "    #transforms.append(T.Normalize([0.0019368887995516483], [0.00672996630111016]))\n",
    "    #transforms.append(T.RandomHorizontalFlip(0.5))\n",
    "    \n",
    "    if train:\n",
    "        transforms.append(T.RandomHorizontalFlip(p=1))\n",
    "        transforms.append(T.RandomVerticalFlip(p=1))\n",
    "    \n",
    "    return T.Compose(transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, scheduler, train, test, num_epochs=25):\n",
    "    since = time.time()\n",
    "    # Create a temporary directory to save training checkpoints\n",
    "    with TemporaryDirectory() as tempdir:\n",
    "        best_model_params_path = os.path.join(tempdir, 'best_model_params.pt')\n",
    "\n",
    "        torch.save(model.state_dict(), best_model_params_path)\n",
    "        best_acc = 0.0\n",
    "        \n",
    "        for epoch in range(num_epochs):\n",
    "            print(f'Epoch {epoch}/{num_epochs - 1}')\n",
    "            print('-' * 10)\n",
    "            dataset_train = torch.utils.data.Subset(dataSetTrain, train[epoch])\n",
    "            dataset_test = torch.utils.data.Subset(dataSetTest, test[epoch])\n",
    "            data_loader_train = torch.utils.data.DataLoader(\n",
    "                dataset_train, batch_size=128, shuffle=True, num_workers=0)\n",
    "\n",
    "            data_loader_test = torch.utils.data.DataLoader(\n",
    "                dataset_test, batch_size=128, shuffle=False, num_workers=0)\n",
    "            # Each epoch has a training and validation phase\n",
    "            for phase in ['val']:\n",
    "                if phase == 'train':\n",
    "                    model.train()  # Set model to training mode\n",
    "                    dataloaders = data_loader_train\n",
    "                else:\n",
    "                    model.eval()   # Set model to evaluate mode\n",
    "                    dataloaders = data_loader_test\n",
    "\n",
    "                running_loss = 0.0\n",
    "                running_corrects = 0\n",
    "                damaged_len=0\n",
    "                damaged_corrects = 0\n",
    "                undamaged_len=0\n",
    "                undamaged_corrects = 0\n",
    "\n",
    "                # Iterate over data.\n",
    "                for inputs, labels, imNo in dataloaders:\n",
    "                    inputs = inputs.to(device)\n",
    "                    labels = labels.to(device)\n",
    "\n",
    "                    # zero the parameter gradients\n",
    "                    optimizer.zero_grad()\n",
    "\n",
    "                    # forward\n",
    "                    # track history if only in train\n",
    "                    with torch.set_grad_enabled(phase == 'train'):\n",
    "                        outputs = model(inputs)\n",
    "                        _, preds = torch.max(outputs, 1)\n",
    "                        loss = criterion(outputs, labels)\n",
    "                        # backward + optimize only if in training phase\n",
    "                        if phase == 'train':\n",
    "                            loss.backward()\n",
    "                            optimizer.step()\n",
    "\n",
    "                    # statistics\n",
    "                    running_loss += loss.item() * inputs.size(0)    # Loss\n",
    "                    nada=torch.tensor(np.zeros(len(labels))).to(device)\n",
    "                    uno=nada+1\n",
    "                    falseneg=preds+1\n",
    "                    falsepos=preds-1\n",
    "                    FPplusTN=torch.sum(labels==nada)\n",
    "                    TPplusFN=torch.sum(labels==uno)\n",
    "                    FN=torch.sum(labels==falseneg)\n",
    "                    FP=torch.sum(labels==falsepos)\n",
    "                    TN=FPplusTN-FP\n",
    "                    TP=TPplusFN-FN\n",
    "                    running_corrects += torch.sum(preds == labels.data) # Accuracy\n",
    "                    damaged_len+=TPplusFN\n",
    "                    damaged_corrects += TP\n",
    "                    undamaged_len+=FPplusTN\n",
    "                    undamaged_corrects += TN\n",
    "                damaged_acc = damaged_corrects / damaged_len\n",
    "                undamaged_acc = undamaged_corrects/undamaged_len\n",
    "                epoch_acc= (damaged_acc+undamaged_acc)/2\n",
    "                proper_acc=(damaged_corrects+undamaged_corrects)/(damaged_len+undamaged_len)\n",
    "                if phase == 'train':\n",
    "                    scheduler.step()\n",
    "\n",
    "                epoch_loss = running_loss / dataset_sizes[phase]    # Loss metric per epoch\n",
    "                #epoch_acc = running_corrects.double() / dataset_sizes[phase]    # Accuracy metric per epoch\n",
    "\n",
    "                if phase == \"train\":    # This is the tensorboard code that writes accuracy and loss metrics\n",
    "                    writer.add_scalar(\"Train/Accuracy\", epoch_acc, epoch)\n",
    "                    writer.add_scalar(\"Train/Loss\", epoch_loss, epoch)\n",
    "                else:\n",
    "                    writer.add_scalar(\"Validation/Accuracy\", epoch_acc, epoch)\n",
    "                    writer.add_scalar(\"Validation/Loss\", epoch_loss, epoch)\n",
    "\n",
    "                print(f'{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n",
    "                print(\"proper accuracy=\")\n",
    "                print(proper_acc)\n",
    "                print(\"damaged accuracy=\")\n",
    "                print(damaged_acc)\n",
    "                print(\"undamaged accuracy=\")\n",
    "                print(undamaged_acc)\n",
    "                con_matter= torch.tensor([[damaged_corrects, damaged_len-damaged_corrects],[undamaged_len-undamaged_corrects,undamaged_corrects]])\n",
    "                con_matter=con_matter.cpu().numpy()\n",
    "                print(con_matter)\n",
    "                # deep copy the model\n",
    "                if phase == 'val' and epoch_acc >= best_acc: \n",
    "                    # This compares validation accuracy to previous bests and adjusts model weights accordingly\n",
    "                    best_acc = epoch_acc\n",
    "                    torch.save(model.state_dict(), best_model_params_path)\n",
    "                    con_mat= torch.tensor([[damaged_corrects, damaged_len-damaged_corrects],[undamaged_len-undamaged_corrects,undamaged_corrects]])\n",
    "\n",
    "            print()\n",
    "\n",
    "        time_elapsed = time.time() - since  # Nice way to measure training time but info also stored (indirectly) by tensorboard\n",
    "        print(\n",
    "            f'Training complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')\n",
    "        print(f'Best val Acc: {best_acc:4f}')\n",
    "        #labels= labels.cpu().numpy()\n",
    "        #preds=preds.cpu().numpy()\n",
    "        model.load_state_dict(torch.load(best_model_params_path))\n",
    "    writer.close()\n",
    "    return model, con_mat   # We want to return the model because its the model, also confusion matrix for later analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is your RESNET\n",
    "# Initialize CNN with kaiming\n",
    "def init_cnn(m):\n",
    "    # Set the weights of the RESNET\n",
    "    if getattr(m, 'bias', None) is not None: nn.init.constant_(m.bias, 0)\n",
    "    if isinstance(m, (nn.Conv2d,nn.Linear)): nn.init.kaiming_normal_(m.weight)\n",
    "    for l in m.children(): init_cnn(l)\n",
    "\n",
    "\n",
    "# noop function for returning nothing\n",
    "def noop(x): return x\n",
    "# activation function(RELU)\n",
    "act_fn = nn.ReLU(inplace=True)\n",
    "\n",
    "# Flatten\n",
    "class Flatten(nn.Module):\n",
    "    def forward(self, x): return x.view(x.size(0), -1)\n",
    "\n",
    "# Make a convolution\n",
    "def conv(ni, nf, ks=3, stride=1, bias=False):\n",
    "    return nn.Conv2d(ni, nf, kernel_size=ks, stride=stride, padding=ks//2, bias=bias)\n",
    "\n",
    "# Create a convuolutional layer with convolution and batch norm\n",
    "def conv_layer(ni, nf, ks=3, stride=1, zero_bn=False, act=True):\n",
    "    bn = nn.BatchNorm2d(nf) # get a 2d batch norm from Pytorhc\n",
    "    nn.init.constant_(bn.weight, 0. if zero_bn else 1.)\n",
    "    layers = [conv(ni, nf, ks, stride=stride), bn]\n",
    "    if act: layers.append(act_fn) # add in the activation function if act is true\n",
    "    return nn.Sequential(*layers)\n",
    "\n",
    "\n",
    "# Resblock\n",
    "class ResBlock(nn.Module):\n",
    "    def __init__(self, expansion, ni, nh, stride = 1):\n",
    "        super().__init__()\n",
    "        # ni - number of inputs channels, nf - number of filters\n",
    "        # nh - number of filters in first conv\n",
    "        # expansion is 1 for resnet 18, 34 and 4 for larger networks\n",
    "        nf, ni = nh*expansion, ni*expansion\n",
    "        layers = [conv_layer(ni, nh, 3, stride = stride), # for resnet < 34 2 convs per resblock\n",
    "                 conv_layer(nh, nf, 3, zero_bn = True, act = False)\n",
    "                 ] if expansion == 1 else [ # for RESNET > 34 then 3 convs per block with bottleneck\n",
    "                            conv_layer(ni, nh, 1),\n",
    "                            conv_layer(nh, nh, 3, stride = stride),\n",
    "                            conv_layer(nh, nf, 1, zero_bn = True, act = False)\n",
    "        ]\n",
    "        self.convs = nn.Sequential(*layers) # Creates the conv layers\n",
    "        self.idconv = noop if ni==nf else conv_layer(ni, nf, 1, act = False) # id convolution ()\n",
    "        self.pool = noop if stride== 1 else nn.AvgPool2d(2, ceil_mode = True) # average pool on \n",
    "        \n",
    "    def forward(self, x): \n",
    "        # Forward function adds the convolution part to the id part \n",
    "        #return act_fn(self.convs(x)) + self.idconv(self.pool(x))\n",
    "        return act_fn(self.convs(x) + self.idconv(self.pool(x)))\n",
    "\n",
    "# XResnet\n",
    "class XResNet(nn.Sequential):\n",
    "    @classmethod\n",
    "    def create(cls, expansion, layers, c_in=3, c_out=1000):\n",
    "        nfs = [c_in, (c_in + 1)*8, 64, 64] # number of filters in stem layer (c_in is number of image channels)\n",
    "        stem = [conv_layer(nfs[i], nfs[i+1], stride=2 if i==0 else 1)\n",
    "            for i in range(3)]\n",
    "\n",
    "        nfs = [64//expansion,64,128,256,512]\n",
    "        res_layers = [cls._make_layer(expansion, nfs[i], nfs[i+1],\n",
    "                                      n_blocks=l, stride=1 if i==0 else 2)\n",
    "                  for i,l in enumerate(layers)]\n",
    "        res = cls(\n",
    "        *stem,\n",
    "        nn.MaxPool2d(kernel_size=3, stride = 2, padding = 1), # then a max pooling layer\n",
    "        *res_layers,\n",
    "        nn.AdaptiveAvgPool2d(1), Flatten(), \n",
    "        nn.Linear(nfs[-1]*expansion, c_out)\n",
    "        )\n",
    "        init_cnn(res)\n",
    "        return res\n",
    "        \n",
    "    @staticmethod\n",
    "    def _make_layer(expansion, ni, nf, n_blocks, stride): # returns a resblock\n",
    "        return nn.Sequential(\n",
    "        *[ResBlock(expansion, ni if i==0 else nf, nf, stride if i==0 else 1)\n",
    "         for i in range(n_blocks)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def xresnet18 (**kwargs): return XResNet.create(1, [2, 2,  2, 2], **kwargs)\n",
    "def xresnet34 (**kwargs): return XResNet.create(1, [3, 4,  6, 3], **kwargs)\n",
    "def xresnet50 (**kwargs): return XResNet.create(4, [3, 4,  6, 3], **kwargs)\n",
    "model = xresnet18(c_in = 1, c_out = 2)\n",
    "#model34 = xresnet34(c_in = 1, c_out = 2)\n",
    "#model50 = xresnet50(c_in = 1, c_out = 2)\n",
    "model.load_state_dict(torch.load(\"/workspace/myFile/Output/17052023/best_model_params.pt\"))\n",
    "model = model.to(device)\n",
    "\n",
    "# Label smoothing cross entropy\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "def reduce_loss(loss, reduction='mean'):\n",
    "    return loss.mean() if reduction=='mean' else loss.sum() if reduction=='sum' else loss\n",
    "\n",
    "class LabelSmoothingCrossEntropy(nn.Module):\n",
    "    def __init__(self, ε:float=0.1, reduction='mean'):\n",
    "        super().__init__()\n",
    "        self.ε,self.reduction = ε,reduction\n",
    "    \n",
    "    def forward(self, output, target):\n",
    "        c = output.size()[-1]\n",
    "        log_preds = F.log_softmax(output, dim=-1)\n",
    "        loss = reduce_loss(-log_preds.sum(dim=-1), self.reduction)\n",
    "        nll = F.nll_loss(log_preds, target, reduction=self.reduction)\n",
    "        return lin_comb(loss/c, nll, self.ε)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions that shows the image, true class, predicted class and degree of prediction\n",
    "\n",
    "def images_to_probs(net, images):\n",
    "    '''\n",
    "    Generates predictions and corresponding probabilities from a trained\n",
    "    network and a list of images\n",
    "    '''\n",
    "    output = net(images)\n",
    "    # convert output probabilities to predicted class\n",
    "    _, preds_tensor = torch.max(output, 1)\n",
    "    preds = np.squeeze(preds_tensor.numpy())\n",
    "    return preds, [F.softmax(el, dim=0)[i].item() for i, el in zip(preds, output)]\n",
    "\n",
    "\n",
    "def plot_classes_preds(net, images, labels):\n",
    "    '''\n",
    "    Generates matplotlib Figure using a trained network, along with images\n",
    "    and labels from a batch, that shows the network's top prediction along\n",
    "    with its probability, alongside the actual label, coloring this\n",
    "    information based on whether the prediction was correct or not.\n",
    "    Uses the \"images_to_probs\" function.\n",
    "    '''\n",
    "    preds, probs = images_to_probs(net, images)\n",
    "    # plot the images in the batch, along with predicted and true labels\n",
    "    fig = plt.figure(figsize=(12, 48))\n",
    "    for idx in np.arange(4):\n",
    "        ax = fig.add_subplot(1, 4, idx+1, xticks=[], yticks=[])\n",
    "        matplotlib_imshow(images[idx], one_channel=True)\n",
    "        ax.set_title(\"{0}, {1:.1f}%\\n(label: {2})\".format(\n",
    "            labels[preds[idx]],\n",
    "            probs[idx] * 100.0,\n",
    "            labels[labels[idx]]),\n",
    "                    color=(\"green\" if preds[idx]==labels[idx].item() else \"red\"))\n",
    "    return fig\n",
    "\n",
    "def matplotlib_imshow(img, one_channel=True):\n",
    "    if one_channel:\n",
    "        img = img.mean(dim=0)\n",
    "    img = img / 2 + 0.5     # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    if one_channel:\n",
    "        plt.imshow(npimg, cmap=\"Greys\")\n",
    "    else:\n",
    "        plt.imshow(np.transpose(npimg, (1, 2, 0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def confusion_matrix_calc(data_loader_test, classes, model_ft):       \n",
    "        y_pred = []\n",
    "        y_true = []\n",
    "        for inputs, labels, imNo in data_loader_test:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "                output = model_ft(inputs) # Feed Network\n",
    "\n",
    "                output = (torch.max(torch.exp(output), 1)[1]).data.cpu().numpy()\n",
    "                y_pred.extend(output) # Save Prediction\n",
    "                \n",
    "                labels = labels.data.cpu().numpy()\n",
    "                y_true.extend(labels) # Save Truth\n",
    "\n",
    "        # constant for classes\n",
    "        # classes = ('Alive', 'Dead')\n",
    "\n",
    "        # Build confusion matrix\n",
    "        cf_matrix = confusion_matrix(y_true, y_pred)\n",
    "        return cf_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "k=5 #NUMBER OF K FOLDS\n",
    "epoch=5 #NUMBER OF EPOCHS\n",
    "\n",
    "torch.manual_seed(10)\n",
    "imIdx = torch.randperm(1).tolist()\n",
    "\n",
    "## Create dataset\n",
    "dataSetTrain = DNADataset(imDr, get_transform(train = True), labels, imDx=imIdx)\n",
    "dataSetTest = DNADataset(imDr, get_transform(train = False), labels, imDx=imIdx)\n",
    "\n",
    "data_loader_train=[]\n",
    "data_loader_test=[]\n",
    "\n",
    "# ## Create dataloaders\n",
    "# Get subset\n",
    "torch.manual_seed(10)\n",
    "indices = torch.randperm(len(dataSetTrain)).tolist()\n",
    "\n",
    "noTrain = int(len(dataSetTrain)*0.7)\n",
    "train=[]\n",
    "test=[]\n",
    "indices = torch.randperm(len(dataSetTrain)).tolist()\n",
    "TotalSet=list(range(len(dataSetTrain)))\n",
    "Kfifth = len(dataSetTrain)//k\n",
    "split= epoch%k\n",
    "train.append(TotalSet[(split+1)*Kfifth:]+TotalSet[:Kfifth*split])\n",
    "\n",
    "indices = torch.randperm(len(dataSetTest)).tolist()\n",
    "TotalSet=list(range(len(dataSetTrain)))\n",
    "test.append(TotalSet)\n",
    "\n",
    "#dataset_train = torch.utils.data.Subset(dataSetTrain, indices[-noTrain:])\n",
    "\n",
    "#dataset_test = torch.utils.data.Subset(dataSetTest, indices[:-noTrain])\n",
    "#len(indices), len(indices[:-50]), len(indices[-50:]), 50/191, type(dataset_test)\n",
    "\n",
    "dataset_sizes = {'train': len(train[0]), 'val': len(test)}\n",
    "\n",
    "#dataset_train = torch.utils.data.Subset(dataSetTrain, train)\n",
    "#data_loader_train.append(dataset_train)\n",
    "#dataset_testo = torch.utils.data.Subset(dataSetTest, test)\n",
    "#data_loader_test.append(dataset_testo)\n",
    "# define training and validation data loaders\n",
    "\n",
    "\n",
    "# Collate function (gathers together the outputs)\n",
    "# def collate_fn(batch):\n",
    "#     return tuple(zip(*batch))\n",
    "\n",
    "#len(indices[-noTrain:]), dataset_sizes\n",
    "#dataset_test[0][1], dataset_test[3][1], dataset_test[-1][1], dataSetTrain.imgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_weights= [0.924865,0.075135] #1-(#inclass/ #intotal )\n",
    "class_weights = torch.Tensor(class_weights)\n",
    "class_weights=class_weights.to(device)\n",
    "criterion = nn.CrossEntropyLoss(weight = class_weights) \n",
    "\n",
    "# Observe that all parameters are being optimized\n",
    "optimizer_ft = optim.Adam(model.parameters(), weight_decay=1e-2) # standard ADAM optimiser\n",
    "\n",
    "# Decay LR by a factor of 0.1 every 7 epochs\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/0\n",
      "----------\n",
      "val Loss: 9217.2987 Acc: 0.9378\n",
      "proper accuracy=\n",
      "tensor(0.9066, device='cuda:0')\n",
      "damaged accuracy=\n",
      "tensor(0.9021, device='cuda:0')\n",
      "undamaged accuracy=\n",
      "tensor(0.9735, device='cuda:0')\n",
      "[[51610  5604]\n",
      " [  103  3781]]\n",
      "\n",
      "Training complete in 1m 6s\n",
      "Best val Acc: 0.937766\n"
     ]
    }
   ],
   "source": [
    "model_ft, con_mat = train_model(model, criterion, optimizer_ft, exp_lr_scheduler, \n",
    "                                    train,test,num_epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cf_matrix = confusion_matrix_calc(data_loader_test, labels, model_ft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x504 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "con_mat=con_mat.cpu().numpy()\n",
    "plotlabels=['Undamaged','Damaged']\n",
    "df_cm_ratio = pd.DataFrame(con_mat / np.sum(con_mat, axis=1)[:, None], index=[i for i in plotlabels],\n",
    "                     columns=[i for i in plotlabels])\n",
    "plt.figure(figsize=(12, 7))\n",
    "sn.heatmap(df_cm_ratio, annot=True)\n",
    "# plt.save(\"Confusion_matrix_ratio.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x504 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_cm_raw = pd.DataFrame(con_mat, index=[i for i in plotlabels],\n",
    "                     columns=[i for i in plotlabels])\n",
    "plt.figure(figsize=(12, 7))\n",
    "sn.heatmap(df_cm_raw, annot=True)\n",
    "# plt.save(\"Confusion_matrix_raw.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[51610,  5604],\n",
       "       [  103,  3781]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "con_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_loader_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotlabels=['Undamaged','Damaged']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "\n",
    "x=torch.randn(10, 1, 244, 244, requires_grad=True).to(device)\n",
    "\n",
    "torch_out = model(x)\n",
    "\n",
    "torch.onnx.export(model, x, \"test.onnx\",\n",
    "\n",
    "                  export_params=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
