{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To note: Running this on different systems (i.e. local, SCW, server) will result in slight changes needing to the code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/scipy/__init__.py:138: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.4)\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion} is required for this version of \"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.pyplot._IonContext at 0x7fb771cfb850>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load libraries\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import sys\n",
    "import torchvision\n",
    "import torchvision.transforms as T\n",
    "import torchvision.models as models\n",
    "from PIL import Image\n",
    "from PIL import ImageEnhance\n",
    "import matplotlib.pyplot as plt\n",
    "import imagesize\n",
    "import subprocess\n",
    "sys.path\n",
    "from IPython.core.debugger import set_trace\n",
    "import scipy.ndimage\n",
    "import matplotlib.patches as patches\n",
    "# plt.rcParams['figure.figsize'] = [12,12]\n",
    "# sys.path.append('/workspace/myFile/Mask_RCNN_Tutorial/')\n",
    "from tqdm import tqdm\n",
    "from torch import nn as nn\n",
    "from torch import optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "import re\n",
    "import time\n",
    "import copy\n",
    "import pylab\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from tempfile import TemporaryDirectory\n",
    "import torch.backends.cudnn as cudnn\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "import seaborn as sn\n",
    "import pandas as pd\n",
    "import glob\n",
    "# Rather than have a messy notebook with a load of functions we can store them in separate .py files and import them\n",
    "\n",
    "cudnn.benchmark = True\n",
    "plt.ion()   # interactive mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "writer = SummaryWriter(\"Experiments/TENSORBOARD\")    # This determines the tensorboard file name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DNADataset(object):\n",
    "    def __init__(self, root, transforms, labels, imDx = False):\n",
    "        self.root, self.transforms, self.labels = root, transforms, labels\n",
    "    \n",
    "        # load all image files, sorting them to ensure they are aligned\n",
    "        self.imgDir = glob.glob(root+\"*/*.tiff\")\n",
    "        Damagednuclei= [x for x in self.imgDir if 'Damaged_nuclei_' in x]\n",
    "        Undamagednuclei= [x for x in self.imgDir if \"No_damage_nuclei\" in x]\n",
    "        #np.random.shuffle(Undamagednuclei)\n",
    "        #Undamagednuclei=Undamagednuclei[:10000]\n",
    "        self.imgDir= Damagednuclei+Undamagednuclei\n",
    "        size80=[]\n",
    "        for x in self.imgDir:\n",
    "            img = Image.open(x) # Open image\n",
    "            w,h=img.size\n",
    "            if w<=80 and h<=80:\n",
    "                size80.append(x)\n",
    "        self.imgDir=size80              \n",
    "        \n",
    "        self.imgs = sorted(self.imgDir) # list of images\n",
    "\n",
    "        \n",
    "\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.imgs[idx]\n",
    "       \n",
    "        # Transform images into tensors\n",
    "        img = Image.open(img_path) # Open image\n",
    "        w,h=img.size\n",
    "        img = np.array(img) # Convert image into an array\n",
    "        img = np.float32(np.divide(img, 2**16)) # Ensure all values are floats\n",
    "        \n",
    "        result=np.zeros((80,80), dtype=np.float32)\n",
    "        x_center = (80 - w) // 2\n",
    "        y_center = (80 - h) // 2 # copy img image into center of result image\n",
    "        result[y_center:y_center+h, x_center:x_center+w] = img\n",
    "        img = result\n",
    "        \n",
    "        targetlab=\"\"\n",
    "        if img_path.find('No_damage_nuclei') != -1:\n",
    "            targetlab= 'Undamaged'\n",
    "        if img_path.find('Damaged_nuclei_') != -1:\n",
    "            targetlab= 'Damaged'  # Find labels corresponding to image\n",
    "        target = self.labels.index(targetlab) # Get the label and assign to a value\n",
    "        \n",
    "        # Convert label to tensor\n",
    "        #torch.to\n",
    "        \n",
    "        if self.transforms is not None:\n",
    "            img = self.transforms(img)\n",
    "#             #print('In the transforms')\n",
    "        imNo = idx\n",
    "        return img, target, imNo\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.imgs)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "imDr = \"/workspace/myFile/Output/17052023/\"  # Image patches directory\n",
    "\n",
    "labels = ['Damaged', 'Undamaged']  # Your labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For data augmentation\n",
    "def get_transform(train):\n",
    "    transforms = []\n",
    "\n",
    "    transforms.append(T.ToTensor())\n",
    "    #transforms.append(T.Normalize([0.0019368887995516483], [0.00672996630111016]))\n",
    "    #transforms.append(T.RandomHorizontalFlip(0.5))\n",
    "    \n",
    "    if train:\n",
    "        transforms.append(T.RandomHorizontalFlip(p=1))\n",
    "        transforms.append(T.RandomVerticalFlip(p=1))\n",
    "    \n",
    "    return T.Compose(transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, scheduler, train, test, num_epochs=25):\n",
    "    since = time.time()\n",
    "    # Create a temporary directory to save training checkpoints\n",
    "    with TemporaryDirectory() as tempdir:\n",
    "        best_model_params_path = os.path.join(tempdir, 'best_model_params.pt')\n",
    "\n",
    "        torch.save(model.state_dict(), best_model_params_path)\n",
    "        best_acc = 0.0\n",
    "        \n",
    "        for epoch in range(num_epochs):\n",
    "            print(f'Epoch {epoch}/{num_epochs - 1}')\n",
    "            print('-' * 10)\n",
    "            dataset_train = torch.utils.data.Subset(dataSetTrain, train[epoch])\n",
    "            dataset_test = torch.utils.data.Subset(dataSetTest, test[epoch])\n",
    "            data_loader_train = torch.utils.data.DataLoader(\n",
    "                dataset_train, batch_size=128, shuffle=True, num_workers=0)\n",
    "\n",
    "            data_loader_test = torch.utils.data.DataLoader(\n",
    "                dataset_test, batch_size=128, shuffle=False, num_workers=0)\n",
    "            # Each epoch has a training and validation phase\n",
    "            for phase in ['val']:\n",
    "                if phase == 'train':\n",
    "                    model.train()  # Set model to training mode\n",
    "                    dataloaders = data_loader_train\n",
    "                else:\n",
    "                    model.eval()   # Set model to evaluate mode\n",
    "                    dataloaders = data_loader_test\n",
    "\n",
    "                running_loss = 0.0\n",
    "                running_corrects = 0\n",
    "                damaged_len=0\n",
    "                damaged_corrects = 0\n",
    "                undamaged_len=0\n",
    "                undamaged_corrects = 0\n",
    "\n",
    "                # Iterate over data.\n",
    "                for inputs, labels, imNo in dataloaders:\n",
    "                    inputs = inputs.to(device)\n",
    "                    labels = labels.to(device)\n",
    "\n",
    "                    # zero the parameter gradients\n",
    "                    optimizer.zero_grad()\n",
    "\n",
    "                    # forward\n",
    "                    # track history if only in train\n",
    "                    with torch.set_grad_enabled(phase == 'train'):\n",
    "                        outputs = model(inputs)\n",
    "                        _, preds = torch.max(outputs, 1)\n",
    "                        loss = criterion(outputs, labels)\n",
    "                        # backward + optimize only if in training phase\n",
    "                        if phase == 'train':\n",
    "                            loss.backward()\n",
    "                            optimizer.step()\n",
    "\n",
    "                    # statistics\n",
    "                    running_loss += loss.item() * inputs.size(0)    # Loss\n",
    "                    nada=torch.tensor(np.zeros(len(labels))).to(device)\n",
    "                    uno=nada+1\n",
    "                    falseneg=preds+1\n",
    "                    falsepos=preds-1\n",
    "                    FPplusTN=torch.sum(labels==nada)\n",
    "                    TPplusFN=torch.sum(labels==uno)\n",
    "                    FN=torch.sum(labels==falseneg)\n",
    "                    FP=torch.sum(labels==falsepos)\n",
    "                    TN=FPplusTN-FP\n",
    "                    TP=TPplusFN-FN\n",
    "                    running_corrects += torch.sum(preds == labels.data) # Accuracy\n",
    "                    damaged_len+=TPplusFN\n",
    "                    damaged_corrects += TP\n",
    "                    undamaged_len+=FPplusTN\n",
    "                    undamaged_corrects += TN\n",
    "                damaged_acc = damaged_corrects / damaged_len\n",
    "                undamaged_acc = undamaged_corrects/undamaged_len\n",
    "                epoch_acc= (damaged_acc+undamaged_acc)/2\n",
    "                proper_acc=(damaged_corrects+undamaged_corrects)/(damaged_len+undamaged_len)\n",
    "                if phase == 'train':\n",
    "                    scheduler.step()\n",
    "\n",
    "                epoch_loss = running_loss / dataset_sizes[phase]    # Loss metric per epoch\n",
    "                #epoch_acc = running_corrects.double() / dataset_sizes[phase]    # Accuracy metric per epoch\n",
    "\n",
    "                if phase == \"train\":    # This is the tensorboard code that writes accuracy and loss metrics\n",
    "                    writer.add_scalar(\"Train/Accuracy\", epoch_acc, epoch)\n",
    "                    writer.add_scalar(\"Train/Loss\", epoch_loss, epoch)\n",
    "                else:\n",
    "                    writer.add_scalar(\"Validation/Accuracy\", epoch_acc, epoch)\n",
    "                    writer.add_scalar(\"Validation/Loss\", epoch_loss, epoch)\n",
    "\n",
    "                print(f'{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n",
    "                print(\"proper accuracy=\")\n",
    "                print(proper_acc)\n",
    "                print(\"damaged accuracy=\")\n",
    "                print(damaged_acc)\n",
    "                print(\"undamaged accuracy=\")\n",
    "                print(undamaged_acc)\n",
    "                con_matter= torch.tensor([[damaged_corrects, damaged_len-damaged_corrects],[undamaged_len-undamaged_corrects,undamaged_corrects]])\n",
    "                con_matter=con_matter.cpu().numpy()\n",
    "                print(con_matter)\n",
    "                # deep copy the model\n",
    "                if phase == 'val' and epoch_acc >= best_acc: \n",
    "                    # This compares validation accuracy to previous bests and adjusts model weights accordingly\n",
    "                    best_acc = epoch_acc\n",
    "                    torch.save(model.state_dict(), best_model_params_path)\n",
    "                    con_mat= torch.tensor([[damaged_corrects, damaged_len-damaged_corrects],[undamaged_len-undamaged_corrects,undamaged_corrects]])\n",
    "\n",
    "            print()\n",
    "\n",
    "        time_elapsed = time.time() - since  # Nice way to measure training time but info also stored (indirectly) by tensorboard\n",
    "        print(\n",
    "            f'Training complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')\n",
    "        print(f'Best val Acc: {best_acc:4f}')\n",
    "        #labels= labels.cpu().numpy()\n",
    "        #preds=preds.cpu().numpy()\n",
    "        model.load_state_dict(torch.load(best_model_params_path))\n",
    "    writer.close()\n",
    "    return model, con_mat   # We want to return the model because its the model, also confusion matrix for later analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is your RESNET\n",
    "# Initialize CNN with kaiming\n",
    "def init_cnn(m):\n",
    "    # Set the weights of the RESNET\n",
    "    if getattr(m, 'bias', None) is not None: nn.init.constant_(m.bias, 0)\n",
    "    if isinstance(m, (nn.Conv2d,nn.Linear)): nn.init.kaiming_normal_(m.weight)\n",
    "    for l in m.children(): init_cnn(l)\n",
    "\n",
    "\n",
    "# noop function for returning nothing\n",
    "def noop(x): return x\n",
    "# activation function(RELU)\n",
    "act_fn = nn.ReLU(inplace=True)\n",
    "\n",
    "# Flatten\n",
    "class Flatten(nn.Module):\n",
    "    def forward(self, x): return x.view(x.size(0), -1)\n",
    "\n",
    "# Make a convolution\n",
    "def conv(ni, nf, ks=3, stride=1, bias=False):\n",
    "    return nn.Conv2d(ni, nf, kernel_size=ks, stride=stride, padding=ks//2, bias=bias)\n",
    "\n",
    "# Create a convuolutional layer with convolution and batch norm\n",
    "def conv_layer(ni, nf, ks=3, stride=1, zero_bn=False, act=True):\n",
    "    bn = nn.BatchNorm2d(nf) # get a 2d batch norm from Pytorhc\n",
    "    nn.init.constant_(bn.weight, 0. if zero_bn else 1.)\n",
    "    layers = [conv(ni, nf, ks, stride=stride), bn]\n",
    "    if act: layers.append(act_fn) # add in the activation function if act is true\n",
    "    return nn.Sequential(*layers)\n",
    "\n",
    "\n",
    "# Resblock\n",
    "class ResBlock(nn.Module):\n",
    "    def __init__(self, expansion, ni, nh, stride = 1):\n",
    "        super().__init__()\n",
    "        # ni - number of inputs channels, nf - number of filters\n",
    "        # nh - number of filters in first conv\n",
    "        # expansion is 1 for resnet 18, 34 and 4 for larger networks\n",
    "        nf, ni = nh*expansion, ni*expansion\n",
    "        layers = [conv_layer(ni, nh, 3, stride = stride), # for resnet < 34 2 convs per resblock\n",
    "                 conv_layer(nh, nf, 3, zero_bn = True, act = False)\n",
    "                 ] if expansion == 1 else [ # for RESNET > 34 then 3 convs per block with bottleneck\n",
    "                            conv_layer(ni, nh, 1),\n",
    "                            conv_layer(nh, nh, 3, stride = stride),\n",
    "                            conv_layer(nh, nf, 1, zero_bn = True, act = False)\n",
    "        ]\n",
    "        self.convs = nn.Sequential(*layers) # Creates the conv layers\n",
    "        self.idconv = noop if ni==nf else conv_layer(ni, nf, 1, act = False) # id convolution ()\n",
    "        self.pool = noop if stride== 1 else nn.AvgPool2d(2, ceil_mode = True) # average pool on \n",
    "        \n",
    "    def forward(self, x): \n",
    "        # Forward function adds the convolution part to the id part \n",
    "        #return act_fn(self.convs(x)) + self.idconv(self.pool(x))\n",
    "        return act_fn(self.convs(x) + self.idconv(self.pool(x)))\n",
    "\n",
    "# XResnet\n",
    "class XResNet(nn.Sequential):\n",
    "    @classmethod\n",
    "    def create(cls, expansion, layers, c_in=3, c_out=1000):\n",
    "        nfs = [c_in, (c_in + 1)*8, 64, 64] # number of filters in stem layer (c_in is number of image channels)\n",
    "        stem = [conv_layer(nfs[i], nfs[i+1], stride=2 if i==0 else 1)\n",
    "            for i in range(3)]\n",
    "\n",
    "        nfs = [64//expansion,64,128,256,512]\n",
    "        res_layers = [cls._make_layer(expansion, nfs[i], nfs[i+1],\n",
    "                                      n_blocks=l, stride=1 if i==0 else 2)\n",
    "                  for i,l in enumerate(layers)]\n",
    "        res = cls(\n",
    "        *stem,\n",
    "        nn.MaxPool2d(kernel_size=3, stride = 2, padding = 1), # then a max pooling layer\n",
    "        *res_layers,\n",
    "        nn.AdaptiveAvgPool2d(1), Flatten(), \n",
    "        nn.Linear(nfs[-1]*expansion, c_out)\n",
    "        )\n",
    "        init_cnn(res)\n",
    "        return res\n",
    "        \n",
    "    @staticmethod\n",
    "    def _make_layer(expansion, ni, nf, n_blocks, stride): # returns a resblock\n",
    "        return nn.Sequential(\n",
    "        *[ResBlock(expansion, ni if i==0 else nf, nf, stride if i==0 else 1)\n",
    "         for i in range(n_blocks)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def xresnet18 (**kwargs): return XResNet.create(1, [2, 2,  2, 2], **kwargs)\n",
    "def xresnet34 (**kwargs): return XResNet.create(1, [3, 4,  6, 3], **kwargs)\n",
    "def xresnet50 (**kwargs): return XResNet.create(4, [3, 4,  6, 3], **kwargs)\n",
    "model = xresnet18(c_in = 1, c_out = 2)\n",
    "#model34 = xresnet34(c_in = 1, c_out = 2)\n",
    "#model50 = xresnet50(c_in = 1, c_out = 2)\n",
    "model.load_state_dict(torch.load(\"/workspace/myFile/Output/17052023/best_model_params.pt\"))\n",
    "model = model.to(device)\n",
    "\n",
    "# Label smoothing cross entropy\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "def reduce_loss(loss, reduction='mean'):\n",
    "    return loss.mean() if reduction=='mean' else loss.sum() if reduction=='sum' else loss\n",
    "\n",
    "class LabelSmoothingCrossEntropy(nn.Module):\n",
    "    def __init__(self, ε:float=0.1, reduction='mean'):\n",
    "        super().__init__()\n",
    "        self.ε,self.reduction = ε,reduction\n",
    "    \n",
    "    def forward(self, output, target):\n",
    "        c = output.size()[-1]\n",
    "        log_preds = F.log_softmax(output, dim=-1)\n",
    "        loss = reduce_loss(-log_preds.sum(dim=-1), self.reduction)\n",
    "        nll = F.nll_loss(log_preds, target, reduction=self.reduction)\n",
    "        return lin_comb(loss/c, nll, self.ε)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions that shows the image, true class, predicted class and degree of prediction\n",
    "\n",
    "def images_to_probs(net, images):\n",
    "    '''\n",
    "    Generates predictions and corresponding probabilities from a trained\n",
    "    network and a list of images\n",
    "    '''\n",
    "    output = net(images)\n",
    "    # convert output probabilities to predicted class\n",
    "    _, preds_tensor = torch.max(output, 1)\n",
    "    preds = np.squeeze(preds_tensor.numpy())\n",
    "    return preds, [F.softmax(el, dim=0)[i].item() for i, el in zip(preds, output)]\n",
    "\n",
    "\n",
    "def plot_classes_preds(net, images, labels):\n",
    "    '''\n",
    "    Generates matplotlib Figure using a trained network, along with images\n",
    "    and labels from a batch, that shows the network's top prediction along\n",
    "    with its probability, alongside the actual label, coloring this\n",
    "    information based on whether the prediction was correct or not.\n",
    "    Uses the \"images_to_probs\" function.\n",
    "    '''\n",
    "    preds, probs = images_to_probs(net, images)\n",
    "    # plot the images in the batch, along with predicted and true labels\n",
    "    fig = plt.figure(figsize=(12, 48))\n",
    "    for idx in np.arange(4):\n",
    "        ax = fig.add_subplot(1, 4, idx+1, xticks=[], yticks=[])\n",
    "        matplotlib_imshow(images[idx], one_channel=True)\n",
    "        ax.set_title(\"{0}, {1:.1f}%\\n(label: {2})\".format(\n",
    "            labels[preds[idx]],\n",
    "            probs[idx] * 100.0,\n",
    "            labels[labels[idx]]),\n",
    "                    color=(\"green\" if preds[idx]==labels[idx].item() else \"red\"))\n",
    "    return fig\n",
    "\n",
    "def matplotlib_imshow(img, one_channel=True):\n",
    "    if one_channel:\n",
    "        img = img.mean(dim=0)\n",
    "    img = img / 2 + 0.5     # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    if one_channel:\n",
    "        plt.imshow(npimg, cmap=\"Greys\")\n",
    "    else:\n",
    "        plt.imshow(np.transpose(npimg, (1, 2, 0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def confusion_matrix_calc(data_loader_test, classes, model_ft):       \n",
    "        y_pred = []\n",
    "        y_true = []\n",
    "        for inputs, labels, imNo in data_loader_test:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "                output = model_ft(inputs) # Feed Network\n",
    "\n",
    "                output = (torch.max(torch.exp(output), 1)[1]).data.cpu().numpy()\n",
    "                y_pred.extend(output) # Save Prediction\n",
    "                \n",
    "                labels = labels.data.cpu().numpy()\n",
    "                y_true.extend(labels) # Save Truth\n",
    "\n",
    "        # constant for classes\n",
    "        # classes = ('Alive', 'Dead')\n",
    "\n",
    "        # Build confusion matrix\n",
    "        cf_matrix = confusion_matrix(y_true, y_pred)\n",
    "        return cf_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "k=5 #NUMBER OF K FOLDS\n",
    "epoch=5 #NUMBER OF EPOCHS\n",
    "\n",
    "torch.manual_seed(10)\n",
    "imIdx = torch.randperm(1).tolist()\n",
    "\n",
    "## Create dataset\n",
    "dataSetTrain = DNADataset(imDr, get_transform(train = True), labels, imDx=imIdx)\n",
    "dataSetTest = DNADataset(imDr, get_transform(train = False), labels, imDx=imIdx)\n",
    "\n",
    "data_loader_train=[]\n",
    "data_loader_test=[]\n",
    "\n",
    "# ## Create dataloaders\n",
    "# Get subset\n",
    "torch.manual_seed(10)\n",
    "indices = torch.randperm(len(dataSetTrain)).tolist()\n",
    "\n",
    "noTrain = int(len(dataSetTrain)*0.7)\n",
    "train=[]\n",
    "test=[]\n",
    "indices = torch.randperm(len(dataSetTrain)).tolist()\n",
    "TotalSet=list(range(len(dataSetTrain)))\n",
    "Kfifth = len(dataSetTrain)//k\n",
    "split= epoch%k\n",
    "train.append(TotalSet[(split+1)*Kfifth:]+TotalSet[:Kfifth*split])\n",
    "\n",
    "indices = torch.randperm(len(dataSetTest)).tolist()\n",
    "TotalSet=list(range(len(dataSetTrain)))\n",
    "test.append(TotalSet)\n",
    "\n",
    "#dataset_train = torch.utils.data.Subset(dataSetTrain, indices[-noTrain:])\n",
    "\n",
    "#dataset_test = torch.utils.data.Subset(dataSetTest, indices[:-noTrain])\n",
    "#len(indices), len(indices[:-50]), len(indices[-50:]), 50/191, type(dataset_test)\n",
    "\n",
    "dataset_sizes = {'train': len(train[0]), 'val': len(test)}\n",
    "\n",
    "#dataset_train = torch.utils.data.Subset(dataSetTrain, train)\n",
    "#data_loader_train.append(dataset_train)\n",
    "#dataset_testo = torch.utils.data.Subset(dataSetTest, test)\n",
    "#data_loader_test.append(dataset_testo)\n",
    "# define training and validation data loaders\n",
    "\n",
    "\n",
    "# Collate function (gathers together the outputs)\n",
    "# def collate_fn(batch):\n",
    "#     return tuple(zip(*batch))\n",
    "\n",
    "#len(indices[-noTrain:]), dataset_sizes\n",
    "#dataset_test[0][1], dataset_test[3][1], dataset_test[-1][1], dataSetTrain.imgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_weights= [3,0.075135] #1-(#inclass/ #intotal )\n",
    "class_weights = torch.Tensor(class_weights)\n",
    "class_weights=class_weights.to(device)\n",
    "criterion = nn.CrossEntropyLoss(weight = class_weights) \n",
    "\n",
    "# Observe that all parameters are being optimized\n",
    "optimizer_ft = optim.Adam(model.parameters(), weight_decay=1e-2) # standard ADAM optimiser\n",
    "\n",
    "# Decay LR by a factor of 0.1 every 7 epochs\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/0\n",
      "----------\n",
      "val Loss: 21553.0809 Acc: 0.9297\n",
      "proper accuracy=\n",
      "tensor(0.8989, device='cuda:0')\n",
      "damaged accuracy=\n",
      "tensor(0.8934, device='cuda:0')\n",
      "undamaged accuracy=\n",
      "tensor(0.9660, device='cuda:0')\n",
      "[[108810  12979]\n",
      " [   336   9558]]\n",
      "\n",
      "Training complete in 2m 21s\n",
      "Best val Acc: 0.929735\n"
     ]
    }
   ],
   "source": [
    "model_ft, con_mat = train_model(model, criterion, optimizer_ft, exp_lr_scheduler, \n",
    "                                    train,test,num_epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cf_matrix = confusion_matrix_calc(data_loader_test, labels, model_ft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x504 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "con_mat=con_mat.cpu().numpy()\n",
    "plotlabels=['Undamaged','Damaged']\n",
    "df_cm_ratio = pd.DataFrame(con_mat / np.sum(con_mat, axis=1)[:, None], index=[i for i in plotlabels],\n",
    "                     columns=[i for i in plotlabels])\n",
    "plt.figure(figsize=(12, 7))\n",
    "sn.heatmap(df_cm_ratio, annot=True)\n",
    "# plt.save(\"Confusion_matrix_ratio.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x504 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_cm_raw = pd.DataFrame(con_mat, index=[i for i in plotlabels],\n",
    "                     columns=[i for i in plotlabels])\n",
    "plt.figure(figsize=(12, 7))\n",
    "sn.heatmap(df_cm_raw, annot=True)\n",
    "# plt.save(\"Confusion_matrix_raw.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[108810,  12979],\n",
       "       [   336,   9558]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "con_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_loader_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotlabels=['Undamaged','Damaged']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
