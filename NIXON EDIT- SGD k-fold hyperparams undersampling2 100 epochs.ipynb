{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To note: Running this on different systems (i.e. local, SCW, server) will result in slight changes needing to the code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/scipy/__init__.py:138: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.4)\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion} is required for this version of \"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.pyplot._IonContext at 0x7fd58cc6bf70>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load libraries\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import sys\n",
    "import torchvision\n",
    "import torchvision.transforms as T\n",
    "import torchvision.models as models\n",
    "from PIL import Image\n",
    "from PIL import ImageEnhance\n",
    "import matplotlib.pyplot as plt\n",
    "import imagesize\n",
    "import subprocess\n",
    "sys.path\n",
    "from IPython.core.debugger import set_trace\n",
    "import scipy.ndimage\n",
    "import matplotlib.patches as patches\n",
    "# plt.rcParams['figure.figsize'] = [12,12]\n",
    "# sys.path.append('/workspace/myFile/Mask_RCNN_Tutorial/')\n",
    "from tqdm import tqdm\n",
    "from torch import nn as nn\n",
    "from torch import optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "import re\n",
    "import time\n",
    "import copy\n",
    "import pylab\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from tempfile import TemporaryDirectory\n",
    "import torch.backends.cudnn as cudnn\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "import seaborn as sn\n",
    "import pandas as pd\n",
    "import glob\n",
    "# Rather than have a messy notebook with a load of functions we can store them in separate .py files and import them\n",
    "\n",
    "cudnn.benchmark = True\n",
    "plt.ion()   # interactive mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard\n",
    "writer = SummaryWriter(\"Experiments/09085epoch\")    # This determines the tensorboard file name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DNADataset(object):\n",
    "    def __init__(self, root, transforms, labels, imDx = False):\n",
    "        self.root, self.transforms, self.labels = root, transforms, labels\n",
    "        self.imgDir=[]\n",
    "        # load all image files, sorting them to ensure they are aligned\n",
    "        for drug in [\"A\",\"B\",\"C\",\"D\",\"E\",\"F\"]:\n",
    "            subset=glob.glob(root+drug+\"*/*.tiff\")\n",
    "            np.random.shuffle(subset)\n",
    "            subset=subset[:12945]\n",
    "            self.imgDir=self.imgDir+subset\n",
    "        Damagednuclei= [x for x in self.imgDir if 'Damaged_nuclei_' in x]\n",
    "        Undamagednuclei= [x for x in self.imgDir if \"No_damage_nuclei\" in x]\n",
    "        #np.random.shuffle(Undamagednuclei)\n",
    "        #Undamagednuclei=Undamagednuclei[:10000]\n",
    "        self.imgDir= Damagednuclei+Undamagednuclei\n",
    "        size80=[]\n",
    "        for x in self.imgDir:\n",
    "            img = Image.open(x) # Open image\n",
    "            w,h=img.size\n",
    "            if w<=80 and h<=80:\n",
    "                size80.append(x)\n",
    "        self.imgDir=size80              \n",
    "        \n",
    "        self.imgs = sorted(self.imgDir) # list of images\n",
    "\n",
    "        \n",
    "\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.imgs[idx]\n",
    "       \n",
    "        # Transform images into tensors\n",
    "        img = Image.open(img_path) # Open image\n",
    "        w,h=img.size\n",
    "        img = np.array(img) # Convert image into an array\n",
    "        img = np.float32(np.divide(img, 2**16)) # Ensure all values are floats\n",
    "        \n",
    "        result=np.zeros((80,80), dtype=np.float32)\n",
    "        x_center = (80 - w) // 2\n",
    "        y_center = (80 - h) // 2 # copy img image into center of result image\n",
    "        result[y_center:y_center+h, x_center:x_center+w] = img\n",
    "        img = result\n",
    "        \n",
    "        targetlab=\"\"\n",
    "        if img_path.find('No_damage_nuclei') != -1:\n",
    "            targetlab= 'Undamaged'\n",
    "        if img_path.find('Damaged_nuclei_') != -1:\n",
    "            targetlab= 'Damaged'  # Find labels corresponding to image\n",
    "        target = self.labels.index(targetlab) # Get the label and assign to a value\n",
    "        \n",
    "        # Convert label to tensor\n",
    "        #torch.to\n",
    "        \n",
    "        if self.transforms is not None:\n",
    "            img = self.transforms(img)\n",
    "#             #print('In the transforms')\n",
    "        imNo = idx\n",
    "        return img, target, imNo\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.imgs)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "root=\"/workspace/myFile/Output/17052023/\"\n",
    "p= glob.glob(root+\"*/*.tiff\")\n",
    "Damagednuclei= [x for x in p if 'Damaged_nuclei_' in x]\n",
    "Undamagednuclei= [x for x in p if \"No_damage_nuclei\" in x]\n",
    "#np.random.shuffle(Undamagednuclei)\n",
    "#Undamagednuclei=Undamagednuclei[:10000]\n",
    "#Undamagednuclei"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "imDr = \"/workspace/myFile/Output/17052023/\"  # Image patches directory\n",
    "\n",
    "labels = ['Damaged', 'Undamaged']  # Your labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For data augmentation\n",
    "def get_transform(train):\n",
    "    transforms = []\n",
    "\n",
    "    transforms.append(T.ToTensor())\n",
    "    #transforms.append(T.Normalize([0.0019368887995516483], [0.00672996630111016]))\n",
    "    #transforms.append(T.RandomHorizontalFlip(0.5))\n",
    "    \n",
    "    if train:\n",
    "        transforms.append(T.RandomHorizontalFlip(p=0.5))\n",
    "        transforms.append(T.RandomVerticalFlip(p=0.5))\n",
    "    \n",
    "    return T.Compose(transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, scheduler, train, test, num_epochs=25):\n",
    "    since = time.time()\n",
    "    # Create a temporary directory to save training checkpoints\n",
    "    with TemporaryDirectory() as tempdir:\n",
    "        best_model_params_path = os.path.join(tempdir, 'best_model_params.pt')\n",
    "\n",
    "        torch.save(model.state_dict(), best_model_params_path)\n",
    "        best_acc = 0.0\n",
    "        \n",
    "        for epoch in range(num_epochs):\n",
    "            print(f'Epoch {epoch}/{num_epochs - 1}')\n",
    "            print('-' * 10)\n",
    "            dataset_train = torch.utils.data.Subset(dataSetTrain, train[epoch])\n",
    "            dataset_test = torch.utils.data.Subset(dataSetTest, test[epoch])\n",
    "            data_loader_train = torch.utils.data.DataLoader(\n",
    "                dataset_train, batch_size=128, shuffle=True, num_workers=0)\n",
    "\n",
    "            data_loader_test = torch.utils.data.DataLoader(\n",
    "                dataset_test, batch_size=128, shuffle=False, num_workers=0)\n",
    "            # Each epoch has a training and validation phase\n",
    "            for phase in ['train', 'val']:\n",
    "                if phase == 'train':\n",
    "                    model.train()  # Set model to training mode\n",
    "                    dataloaders = data_loader_train\n",
    "                else:\n",
    "                    model.eval()   # Set model to evaluate mode\n",
    "                    dataloaders = data_loader_test\n",
    "\n",
    "                running_loss = 0.0\n",
    "                running_corrects = 0\n",
    "                damaged_len=0\n",
    "                damaged_corrects = 0\n",
    "                undamaged_len=0\n",
    "                undamaged_corrects = 0\n",
    "\n",
    "                # Iterate over data.\n",
    "                for inputs, labels, imNo in dataloaders:\n",
    "                    inputs = inputs.to(device)\n",
    "                    labels = labels.to(device)\n",
    "\n",
    "                    # zero the parameter gradients\n",
    "                    optimizer.zero_grad()\n",
    "\n",
    "                    # forward\n",
    "                    # track history if only in train\n",
    "                    with torch.set_grad_enabled(phase == 'train'):\n",
    "                        outputs = model(inputs)\n",
    "                        _, preds = torch.max(outputs, 1)\n",
    "                        loss = criterion(outputs, labels)\n",
    "                        # backward + optimize only if in training phase\n",
    "                        if phase == 'train':\n",
    "                            loss.backward()\n",
    "                            optimizer.step()\n",
    "\n",
    "                    # statistics\n",
    "                    running_loss += loss.item() * inputs.size(0)    # Loss\n",
    "                    nada=torch.tensor(np.zeros(len(labels))).to(device)\n",
    "                    uno=nada+1\n",
    "                    falseneg=preds+1\n",
    "                    falsepos=preds-1\n",
    "                    FPplusTN=torch.sum(labels==nada)\n",
    "                    TPplusFN=torch.sum(labels==uno)\n",
    "                    FN=torch.sum(labels==falseneg)\n",
    "                    FP=torch.sum(labels==falsepos)\n",
    "                    TN=FPplusTN-FP\n",
    "                    TP=TPplusFN-FN\n",
    "                    running_corrects += torch.sum(preds == labels.data) # Accuracy\n",
    "                    damaged_len+=TPplusFN\n",
    "                    damaged_corrects += TP\n",
    "                    undamaged_len+=FPplusTN\n",
    "                    undamaged_corrects += TN\n",
    "                damaged_acc = damaged_corrects / damaged_len\n",
    "                undamaged_acc = undamaged_corrects/undamaged_len\n",
    "                epoch_acc= (damaged_acc+undamaged_acc)/2\n",
    "                \n",
    "                if phase == 'train':\n",
    "                    scheduler.step()\n",
    "\n",
    "                epoch_loss = running_loss / dataset_sizes[phase]    # Loss metric per epoch\n",
    "                #epoch_acc = running_corrects.double() / dataset_sizes[phase]    # Accuracy metric per epoch\n",
    "\n",
    "                if phase == \"train\":    # This is the tensorboard code that writes accuracy and loss metrics\n",
    "                    writer.add_scalar(\"Train/Accuracy\", epoch_acc, epoch)\n",
    "                    writer.add_scalar(\"Train/Loss\", epoch_loss, epoch)\n",
    "                else:\n",
    "                    writer.add_scalar(\"Validation/Accuracy\", epoch_acc, epoch)\n",
    "                    writer.add_scalar(\"Validation/Loss\", epoch_loss, epoch)\n",
    "\n",
    "                print(f'{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n",
    "\n",
    "                # deep copy the model\n",
    "                if phase == 'val' and epoch_acc >= best_acc: \n",
    "                    # This compares validation accuracy to previous bests and adjusts model weights accordingly\n",
    "                    best_acc = epoch_acc\n",
    "                    torch.save(model.state_dict(), best_model_params_path)\n",
    "                    con_mat= torch.tensor([[damaged_corrects, damaged_len-damaged_corrects],[undamaged_len-undamaged_corrects,undamaged_corrects]])\n",
    "\n",
    "            print()\n",
    "\n",
    "        time_elapsed = time.time() - since  # Nice way to measure training time but info also stored (indirectly) by tensorboard\n",
    "        print(\n",
    "            f'Training complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')\n",
    "        print(f'Best val Acc: {best_acc:4f}')\n",
    "        #labels= labels.cpu().numpy()\n",
    "        #preds=preds.cpu().numpy()\n",
    "        model.load_state_dict(torch.load(best_model_params_path))\n",
    "    writer.close()\n",
    "    return model, con_mat, best_acc   # We want to return the model because its the model, also confusion matrix for later analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is your RESNET\n",
    "# Initialize CNN with kaiming\n",
    "def init_cnn(m):\n",
    "    # Set the weights of the RESNET\n",
    "    if getattr(m, 'bias', None) is not None: nn.init.constant_(m.bias, 0)\n",
    "    if isinstance(m, (nn.Conv2d,nn.Linear)): nn.init.kaiming_normal_(m.weight)\n",
    "    for l in m.children(): init_cnn(l)\n",
    "\n",
    "\n",
    "# noop function for returning nothing\n",
    "def noop(x): return x\n",
    "# activation function(RELU)\n",
    "act_fn = nn.ReLU(inplace=True)\n",
    "\n",
    "# Flatten\n",
    "class Flatten(nn.Module):\n",
    "    def forward(self, x): return x.view(x.size(0), -1)\n",
    "\n",
    "# Make a convolution\n",
    "def conv(ni, nf, ks=3, stride=1, bias=False):\n",
    "    return nn.Conv2d(ni, nf, kernel_size=ks, stride=stride, padding=ks//2, bias=bias)\n",
    "\n",
    "# Create a convuolutional layer with convolution and batch norm\n",
    "def conv_layer(ni, nf, ks=3, stride=1, zero_bn=False, act=True):\n",
    "    bn = nn.BatchNorm2d(nf) # get a 2d batch norm from Pytorhc\n",
    "    nn.init.constant_(bn.weight, 0. if zero_bn else 1.)\n",
    "    layers = [conv(ni, nf, ks, stride=stride), bn]\n",
    "    if act: layers.append(act_fn) # add in the activation function if act is true\n",
    "    return nn.Sequential(*layers)\n",
    "\n",
    "\n",
    "# Resblock\n",
    "class ResBlock(nn.Module):\n",
    "    def __init__(self, expansion, ni, nh, stride = 1):\n",
    "        super().__init__()\n",
    "        # ni - number of inputs channels, nf - number of filters\n",
    "        # nh - number of filters in first conv\n",
    "        # expansion is 1 for resnet 18, 34 and 4 for larger networks\n",
    "        nf, ni = nh*expansion, ni*expansion\n",
    "        layers = [conv_layer(ni, nh, 3, stride = stride), # for resnet < 34 2 convs per resblock\n",
    "                 conv_layer(nh, nf, 3, zero_bn = True, act = False)\n",
    "                 ] if expansion == 1 else [ # for RESNET > 34 then 3 convs per block with bottleneck\n",
    "                            conv_layer(ni, nh, 1),\n",
    "                            conv_layer(nh, nh, 3, stride = stride),\n",
    "                            conv_layer(nh, nf, 1, zero_bn = True, act = False)\n",
    "        ]\n",
    "        self.convs = nn.Sequential(*layers) # Creates the conv layers\n",
    "        self.idconv = noop if ni==nf else conv_layer(ni, nf, 1, act = False) # id convolution ()\n",
    "        self.pool = noop if stride== 1 else nn.AvgPool2d(2, ceil_mode = True) # average pool on \n",
    "        \n",
    "    def forward(self, x): \n",
    "        # Forward function adds the convolution part to the id part \n",
    "        #return act_fn(self.convs(x)) + self.idconv(self.pool(x))\n",
    "        return act_fn(self.convs(x) + self.idconv(self.pool(x)))\n",
    "\n",
    "# XResnet\n",
    "class XResNet(nn.Sequential):\n",
    "    @classmethod\n",
    "    def create(cls, expansion, layers, c_in=3, c_out=1000):\n",
    "        nfs = [c_in, (c_in + 1)*8, 64, 64] # number of filters in stem layer (c_in is number of image channels)\n",
    "        stem = [conv_layer(nfs[i], nfs[i+1], stride=2 if i==0 else 1)\n",
    "            for i in range(3)]\n",
    "\n",
    "        nfs = [64//expansion,64,128,256,512]\n",
    "        res_layers = [cls._make_layer(expansion, nfs[i], nfs[i+1],\n",
    "                                      n_blocks=l, stride=1 if i==0 else 2)\n",
    "                  for i,l in enumerate(layers)]\n",
    "        res = cls(\n",
    "        *stem,\n",
    "        nn.MaxPool2d(kernel_size=3, stride = 2, padding = 1), # then a max pooling layer\n",
    "        *res_layers,\n",
    "        nn.AdaptiveAvgPool2d(1), Flatten(), \n",
    "        nn.Linear(nfs[-1]*expansion, c_out)\n",
    "        )\n",
    "        init_cnn(res)\n",
    "        return res\n",
    "        \n",
    "    @staticmethod\n",
    "    def _make_layer(expansion, ni, nf, n_blocks, stride): # returns a resblock\n",
    "        return nn.Sequential(\n",
    "        *[ResBlock(expansion, ni if i==0 else nf, nf, stride if i==0 else 1)\n",
    "         for i in range(n_blocks)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def xresnet18 (**kwargs): return XResNet.create(1, [2, 2,  2, 2], **kwargs)\n",
    "def xresnet34 (**kwargs): return XResNet.create(1, [3, 4,  6, 3], **kwargs)\n",
    "def xresnet50 (**kwargs): return XResNet.create(4, [3, 4,  6, 3], **kwargs)\n",
    "model18 = xresnet18(c_in = 1, c_out = 2)\n",
    "model34 = xresnet34(c_in = 1, c_out = 2)\n",
    "model50 = xresnet50(c_in = 1, c_out = 2)\n",
    "\n",
    "# Label smoothing cross entropy\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "def reduce_loss(loss, reduction='mean'):\n",
    "    return loss.mean() if reduction=='mean' else loss.sum() if reduction=='sum' else loss\n",
    "\n",
    "class LabelSmoothingCrossEntropy(nn.Module):\n",
    "    def __init__(self, ε:float=0.1, reduction='mean'):\n",
    "        super().__init__()\n",
    "        self.ε,self.reduction = ε,reduction\n",
    "    \n",
    "    def forward(self, output, target):\n",
    "        c = output.size()[-1]\n",
    "        log_preds = F.log_softmax(output, dim=-1)\n",
    "        loss = reduce_loss(-log_preds.sum(dim=-1), self.reduction)\n",
    "        nll = F.nll_loss(log_preds, target, reduction=self.reduction)\n",
    "        return lin_comb(loss/c, nll, self.ε)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions that shows the image, true class, predicted class and degree of prediction\n",
    "\n",
    "def images_to_probs(net, images):\n",
    "    '''\n",
    "    Generates predictions and corresponding probabilities from a trained\n",
    "    network and a list of images\n",
    "    '''\n",
    "    output = net(images)\n",
    "    # convert output probabilities to predicted class\n",
    "    _, preds_tensor = torch.max(output, 1)\n",
    "    preds = np.squeeze(preds_tensor.numpy())\n",
    "    return preds, [F.softmax(el, dim=0)[i].item() for i, el in zip(preds, output)]\n",
    "\n",
    "\n",
    "def plot_classes_preds(net, images, labels):\n",
    "    '''\n",
    "    Generates matplotlib Figure using a trained network, along with images\n",
    "    and labels from a batch, that shows the network's top prediction along\n",
    "    with its probability, alongside the actual label, coloring this\n",
    "    information based on whether the prediction was correct or not.\n",
    "    Uses the \"images_to_probs\" function.\n",
    "    '''\n",
    "    preds, probs = images_to_probs(net, images)\n",
    "    # plot the images in the batch, along with predicted and true labels\n",
    "    fig = plt.figure(figsize=(12, 48))\n",
    "    for idx in np.arange(4):\n",
    "        ax = fig.add_subplot(1, 4, idx+1, xticks=[], yticks=[])\n",
    "        matplotlib_imshow(images[idx], one_channel=True)\n",
    "        ax.set_title(\"{0}, {1:.1f}%\\n(label: {2})\".format(\n",
    "            labels[preds[idx]],\n",
    "            probs[idx] * 100.0,\n",
    "            labels[labels[idx]]),\n",
    "                    color=(\"green\" if preds[idx]==labels[idx].item() else \"red\"))\n",
    "    return fig\n",
    "\n",
    "def matplotlib_imshow(img, one_channel=True):\n",
    "    if one_channel:\n",
    "        img = img.mean(dim=0)\n",
    "    img = img / 2 + 0.5     # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    if one_channel:\n",
    "        plt.imshow(npimg, cmap=\"Greys\")\n",
    "    else:\n",
    "        plt.imshow(np.transpose(npimg, (1, 2, 0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def confusion_matrix_calc(data_loader_test, classes, model_ft):       \n",
    "        y_pred = []\n",
    "        y_true = []\n",
    "        for inputs, labels, imNo in data_loader_test:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "                output = model_ft(inputs) # Feed Network\n",
    "\n",
    "                output = (torch.max(torch.exp(output), 1)[1]).data.cpu().numpy()\n",
    "                y_pred.extend(output) # Save Prediction\n",
    "                \n",
    "                labels = labels.data.cpu().numpy()\n",
    "                y_true.extend(labels) # Save Truth\n",
    "\n",
    "        # constant for classes\n",
    "        # classes = ('Alive', 'Dead')\n",
    "\n",
    "        # Build confusion matrix\n",
    "        cf_matrix = confusion_matrix(y_true, y_pred)\n",
    "        return cf_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "k=5 #NUMBER OF K FOLDS\n",
    "epoch=range(100) #NUMBER OF EPOCHS\n",
    "\n",
    "torch.manual_seed(10)\n",
    "imIdx = torch.randperm(1).tolist()\n",
    "\n",
    "## Create dataset\n",
    "dataSetTrain = DNADataset(imDr, get_transform(train = True), labels, imDx=imIdx)\n",
    "dataSetTest = DNADataset(imDr, get_transform(train = False), labels, imDx=imIdx)\n",
    "\n",
    "data_loader_train=[]\n",
    "data_loader_test=[]\n",
    "\n",
    "# ## Create dataloaders\n",
    "# Get subset\n",
    "torch.manual_seed(10)\n",
    "TotalSetTrain=list(range(len(dataSetTrain)))\n",
    "np.random.shuffle(TotalSetTrain)\n",
    "TotalSetTest=list(range(len(dataSetTest)))\n",
    "np.random.shuffle(TotalSetTest)\n",
    "\n",
    "train=[]\n",
    "test=[]\n",
    "for epoch in epoch:\n",
    "    \n",
    "    Kfifth = len(dataSetTrain)//k\n",
    "    split= epoch%k\n",
    "    train.append(TotalSetTrain[(split+1)*Kfifth:]+TotalSetTrain[:Kfifth*split])\n",
    "    test.append(TotalSetTest[split*Kfifth:(split+1)*Kfifth])\n",
    "\n",
    "#dataset_train = torch.utils.data.Subset(dataSetTrain, indices[-noTrain:])\n",
    "\n",
    "#dataset_test = torch.utils.data.Subset(dataSetTest, indices[:-noTrain])\n",
    "#len(indices), len(indices[:-50]), len(indices[-50:]), 50/191, type(dataset_test)\n",
    "\n",
    "dataset_sizes = {'train': len(train[0]), 'val': len(test[0])}\n",
    "\n",
    "#dataset_train = torch.utils.data.Subset(dataSetTrain, train)\n",
    "#data_loader_train.append(dataset_train)\n",
    "#dataset_testo = torch.utils.data.Subset(dataSetTest, test)\n",
    "#data_loader_test.append(dataset_testo)\n",
    "# define training and validation data loaders\n",
    "\n",
    "\n",
    "# Collate function (gathers together the outputs)\n",
    "# def collate_fn(batch):\n",
    "#     return tuple(zip(*batch))\n",
    "\n",
    "#len(indices[-noTrain:]), dataset_sizes\n",
    "#dataset_test[0][1], dataset_test[3][1], dataset_test[-1][1], dataSetTrain.imgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/99\n",
      "----------\n",
      "train Loss: 0.6656 Acc: 0.6682\n",
      "val Loss: 1.4379 Acc: 0.5159\n",
      "\n",
      "Epoch 1/99\n",
      "----------\n",
      "train Loss: 0.4830 Acc: 0.7660\n",
      "val Loss: 1.1299 Acc: 0.5212\n",
      "\n",
      "Epoch 2/99\n",
      "----------\n",
      "train Loss: 0.4724 Acc: 0.7718\n",
      "val Loss: 0.7595 Acc: 0.5393\n",
      "\n",
      "Epoch 3/99\n",
      "----------\n",
      "train Loss: 0.4584 Acc: 0.7805\n",
      "val Loss: 0.5822 Acc: 0.7268\n",
      "\n",
      "Epoch 4/99\n",
      "----------\n",
      "train Loss: 0.4496 Acc: 0.7851\n",
      "val Loss: 0.9460 Acc: 0.5842\n",
      "\n",
      "Epoch 5/99\n",
      "----------\n",
      "train Loss: 0.4379 Acc: 0.7960\n",
      "val Loss: 0.4516 Acc: 0.7961\n",
      "\n",
      "Epoch 6/99\n",
      "----------\n",
      "train Loss: 0.4263 Acc: 0.7950\n",
      "val Loss: 0.5349 Acc: 0.7739\n",
      "\n",
      "Epoch 7/99\n",
      "----------\n",
      "train Loss: 0.4114 Acc: 0.8066\n",
      "val Loss: 0.7542 Acc: 0.6000\n",
      "\n",
      "Epoch 8/99\n",
      "----------\n",
      "train Loss: 0.4057 Acc: 0.8081\n",
      "val Loss: 0.4039 Acc: 0.8062\n",
      "\n",
      "Epoch 9/99\n",
      "----------\n",
      "train Loss: 0.4032 Acc: 0.8090\n",
      "val Loss: 0.3979 Acc: 0.8155\n",
      "\n",
      "Epoch 10/99\n",
      "----------\n",
      "train Loss: 0.4002 Acc: 0.8113\n",
      "val Loss: 0.4708 Acc: 0.7427\n",
      "\n",
      "Epoch 11/99\n",
      "----------\n",
      "train Loss: 0.3934 Acc: 0.8152\n",
      "val Loss: 0.4227 Acc: 0.8120\n",
      "\n",
      "Epoch 12/99\n",
      "----------\n",
      "train Loss: 0.3937 Acc: 0.8158\n",
      "val Loss: 0.3955 Acc: 0.8086\n",
      "\n",
      "Epoch 13/99\n",
      "----------\n",
      "train Loss: 0.3970 Acc: 0.8146\n",
      "val Loss: 0.8194 Acc: 0.5890\n",
      "\n",
      "Epoch 14/99\n",
      "----------\n",
      "train Loss: 0.3930 Acc: 0.8150\n",
      "val Loss: 0.3913 Acc: 0.8191\n",
      "\n",
      "Epoch 15/99\n",
      "----------\n",
      "train Loss: 0.3885 Acc: 0.8167\n",
      "val Loss: 0.3994 Acc: 0.8039\n",
      "\n",
      "Epoch 16/99\n",
      "----------\n",
      "train Loss: 0.3859 Acc: 0.8175\n",
      "val Loss: 0.4018 Acc: 0.8171\n",
      "\n",
      "Epoch 17/99\n",
      "----------\n",
      "train Loss: 0.3901 Acc: 0.8183\n",
      "val Loss: 0.3910 Acc: 0.8154\n",
      "\n",
      "Epoch 18/99\n",
      "----------\n",
      "train Loss: 0.3906 Acc: 0.8165\n",
      "val Loss: 0.3747 Acc: 0.8258\n",
      "\n",
      "Epoch 19/99\n",
      "----------\n",
      "train Loss: 0.3893 Acc: 0.8188\n",
      "val Loss: 0.3903 Acc: 0.8189\n",
      "\n",
      "Epoch 20/99\n",
      "----------\n",
      "train Loss: 0.3859 Acc: 0.8190\n",
      "val Loss: 0.3757 Acc: 0.8242\n",
      "\n",
      "Epoch 21/99\n",
      "----------\n",
      "train Loss: 0.3843 Acc: 0.8192\n",
      "val Loss: 0.5555 Acc: 0.6961\n",
      "\n",
      "Epoch 22/99\n",
      "----------\n",
      "train Loss: 0.3897 Acc: 0.8160\n",
      "val Loss: 0.3971 Acc: 0.8037\n",
      "\n",
      "Epoch 23/99\n",
      "----------\n",
      "train Loss: 0.3875 Acc: 0.8185\n",
      "val Loss: 0.3745 Acc: 0.8261\n",
      "\n",
      "Epoch 24/99\n",
      "----------\n",
      "train Loss: 0.3911 Acc: 0.8158\n",
      "val Loss: 0.3979 Acc: 0.8082\n",
      "\n",
      "Epoch 25/99\n",
      "----------\n",
      "train Loss: 0.3894 Acc: 0.8182\n",
      "val Loss: 0.3790 Acc: 0.8226\n",
      "\n",
      "Epoch 26/99\n",
      "----------\n",
      "train Loss: 0.3854 Acc: 0.8201\n",
      "val Loss: 0.4006 Acc: 0.8154\n",
      "\n",
      "Epoch 27/99\n",
      "----------\n",
      "train Loss: 0.3894 Acc: 0.8163\n",
      "val Loss: 0.3913 Acc: 0.8173\n",
      "\n",
      "Epoch 28/99\n",
      "----------\n",
      "train Loss: 0.3888 Acc: 0.8169\n",
      "val Loss: 0.3746 Acc: 0.8252\n",
      "\n",
      "Epoch 29/99\n",
      "----------\n",
      "train Loss: 0.3895 Acc: 0.8186\n",
      "val Loss: 0.3909 Acc: 0.8188\n",
      "\n",
      "Epoch 30/99\n",
      "----------\n",
      "train Loss: 0.3865 Acc: 0.8196\n",
      "val Loss: 0.3770 Acc: 0.8237\n",
      "\n",
      "Epoch 31/99\n",
      "----------\n",
      "train Loss: 0.3896 Acc: 0.8175\n",
      "val Loss: 0.3990 Acc: 0.8142\n",
      "\n",
      "Epoch 32/99\n",
      "----------\n",
      "train Loss: 0.3887 Acc: 0.8173\n",
      "val Loss: 0.3948 Acc: 0.8066\n",
      "\n",
      "Epoch 33/99\n",
      "----------\n",
      "train Loss: 0.3894 Acc: 0.8177\n",
      "val Loss: 0.3738 Acc: 0.8292\n",
      "\n",
      "Epoch 34/99\n",
      "----------\n",
      "train Loss: 0.3883 Acc: 0.8204\n",
      "val Loss: 0.3985 Acc: 0.8082\n",
      "\n",
      "Epoch 35/99\n",
      "----------\n",
      "train Loss: 0.3873 Acc: 0.8169\n",
      "val Loss: 0.3760 Acc: 0.8269\n",
      "\n",
      "Epoch 36/99\n",
      "----------\n",
      "train Loss: 0.3855 Acc: 0.8190\n",
      "val Loss: 0.4010 Acc: 0.8156\n",
      "\n",
      "Epoch 37/99\n",
      "----------\n",
      "train Loss: 0.3880 Acc: 0.8208\n",
      "val Loss: 0.3914 Acc: 0.8167\n",
      "\n",
      "Epoch 38/99\n",
      "----------\n",
      "train Loss: 0.3867 Acc: 0.8177\n",
      "val Loss: 0.3789 Acc: 0.8214\n",
      "\n",
      "Epoch 39/99\n",
      "----------\n",
      "train Loss: 0.3905 Acc: 0.8168\n",
      "val Loss: 0.3893 Acc: 0.8221\n",
      "\n",
      "Epoch 40/99\n",
      "----------\n",
      "train Loss: 0.3879 Acc: 0.8182\n",
      "val Loss: 0.3754 Acc: 0.8277\n",
      "\n",
      "Epoch 41/99\n",
      "----------\n",
      "train Loss: 0.3884 Acc: 0.8152\n",
      "val Loss: 0.4002 Acc: 0.8074\n",
      "\n",
      "Epoch 42/99\n",
      "----------\n",
      "train Loss: 0.3875 Acc: 0.8194\n",
      "val Loss: 0.3932 Acc: 0.8123\n",
      "\n",
      "Epoch 43/99\n",
      "----------\n",
      "train Loss: 0.3894 Acc: 0.8164\n",
      "val Loss: 0.3741 Acc: 0.8275\n",
      "\n",
      "Epoch 44/99\n",
      "----------\n",
      "train Loss: 0.3894 Acc: 0.8141\n",
      "val Loss: 0.5291 Acc: 0.7165\n",
      "\n",
      "Epoch 45/99\n",
      "----------\n",
      "train Loss: 0.3860 Acc: 0.8188\n",
      "val Loss: 0.3752 Acc: 0.8253\n",
      "\n",
      "Epoch 46/99\n",
      "----------\n",
      "train Loss: 0.3874 Acc: 0.8182\n",
      "val Loss: 0.3998 Acc: 0.8150\n",
      "\n",
      "Epoch 47/99\n",
      "----------\n",
      "train Loss: 0.3871 Acc: 0.8175\n",
      "val Loss: 0.4704 Acc: 0.7453\n",
      "\n",
      "Epoch 48/99\n",
      "----------\n",
      "train Loss: 0.3902 Acc: 0.8181\n",
      "val Loss: 0.3750 Acc: 0.8245\n",
      "\n",
      "Epoch 49/99\n",
      "----------\n",
      "train Loss: 0.3935 Acc: 0.8160\n",
      "val Loss: 0.4387 Acc: 0.7756\n",
      "\n",
      "Epoch 50/99\n",
      "----------\n",
      "train Loss: 0.3853 Acc: 0.8187\n",
      "val Loss: 0.3750 Acc: 0.8266\n",
      "\n",
      "Epoch 51/99\n",
      "----------\n",
      "train Loss: 0.3853 Acc: 0.8193\n",
      "val Loss: 0.3986 Acc: 0.8143\n",
      "\n",
      "Epoch 52/99\n",
      "----------\n",
      "train Loss: 0.3904 Acc: 0.8182\n",
      "val Loss: 0.4007 Acc: 0.8015\n",
      "\n",
      "Epoch 53/99\n",
      "----------\n",
      "train Loss: 0.3896 Acc: 0.8161\n",
      "val Loss: 0.3750 Acc: 0.8255\n",
      "\n",
      "Epoch 54/99\n",
      "----------\n",
      "train Loss: 0.3906 Acc: 0.8150\n",
      "val Loss: 0.3895 Acc: 0.8211\n",
      "\n",
      "Epoch 55/99\n",
      "----------\n",
      "train Loss: 0.3894 Acc: 0.8163\n",
      "val Loss: 0.4012 Acc: 0.7997\n",
      "\n",
      "Epoch 56/99\n",
      "----------\n",
      "train Loss: 0.3862 Acc: 0.8192\n",
      "val Loss: 0.4022 Acc: 0.8165\n",
      "\n",
      "Epoch 57/99\n",
      "----------\n",
      "train Loss: 0.3905 Acc: 0.8180\n",
      "val Loss: 0.3919 Acc: 0.8138\n",
      "\n",
      "Epoch 58/99\n",
      "----------\n",
      "train Loss: 0.3896 Acc: 0.8180\n",
      "val Loss: 0.3994 Acc: 0.8015\n",
      "\n",
      "Epoch 59/99\n",
      "----------\n",
      "train Loss: 0.3920 Acc: 0.8144\n",
      "val Loss: 0.8254 Acc: 0.4490\n",
      "\n",
      "Epoch 60/99\n",
      "----------\n",
      "train Loss: 0.3867 Acc: 0.8188\n",
      "val Loss: 0.3758 Acc: 0.8249\n",
      "\n",
      "Epoch 61/99\n",
      "----------\n",
      "train Loss: 0.3861 Acc: 0.8196\n",
      "val Loss: 0.3999 Acc: 0.8158\n",
      "\n",
      "Epoch 62/99\n",
      "----------\n",
      "train Loss: 0.3869 Acc: 0.8185\n",
      "val Loss: 0.3936 Acc: 0.8107\n",
      "\n",
      "Epoch 63/99\n",
      "----------\n",
      "train Loss: 0.3874 Acc: 0.8171\n",
      "val Loss: 0.3745 Acc: 0.8254\n",
      "\n",
      "Epoch 64/99\n",
      "----------\n",
      "train Loss: 0.3902 Acc: 0.8188\n",
      "val Loss: 0.7947 Acc: 0.5992\n",
      "\n",
      "Epoch 65/99\n",
      "----------\n",
      "train Loss: 0.3853 Acc: 0.8196\n",
      "val Loss: 0.3749 Acc: 0.8272\n",
      "\n",
      "Epoch 66/99\n",
      "----------\n",
      "train Loss: 0.3873 Acc: 0.8181\n",
      "val Loss: 0.4017 Acc: 0.8073\n",
      "\n",
      "Epoch 67/99\n",
      "----------\n",
      "train Loss: 0.3891 Acc: 0.8176\n",
      "val Loss: 0.3905 Acc: 0.8175\n",
      "\n",
      "Epoch 68/99\n",
      "----------\n",
      "train Loss: 0.3890 Acc: 0.8163\n",
      "val Loss: 0.3738 Acc: 0.8259\n",
      "\n",
      "Epoch 69/99\n",
      "----------\n",
      "train Loss: 0.3919 Acc: 0.8159\n",
      "val Loss: 0.3892 Acc: 0.8207\n",
      "\n",
      "Epoch 70/99\n",
      "----------\n",
      "train Loss: 0.3886 Acc: 0.8193\n",
      "val Loss: 0.3764 Acc: 0.8227\n",
      "\n",
      "Epoch 71/99\n",
      "----------\n",
      "train Loss: 0.3858 Acc: 0.8177\n",
      "val Loss: 0.4017 Acc: 0.8169\n",
      "\n",
      "Epoch 72/99\n",
      "----------\n",
      "train Loss: 0.3913 Acc: 0.8148\n",
      "val Loss: 0.3913 Acc: 0.8157\n",
      "\n",
      "Epoch 73/99\n",
      "----------\n",
      "train Loss: 0.3894 Acc: 0.8179\n",
      "val Loss: 0.8096 Acc: 0.5983\n",
      "\n",
      "Epoch 74/99\n",
      "----------\n",
      "train Loss: 0.3908 Acc: 0.8150\n",
      "val Loss: 0.3898 Acc: 0.8211\n",
      "\n",
      "Epoch 75/99\n",
      "----------\n",
      "train Loss: 0.3878 Acc: 0.8185\n",
      "val Loss: 0.3808 Acc: 0.8193\n",
      "\n",
      "Epoch 76/99\n",
      "----------\n",
      "train Loss: 0.3840 Acc: 0.8202\n",
      "val Loss: 0.4002 Acc: 0.8151\n",
      "\n",
      "Epoch 77/99\n",
      "----------\n",
      "train Loss: 0.3870 Acc: 0.8196\n",
      "val Loss: 0.3970 Acc: 0.8036\n",
      "\n",
      "Epoch 78/99\n",
      "----------\n",
      "train Loss: 0.3893 Acc: 0.8164\n",
      "val Loss: 0.3769 Acc: 0.8221\n",
      "\n",
      "Epoch 79/99\n",
      "----------\n",
      "train Loss: 0.3884 Acc: 0.8184\n",
      "val Loss: 0.3913 Acc: 0.8175\n",
      "\n",
      "Epoch 80/99\n",
      "----------\n",
      "train Loss: 0.3867 Acc: 0.8172\n",
      "val Loss: 0.3754 Acc: 0.8251\n",
      "\n",
      "Epoch 81/99\n",
      "----------\n",
      "train Loss: 0.3871 Acc: 0.8182\n",
      "val Loss: 0.4000 Acc: 0.8141\n",
      "\n",
      "Epoch 82/99\n",
      "----------\n",
      "train Loss: 0.3881 Acc: 0.8178\n",
      "val Loss: 0.3902 Acc: 0.8169\n",
      "\n",
      "Epoch 83/99\n",
      "----------\n",
      "train Loss: 0.3887 Acc: 0.8153\n",
      "val Loss: 0.3790 Acc: 0.8203\n",
      "\n",
      "Epoch 84/99\n",
      "----------\n",
      "train Loss: 0.3902 Acc: 0.8172\n",
      "val Loss: 0.3894 Acc: 0.8192\n",
      "\n",
      "Epoch 85/99\n",
      "----------\n",
      "train Loss: 0.3843 Acc: 0.8192\n",
      "val Loss: 0.3794 Acc: 0.8204\n",
      "\n",
      "Epoch 86/99\n",
      "----------\n",
      "train Loss: 0.3859 Acc: 0.8177\n",
      "val Loss: 0.3986 Acc: 0.8123\n",
      "\n",
      "Epoch 87/99\n",
      "----------\n",
      "train Loss: 0.3896 Acc: 0.8174\n",
      "val Loss: 0.3908 Acc: 0.8174\n",
      "\n",
      "Epoch 88/99\n",
      "----------\n",
      "train Loss: 0.3875 Acc: 0.8178\n",
      "val Loss: 0.3839 Acc: 0.8134\n",
      "\n",
      "Epoch 89/99\n",
      "----------\n",
      "train Loss: 0.3877 Acc: 0.8174\n",
      "val Loss: 0.6300 Acc: 0.6686\n",
      "\n",
      "Epoch 90/99\n",
      "----------\n",
      "train Loss: 0.3868 Acc: 0.8210\n",
      "val Loss: 0.3795 Acc: 0.8221\n",
      "\n",
      "Epoch 91/99\n",
      "----------\n",
      "train Loss: 0.3881 Acc: 0.8179\n",
      "val Loss: 0.4007 Acc: 0.8142\n",
      "\n",
      "Epoch 92/99\n",
      "----------\n",
      "train Loss: 0.3888 Acc: 0.8167\n",
      "val Loss: 0.3911 Acc: 0.8135\n",
      "\n",
      "Epoch 93/99\n",
      "----------\n",
      "train Loss: 0.3879 Acc: 0.8170\n",
      "val Loss: 0.3779 Acc: 0.8221\n",
      "\n",
      "Epoch 94/99\n",
      "----------\n",
      "train Loss: 0.3902 Acc: 0.8145\n",
      "val Loss: 0.3910 Acc: 0.8204\n",
      "\n",
      "Epoch 95/99\n",
      "----------\n",
      "train Loss: 0.3857 Acc: 0.8194\n",
      "val Loss: 0.4479 Acc: 0.7633\n",
      "\n",
      "Epoch 96/99\n",
      "----------\n",
      "train Loss: 0.3866 Acc: 0.8191\n",
      "val Loss: 0.3991 Acc: 0.8159\n",
      "\n",
      "Epoch 97/99\n",
      "----------\n",
      "train Loss: 0.3889 Acc: 0.8175\n",
      "val Loss: 0.3918 Acc: 0.8132\n",
      "\n",
      "Epoch 98/99\n",
      "----------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.3903 Acc: 0.8148\n",
      "val Loss: 0.3813 Acc: 0.8177\n",
      "\n",
      "Epoch 99/99\n",
      "----------\n",
      "train Loss: 0.3915 Acc: 0.8153\n",
      "val Loss: 0.3903 Acc: 0.8209\n",
      "\n",
      "Training complete in 86m 25s\n",
      "Best val Acc: 0.829213\n",
      "[[5567 1556]\n",
      " [ 115  819]]\n",
      "Current hyperparameters: {'learning rate': 0.2, 'gamma': 0.05, 'Momentum': 0.9, 'Model': 'model18'}\n",
      "Best hyperparameters: {'learning rate': 0.2, 'gamma': 0.05, 'Momentum': 0.9, 'Model': 'model18'}\n",
      "Best score: 0.8292132\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x504 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "class_weights= [0.924865,0.075135] #1-(#inclass/ #intotal )\n",
    "class_weights = torch.Tensor(class_weights)\n",
    "class_weights=class_weights.to(device)\n",
    "criterion = nn.CrossEntropyLoss(weight = class_weights) \n",
    "\n",
    "# Observe that all parameters are being optimized\n",
    "learning_rate=[0.05, 0.1,0.2]\n",
    "Momentum=[0.5,0.9,0.99]\n",
    "GAMMA=[0.05, 0.1, 0.5]\n",
    "#Batch_size= [16,32]#,64,128]\n",
    "models=[model18, model34, model50]\n",
    "modelnames=[\"model18\",\"model34\",\"model50\"]\n",
    "#ADD IN A THING SO IT SAVES THE TENSORBOARD TO DIFFERENT BITS\n",
    "best_params = None\n",
    "best_score=0.00\n",
    "Current_params=None\n",
    "lrnum=2\n",
    "gamnum=0\n",
    "Momnum=1\n",
    "modnum=0\n",
    "model=models[modnum]\n",
    "model = model.to(device)\n",
    "optimizer_ft = optim.SGD(model.parameters(), lr=learning_rate[lrnum], momentum=Momentum[Momnum])\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=GAMMA[gamnum])\n",
    "writer = SummaryWriter(\"Experiments/undersampledrug2-100/lr\"+str(learning_rate[lrnum])+\"momentum\"+\n",
    "        str(Momentum[Momnum])+\"gamma\"+str(GAMMA[gamnum])+\"model\"+modelnames[modnum])  \n",
    "model_ft, con_mat, current_score = train_model(model, criterion, optimizer_ft, exp_lr_scheduler,\n",
    "   train,test,num_epochs=100)\n",
    "con_mat=con_mat.cpu().numpy()\n",
    "current_score=current_score.cpu().numpy()\n",
    "Current_params= {'learning rate': learning_rate[lrnum], 'gamma': GAMMA[gamnum], \n",
    "                   'Momentum': Momentum[Momnum], 'Model': modelnames[modnum]}\n",
    "print(con_mat)\n",
    "print(\"Current hyperparameters:\", Current_params)\n",
    "df_cm_ratio = pd.DataFrame(con_mat / np.sum(con_mat, axis=1)[:, None], index=[i for i in labels],\n",
    "                     columns=[i for i in labels])\n",
    "plt.figure(figsize=(12, 7))\n",
    "sn.heatmap(df_cm_ratio, annot=True)\n",
    "if current_score > best_score:\n",
    "    best_score = current_score\n",
    "    best_params = {'learning rate': learning_rate[lrnum], 'gamma': GAMMA[gamnum], \n",
    "                   'Momentum': Momentum[Momnum], 'Model': modelnames[modnum]}\n",
    "\n",
    "print(\"Best hyperparameters:\", best_params)\n",
    "print(\"Best score:\", best_score)\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cf_matrix = confusion_matrix_calc(data_loader_test, labels, model_ft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/dash: 1: kill: No such process\r\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "!kill 8488"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-f1c78d554152de7a\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-f1c78d554152de7a\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir Experiments/undersampledrug2-100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'learning rate': 0.2, 'gamma': 0.05, 'Momentum': 0.9, 'Model': 'model18'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(0.8292132, dtype=float32)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(best_params)\n",
    "best_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model_ft.state_dict(), \"/workspace/myFile/Output/17052023/undersampling_best_model_params.pt\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
