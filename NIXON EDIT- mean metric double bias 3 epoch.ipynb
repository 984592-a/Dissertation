{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To note: Running this on different systems (i.e. local, SCW, server) will result in slight changes needing to the code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/scipy/__init__.py:138: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.4)\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion} is required for this version of \"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.pyplot._IonContext at 0x7f031a526f70>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load libraries\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import sys\n",
    "import torchvision\n",
    "import torchvision.transforms as T\n",
    "import torchvision.models as models\n",
    "from PIL import Image\n",
    "from PIL import ImageEnhance\n",
    "import matplotlib.pyplot as plt\n",
    "import imagesize\n",
    "import subprocess\n",
    "sys.path\n",
    "from IPython.core.debugger import set_trace\n",
    "import scipy.ndimage\n",
    "import matplotlib.patches as patches\n",
    "# plt.rcParams['figure.figsize'] = [12,12]\n",
    "# sys.path.append('/workspace/myFile/Mask_RCNN_Tutorial/')\n",
    "from tqdm import tqdm\n",
    "from torch import nn as nn\n",
    "from torch import optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "import re\n",
    "import time\n",
    "import copy\n",
    "import pylab\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from tempfile import TemporaryDirectory\n",
    "import torch.backends.cudnn as cudnn\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "import seaborn as sn\n",
    "import pandas as pd\n",
    "import glob\n",
    "# Rather than have a messy notebook with a load of functions we can store them in separate .py files and import them\n",
    "\n",
    "cudnn.benchmark = True\n",
    "plt.ion()   # interactive mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "writer = SummaryWriter(\"Experiments/TENSORBOARD\")    # This determines the tensorboard file name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DNADataset(object):\n",
    "    def __init__(self, root, transforms, labels, imDx = False):\n",
    "        self.root, self.transforms, self.labels = root, transforms, labels\n",
    "    \n",
    "        # load all image files, sorting them to ensure they are aligned\n",
    "        self.imgDir = glob.glob(root+\"*/*.tiff\")\n",
    "        Damagednuclei= [x for x in self.imgDir if 'Damaged_nuclei_' in x]\n",
    "        Undamagednuclei= [x for x in self.imgDir if \"No_damage_nuclei\" in x]\n",
    "        #np.random.shuffle(Undamagednuclei)\n",
    "        #Undamagednuclei=Undamagednuclei[:10000]\n",
    "        self.imgDir= Damagednuclei+Undamagednuclei\n",
    "        size80=[]\n",
    "        for x in self.imgDir:\n",
    "            img = Image.open(x) # Open image\n",
    "            w,h=img.size\n",
    "            if w<=80 and h<=80:\n",
    "                size80.append(x)\n",
    "        self.imgDir=size80              \n",
    "        \n",
    "        self.imgs = sorted(self.imgDir) # list of images\n",
    "\n",
    "        \n",
    "\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.imgs[idx]\n",
    "       \n",
    "        # Transform images into tensors\n",
    "        img = Image.open(img_path) # Open image\n",
    "        w,h=img.size\n",
    "        img = np.array(img) # Convert image into an array\n",
    "        img = np.float32(np.divide(img, 2**16)) # Ensure all values are floats\n",
    "        \n",
    "        result=np.zeros((80,80), dtype=np.float32)\n",
    "        x_center = (80 - w) // 2\n",
    "        y_center = (80 - h) // 2 # copy img image into center of result image\n",
    "        result[y_center:y_center+h, x_center:x_center+w] = img\n",
    "        img = result\n",
    "        \n",
    "        targetlab=\"\"\n",
    "        if img_path.find('No_damage_nuclei') != -1:\n",
    "            targetlab= 'Undamaged'\n",
    "        if img_path.find('Damaged_nuclei_') != -1:\n",
    "            targetlab= 'Damaged'  # Find labels corresponding to image\n",
    "        target = self.labels.index(targetlab) # Get the label and assign to a value\n",
    "        \n",
    "        # Convert label to tensor\n",
    "        #torch.to\n",
    "        \n",
    "        if self.transforms is not None:\n",
    "            img = self.transforms(img)\n",
    "#             #print('In the transforms')\n",
    "        imNo = idx\n",
    "        return img, target, imNo\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.imgs)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "root=\"/workspace/myFile/Output/17052023/\"\n",
    "p= glob.glob(root+\"*/*.tiff\")\n",
    "Damagednuclei= [x for x in p if 'Damaged_nuclei_' in x]\n",
    "Undamagednuclei= [x for x in p if \"No_damage_nuclei\" in x]\n",
    "#np.random.shuffle(Undamagednuclei)\n",
    "#Undamagednuclei=Undamagednuclei[:10000]\n",
    "#Undamagednuclei"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "imDr = \"/workspace/myFile/Output/17052023/\"  # Image patches directory\n",
    "\n",
    "labels = ['Damaged', 'Undamaged']  # Your labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For data augmentation\n",
    "def get_transform(train):\n",
    "    transforms = []\n",
    "\n",
    "    transforms.append(T.ToTensor())\n",
    "    transforms.append(T.Normalize([0.0019368887995516483], [0.00672996630111016]))\n",
    "    #transforms.append(T.RandomHorizontalFlip(0.5))\n",
    "    \n",
    "    if train:\n",
    "        transforms.append(T.RandomHorizontalFlip())\n",
    "        transforms.append(T.RandomVerticalFlip())\n",
    "    \n",
    "    return T.Compose(transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, scheduler, dataloaderTrain, dataloaderTest, num_epochs=25):\n",
    "    since = time.time()\n",
    "    # Create a temporary directory to save training checkpoints\n",
    "    with TemporaryDirectory() as tempdir:\n",
    "        best_model_params_path = os.path.join(tempdir, 'best_model_params.pt')\n",
    "\n",
    "        torch.save(model.state_dict(), best_model_params_path)\n",
    "        best_acc = 0.0\n",
    "        \n",
    "        for epoch in range(num_epochs):\n",
    "            print(f'Epoch {epoch}/{num_epochs - 1}')\n",
    "            print('-' * 10)\n",
    "\n",
    "            # Each epoch has a training and validation phase\n",
    "            for phase in ['train', 'val']:\n",
    "                if phase == 'train':\n",
    "                    model.train()  # Set model to training mode\n",
    "                    dataloaders = dataloaderTrain\n",
    "                else:\n",
    "                    model.eval()   # Set model to evaluate mode\n",
    "                    dataloaders = dataloaderTest\n",
    "\n",
    "                running_loss = 0.0\n",
    "                running_corrects = 0\n",
    "                damaged_len=0\n",
    "                damaged_corrects = 0\n",
    "                undamaged_len=0\n",
    "                undamaged_corrects = 0\n",
    "\n",
    "                # Iterate over data.\n",
    "                for inputs, labels, imNo in dataloaders:\n",
    "                    inputs = inputs.to(device)\n",
    "                    labels = labels.to(device)\n",
    "\n",
    "                    # zero the parameter gradients\n",
    "                    optimizer.zero_grad()\n",
    "\n",
    "                    # forward\n",
    "                    # track history if only in train\n",
    "                    with torch.set_grad_enabled(phase == 'train'):\n",
    "                        outputs = model(inputs)\n",
    "                        _, preds = torch.max(outputs, 1)\n",
    "                        loss = criterion(outputs, labels)\n",
    "                        # backward + optimize only if in training phase\n",
    "                        if phase == 'train':\n",
    "                            loss.backward()\n",
    "                            optimizer.step()\n",
    "\n",
    "                    # statistics\n",
    "                    running_loss += loss.item() * inputs.size(0)    # Loss\n",
    "                    nada=torch.tensor(np.zeros(len(labels))).to(device)\n",
    "                    uno=nada+1\n",
    "                    falseneg=preds+1\n",
    "                    falsepos=preds-1\n",
    "                    FPplusTN=torch.sum(labels==nada)\n",
    "                    TPplusFN=torch.sum(labels==uno)\n",
    "                    FN=torch.sum(labels==falseneg)\n",
    "                    FP=torch.sum(labels==falsepos)\n",
    "                    TN=FPplusTN-FP\n",
    "                    TP=TPplusFN-FN\n",
    "                    running_corrects += torch.sum(preds == labels.data) # Accuracy\n",
    "                    damaged_len+=TPplusFN\n",
    "                    damaged_corrects += TP\n",
    "                    undamaged_len+=FPplusTN\n",
    "                    undamaged_corrects += TN\n",
    "                damaged_acc = damaged_corrects / damaged_len\n",
    "                undamaged_acc = undamaged_corrects/undamaged_len\n",
    "                epoch_acc= (damaged_acc+undamaged_acc)/2\n",
    "                \n",
    "                if phase == 'train':\n",
    "                    scheduler.step()\n",
    "\n",
    "                epoch_loss = running_loss / dataset_sizes[phase]    # Loss metric per epoch\n",
    "                #epoch_acc = running_corrects.double() / dataset_sizes[phase]    # Accuracy metric per epoch\n",
    "\n",
    "                if phase == \"train\":    # This is the tensorboard code that writes accuracy and loss metrics\n",
    "                    writer.add_scalar(\"Train/Accuracy\", epoch_acc, epoch)\n",
    "                    writer.add_scalar(\"Train/Loss\", epoch_loss, epoch)\n",
    "                else:\n",
    "                    writer.add_scalar(\"Validation/Accuracy\", epoch_acc, epoch)\n",
    "                    writer.add_scalar(\"Validation/Loss\", epoch_loss, epoch)\n",
    "\n",
    "                print(f'{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n",
    "\n",
    "                # deep copy the model\n",
    "                if phase == 'val' and epoch_acc >= best_acc: \n",
    "                    # This compares validation accuracy to previous bests and adjusts model weights accordingly\n",
    "                    best_acc = epoch_acc\n",
    "                    torch.save(model.state_dict(), best_model_params_path)\n",
    "\n",
    "            print()\n",
    "\n",
    "        time_elapsed = time.time() - since  # Nice way to measure training time but info also stored (indirectly) by tensorboard\n",
    "        print(\n",
    "            f'Training complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')\n",
    "        print(f'Best val Acc: {best_acc:4f}')\n",
    "        labels= labels.cpu().numpy()\n",
    "        preds=preds.cpu().numpy()\n",
    "        con_mat = confusion_matrix(labels, preds)   # Confusion matrix compares true class with predicted class\n",
    "        # load best model weights\n",
    "        model.load_state_dict(torch.load(best_model_params_path))\n",
    "    writer.close()\n",
    "    return model, con_mat   # We want to return the model because its the model, also confusion matrix for later analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is your RESNET\n",
    "# Initialize CNN with kaiming\n",
    "def init_cnn(m):\n",
    "    # Set the weights of the RESNET\n",
    "    if getattr(m, 'bias', None) is not None: nn.init.constant_(m.bias, 0)\n",
    "    if isinstance(m, (nn.Conv2d,nn.Linear)): nn.init.kaiming_normal_(m.weight)\n",
    "    for l in m.children(): init_cnn(l)\n",
    "\n",
    "\n",
    "# noop function for returning nothing\n",
    "def noop(x): return x\n",
    "# activation function(RELU)\n",
    "act_fn = nn.ReLU(inplace=True)\n",
    "\n",
    "# Flatten\n",
    "class Flatten(nn.Module):\n",
    "    def forward(self, x): return x.view(x.size(0), -1)\n",
    "\n",
    "# Make a convolution\n",
    "def conv(ni, nf, ks=3, stride=1, bias=False):\n",
    "    return nn.Conv2d(ni, nf, kernel_size=ks, stride=stride, padding=ks//2, bias=bias)\n",
    "\n",
    "# Create a convuolutional layer with convolution and batch norm\n",
    "def conv_layer(ni, nf, ks=3, stride=1, zero_bn=False, act=True):\n",
    "    bn = nn.BatchNorm2d(nf) # get a 2d batch norm from Pytorhc\n",
    "    nn.init.constant_(bn.weight, 0. if zero_bn else 1.)\n",
    "    layers = [conv(ni, nf, ks, stride=stride), bn]\n",
    "    if act: layers.append(act_fn) # add in the activation function if act is true\n",
    "    return nn.Sequential(*layers)\n",
    "\n",
    "\n",
    "# Resblock\n",
    "class ResBlock(nn.Module):\n",
    "    def __init__(self, expansion, ni, nh, stride = 1):\n",
    "        super().__init__()\n",
    "        # ni - number of inputs channels, nf - number of filters\n",
    "        # nh - number of filters in first conv\n",
    "        # expansion is 1 for resnet 18, 34 and 4 for larger networks\n",
    "        nf, ni = nh*expansion, ni*expansion\n",
    "        layers = [conv_layer(ni, nh, 3, stride = stride), # for resnet < 34 2 convs per resblock\n",
    "                 conv_layer(nh, nf, 3, zero_bn = True, act = False)\n",
    "                 ] if expansion == 1 else [ # for RESNET > 34 then 3 convs per block with bottleneck\n",
    "                            conv_layer(ni, nh, 1),\n",
    "                            conv_layer(nh, nh, 3, stride = stride),\n",
    "                            conv_layer(nh, nf, 1, zero_bn = True, act = False)\n",
    "        ]\n",
    "        self.convs = nn.Sequential(*layers) # Creates the conv layers\n",
    "        self.idconv = noop if ni==nf else conv_layer(ni, nf, 1, act = False) # id convolution ()\n",
    "        self.pool = noop if stride== 1 else nn.AvgPool2d(2, ceil_mode = True) # average pool on \n",
    "        \n",
    "    def forward(self, x): \n",
    "        # Forward function adds the convolution part to the id part \n",
    "        #return act_fn(self.convs(x)) + self.idconv(self.pool(x))\n",
    "        return act_fn(self.convs(x) + self.idconv(self.pool(x)))\n",
    "\n",
    "# XResnet\n",
    "class XResNet(nn.Sequential):\n",
    "    @classmethod\n",
    "    def create(cls, expansion, layers, c_in=3, c_out=1000):\n",
    "        nfs = [c_in, (c_in + 1)*8, 64, 64] # number of filters in stem layer (c_in is number of image channels)\n",
    "        stem = [conv_layer(nfs[i], nfs[i+1], stride=2 if i==0 else 1)\n",
    "            for i in range(3)]\n",
    "\n",
    "        nfs = [64//expansion,64,128,256,512]\n",
    "        res_layers = [cls._make_layer(expansion, nfs[i], nfs[i+1],\n",
    "                                      n_blocks=l, stride=1 if i==0 else 2)\n",
    "                  for i,l in enumerate(layers)]\n",
    "        res = cls(\n",
    "        *stem,\n",
    "        nn.MaxPool2d(kernel_size=3, stride = 2, padding = 1), # then a max pooling layer\n",
    "        *res_layers,\n",
    "        nn.AdaptiveAvgPool2d(1), Flatten(), \n",
    "        nn.Linear(nfs[-1]*expansion, c_out)\n",
    "        )\n",
    "        init_cnn(res)\n",
    "        return res\n",
    "        \n",
    "    @staticmethod\n",
    "    def _make_layer(expansion, ni, nf, n_blocks, stride): # returns a resblock\n",
    "        return nn.Sequential(\n",
    "        *[ResBlock(expansion, ni if i==0 else nf, nf, stride if i==0 else 1)\n",
    "         for i in range(n_blocks)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def xresnet18 (**kwargs): return XResNet.create(1, [2, 2,  2, 2], **kwargs)\n",
    "def xresnet34 (**kwargs): return XResNet.create(1, [3, 4,  6, 3], **kwargs)\n",
    "def xresnet50 (**kwargs): return XResNet.create(4, [3, 4,  6, 3], **kwargs)\n",
    "model = xresnet18(c_in = 1, c_out = 2)\n",
    "#model = xresnet34(c_in = 1, c_out = 2)\n",
    "#model = xresnet50(c_in = 1, c_out = 2)\n",
    "model = model.to(device)\n",
    "\n",
    "# Label smoothing cross entropy\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "def reduce_loss(loss, reduction='mean'):\n",
    "    return loss.mean() if reduction=='mean' else loss.sum() if reduction=='sum' else loss\n",
    "\n",
    "class LabelSmoothingCrossEntropy(nn.Module):\n",
    "    def __init__(self, ε:float=0.1, reduction='mean'):\n",
    "        super().__init__()\n",
    "        self.ε,self.reduction = ε,reduction\n",
    "    \n",
    "    def forward(self, output, target):\n",
    "        c = output.size()[-1]\n",
    "        log_preds = F.log_softmax(output, dim=-1)\n",
    "        loss = reduce_loss(-log_preds.sum(dim=-1), self.reduction)\n",
    "        nll = F.nll_loss(log_preds, target, reduction=self.reduction)\n",
    "        return lin_comb(loss/c, nll, self.ε)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions that shows the image, true class, predicted class and degree of prediction\n",
    "\n",
    "def images_to_probs(net, images):\n",
    "    '''\n",
    "    Generates predictions and corresponding probabilities from a trained\n",
    "    network and a list of images\n",
    "    '''\n",
    "    output = net(images)\n",
    "    # convert output probabilities to predicted class\n",
    "    _, preds_tensor = torch.max(output, 1)\n",
    "    preds = np.squeeze(preds_tensor.numpy())\n",
    "    return preds, [F.softmax(el, dim=0)[i].item() for i, el in zip(preds, output)]\n",
    "\n",
    "\n",
    "def plot_classes_preds(net, images, labels):\n",
    "    '''\n",
    "    Generates matplotlib Figure using a trained network, along with images\n",
    "    and labels from a batch, that shows the network's top prediction along\n",
    "    with its probability, alongside the actual label, coloring this\n",
    "    information based on whether the prediction was correct or not.\n",
    "    Uses the \"images_to_probs\" function.\n",
    "    '''\n",
    "    preds, probs = images_to_probs(net, images)\n",
    "    # plot the images in the batch, along with predicted and true labels\n",
    "    fig = plt.figure(figsize=(12, 48))\n",
    "    for idx in np.arange(4):\n",
    "        ax = fig.add_subplot(1, 4, idx+1, xticks=[], yticks=[])\n",
    "        matplotlib_imshow(images[idx], one_channel=True)\n",
    "        ax.set_title(\"{0}, {1:.1f}%\\n(label: {2})\".format(\n",
    "            labels[preds[idx]],\n",
    "            probs[idx] * 100.0,\n",
    "            labels[labels[idx]]),\n",
    "                    color=(\"green\" if preds[idx]==labels[idx].item() else \"red\"))\n",
    "    return fig\n",
    "\n",
    "def matplotlib_imshow(img, one_channel=True):\n",
    "    if one_channel:\n",
    "        img = img.mean(dim=0)\n",
    "    img = img / 2 + 0.5     # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    if one_channel:\n",
    "        plt.imshow(npimg, cmap=\"Greys\")\n",
    "    else:\n",
    "        plt.imshow(np.transpose(npimg, (1, 2, 0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def confusion_matrix_calc(data_loader_test, classes, model_ft):       \n",
    "        y_pred = []\n",
    "        y_true = []\n",
    "        for inputs, labels, imNo in data_loader_test:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "                output = model_ft(inputs) # Feed Network\n",
    "\n",
    "                output = (torch.max(torch.exp(output), 1)[1]).data.cpu().numpy()\n",
    "                y_pred.extend(output) # Save Prediction\n",
    "                \n",
    "                labels = labels.data.cpu().numpy()\n",
    "                y_true.extend(labels) # Save Truth\n",
    "\n",
    "        # constant for classes\n",
    "        # classes = ('Alive', 'Dead')\n",
    "\n",
    "        # Build confusion matrix\n",
    "        cf_matrix = confusion_matrix(y_true, y_pred)\n",
    "        return cf_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(92178, {'train': 92178, 'val': 39505})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(10)\n",
    "imIdx = torch.randperm(101106).tolist()\n",
    "\n",
    "## Create dataset\n",
    "dataSetTrain = DNADataset(imDr, get_transform(train = True), labels, imDx=imIdx)\n",
    "dataSetTest = DNADataset(imDr, get_transform(train = False), labels, imDx=imIdx)\n",
    "\n",
    "# ## Create dataloaders\n",
    "# Get subset\n",
    "torch.manual_seed(10)\n",
    "indices = torch.randperm(len(dataSetTrain)).tolist()\n",
    "\n",
    "noTrain = int(len(dataSetTrain)*0.7)\n",
    "\n",
    "dataset_train = torch.utils.data.Subset(dataSetTrain, indices[-noTrain:])\n",
    "\n",
    "dataset_test = torch.utils.data.Subset(dataSetTest, indices[:-noTrain])\n",
    "#len(indices), len(indices[:-50]), len(indices[-50:]), 50/191, type(dataset_test)\n",
    "\n",
    "dataset_sizes = {'train': len(dataset_train), 'val': len(dataset_test)}\n",
    "\n",
    "# define training and validation data loaders\n",
    "data_loader_train = torch.utils.data.DataLoader(\n",
    "    dataset_train, batch_size=24, shuffle=True, num_workers=0)\n",
    "\n",
    "data_loader_test = torch.utils.data.DataLoader(\n",
    "    dataset_test, batch_size=24, shuffle=False, num_workers=0)\n",
    "\n",
    "# Collate function (gathers together the outputs)\n",
    "# def collate_fn(batch):\n",
    "#     return tuple(zip(*batch))\n",
    "\n",
    "len(indices[-noTrain:]), dataset_sizes\n",
    "#dataset_test[0][1], dataset_test[3][1], dataset_test[-1][1], dataSetTrain.imgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_weights= [1.84972,0.075135] #1-(#inclass/ #intotal )\n",
    "class_weights = torch.Tensor(class_weights)\n",
    "class_weights=class_weights.to(device)\n",
    "criterion = nn.CrossEntropyLoss(weight = class_weights) \n",
    "\n",
    "# Observe that all parameters are being optimized\n",
    "optimizer_ft = optim.Adam(model.parameters(), weight_decay=1e-2) # standard ADAM optimiser\n",
    "\n",
    "# Decay LR by a factor of 0.1 every 7 epochs\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/2\n",
      "----------\n",
      "train Loss: 0.5357 Acc: 0.7364\n",
      "val Loss: 0.4733 Acc: 0.7726\n",
      "\n",
      "Epoch 1/2\n",
      "----------\n",
      "train Loss: 0.4862 Acc: 0.7735\n",
      "val Loss: 0.4851 Acc: 0.7931\n",
      "\n",
      "Epoch 2/2\n",
      "----------\n",
      "train Loss: 0.4796 Acc: 0.7756\n",
      "val Loss: 0.5010 Acc: 0.7757\n",
      "\n",
      "Training complete in 14m 8s\n",
      "Best val Acc: 0.793059\n"
     ]
    }
   ],
   "source": [
    "model_ft, con_mat = train_model(model, criterion, optimizer_ft, exp_lr_scheduler,\n",
    "                       data_loader_train,data_loader_test,num_epochs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "cf_matrix = confusion_matrix_calc(data_loader_test, labels, model_ft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x504 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_cm_ratio = pd.DataFrame(cf_matrix / np.sum(cf_matrix, axis=1)[:, None], index=[i for i in labels],\n",
    "                     columns=[i for i in labels])\n",
    "plt.figure(figsize=(12, 7))\n",
    "sn.heatmap(df_cm_ratio, annot=True)\n",
    "# plt.save(\"Confusion_matrix_ratio.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x504 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_cm_raw = pd.DataFrame(cf_matrix, index=[i for i in labels],\n",
    "                     columns=[i for i in labels])\n",
    "plt.figure(figsize=(12, 7))\n",
    "sn.heatmap(df_cm_raw, annot=True)\n",
    "# plt.save(\"Confusion_matrix_raw.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2289,   703],\n",
       "       [ 6533, 29980]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cf_matrix"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
