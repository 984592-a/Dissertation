{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To note: Running this on different systems (i.e. local, SCW, server) will result in slight changes needing to the code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/scipy/__init__.py:138: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.4)\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion} is required for this version of \"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.pyplot._IonContext at 0x7f4d8c5d1d60>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load libraries\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import sys\n",
    "import torchvision\n",
    "import torchvision.transforms as T\n",
    "import torchvision.models as models\n",
    "from PIL import Image\n",
    "from PIL import ImageEnhance\n",
    "import matplotlib.pyplot as plt\n",
    "import imagesize\n",
    "import subprocess\n",
    "sys.path\n",
    "from IPython.core.debugger import set_trace\n",
    "import scipy.ndimage\n",
    "import matplotlib.patches as patches\n",
    "# plt.rcParams['figure.figsize'] = [12,12]\n",
    "# sys.path.append('/workspace/myFile/Mask_RCNN_Tutorial/')\n",
    "from tqdm import tqdm\n",
    "from torch import nn as nn\n",
    "from torch import optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "import re\n",
    "import time\n",
    "import copy\n",
    "import pylab\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from tempfile import TemporaryDirectory\n",
    "import torch.backends.cudnn as cudnn\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "import seaborn as sn\n",
    "import pandas as pd\n",
    "import glob\n",
    "# Rather than have a messy notebook with a load of functions we can store them in separate .py files and import them\n",
    "\n",
    "cudnn.benchmark = True\n",
    "plt.ion()   # interactive mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "writer = SummaryWriter(\"Experiments/TENSORBOARD\")    # This determines the tensorboard file name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DNADataset(object):\n",
    "    def __init__(self, root, transforms, labels, imDx = False):\n",
    "        self.root, self.transforms, self.labels = root, transforms, labels\n",
    "    \n",
    "        # load all image files, sorting them to ensure they are aligned\n",
    "        self.imgDir = glob.glob(root+\"*/*.tiff\")\n",
    "        self.imgDir= [x for x in self.imgDir if \"nuclei\"  in x]\n",
    "        size80=[]\n",
    "        for x in self.imgDir:\n",
    "            img = Image.open(x) # Open image\n",
    "            w,h=img.size\n",
    "            if w<=80 and h<=80:\n",
    "                size80.append(x)\n",
    "        self.imgDir=size80            \n",
    "        \n",
    "        self.imgs = sorted(self.imgDir) # list of images\n",
    "\n",
    "        \n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.imgs[idx]\n",
    "       \n",
    "        # Transform images into tensors\n",
    "        img = Image.open(img_path) # Open image\n",
    "        w,h=img.size\n",
    "        img = np.array(img) # Convert image into an array\n",
    "        img = np.float32(np.divide(img, 2**16)) # Ensure all values are floats\n",
    "        \n",
    "        result=np.zeros((80,80), dtype=np.float32)\n",
    "        x_center = (80 - w) // 2\n",
    "        y_center = (80 - h) // 2 # copy img image into center of result image\n",
    "        result[y_center:y_center+h, x_center:x_center+w] = img\n",
    "        img = result\n",
    "        \n",
    "        targetlab=\"\"\n",
    "        if img_path.find('No_damage_nuclei') != -1:\n",
    "            targetlab= 'Undamaged'\n",
    "        if img_path.find('Damaged_nuclei_') != -1:\n",
    "            targetlab= 'Damaged'  # Find labels corresponding to image\n",
    "        target = self.labels.index(targetlab) # Get the label and assign to a value\n",
    "        \n",
    "        # Convert label to tensor\n",
    "        #torch.to\n",
    "        \n",
    "        if self.transforms is not None:\n",
    "            img = self.transforms(img)\n",
    "#             #print('In the transforms')\n",
    "        imNo = idx\n",
    "        return img, target, imNo\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.imgs)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "imDr = \"/workspace/myFile/Output/17052023/\"  # Image patches directory\n",
    "\n",
    "labels = ['Damaged', 'Undamaged']  # Your labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For data augmentation\n",
    "def get_transform(train):\n",
    "    transforms = []\n",
    "\n",
    "    transforms.append(T.ToTensor())\n",
    "    transforms.append(T.Normalize([0.0019368887995516483], [0.00672996630111016]))\n",
    "    #transforms.append(T.RandomHorizontalFlip(0.5))\n",
    "    \n",
    "    if train:\n",
    "        transforms.append(T.RandomHorizontalFlip())\n",
    "        transforms.append(T.RandomVerticalFlip())\n",
    "    \n",
    "    return T.Compose(transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, scheduler, dataloaderTrain, dataloaderTest, num_epochs=25):\n",
    "    since = time.time()\n",
    "    # Create a temporary directory to save training checkpoints\n",
    "    with TemporaryDirectory() as tempdir:\n",
    "        best_model_params_path = os.path.join(tempdir, 'best_model_params.pt')\n",
    "\n",
    "        torch.save(model.state_dict(), best_model_params_path)\n",
    "        best_acc = 0.0\n",
    "\n",
    "        for epoch in range(num_epochs):\n",
    "            print(f'Epoch {epoch}/{num_epochs - 1}')\n",
    "            print('-' * 10)\n",
    "\n",
    "            # Each epoch has a training and validation phase\n",
    "            for phase in ['train', 'val']:\n",
    "                if phase == 'train':\n",
    "                    model.train()  # Set model to training mode\n",
    "                    dataloaders = dataloaderTrain\n",
    "                else:\n",
    "                    model.eval()   # Set model to evaluate mode\n",
    "                    dataloaders = dataloaderTest\n",
    "\n",
    "                running_loss = 0.0\n",
    "                running_corrects = 0\n",
    "\n",
    "                # Iterate over data.\n",
    "                for inputs, labels, imNo in dataloaders:\n",
    "                    inputs = inputs.to(device)\n",
    "                    labels = labels.to(device)\n",
    "\n",
    "                    # zero the parameter gradients\n",
    "                    optimizer.zero_grad()\n",
    "\n",
    "                    # forward\n",
    "                    # track history if only in train\n",
    "                    with torch.set_grad_enabled(phase == 'train'):\n",
    "                        outputs = model(inputs)\n",
    "                        _, preds = torch.max(outputs, 1)\n",
    "                        loss = criterion(outputs, labels)\n",
    "                        # backward + optimize only if in training phase\n",
    "                        if phase == 'train':\n",
    "                            loss.backward()\n",
    "                            optimizer.step()\n",
    "\n",
    "                    # statistics\n",
    "                    running_loss += loss.item() * inputs.size(0)    # Loss\n",
    "                    running_corrects += torch.sum(preds == labels.data) # Accuracy\n",
    "\n",
    "                if phase == 'train':\n",
    "                    scheduler.step()\n",
    "\n",
    "                epoch_loss = running_loss / dataset_sizes[phase]    # Loss metric per epoch\n",
    "                epoch_acc = running_corrects.double() / dataset_sizes[phase]    # Accuracy metric per epoch\n",
    "\n",
    "                if phase == \"train\":    # This is the tensorboard code that writes accuracy and loss metrics\n",
    "                    writer.add_scalar(\"Train/Accuracy\", epoch_acc, epoch)\n",
    "                    writer.add_scalar(\"Train/Loss\", epoch_loss, epoch)\n",
    "                else:\n",
    "                    writer.add_scalar(\"Validation/Accuracy\", epoch_acc, epoch)\n",
    "                    writer.add_scalar(\"Validation/Loss\", epoch_loss, epoch)\n",
    "\n",
    "                print(f'{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n",
    "\n",
    "                # deep copy the model\n",
    "                if phase == 'val' and epoch_acc > best_acc: \n",
    "                    # This compares validation accuracy to previous bests and adjusts model weights accordingly\n",
    "                    best_acc = epoch_acc\n",
    "                    torch.save(model.state_dict(), best_model_params_path)\n",
    "\n",
    "            print()\n",
    "\n",
    "        time_elapsed = time.time() - since  # Nice way to measure training time but info also stored (indirectly) by tensorboard\n",
    "        print(\n",
    "            f'Training complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')\n",
    "        print(f'Best val Acc: {best_acc:4f}')\n",
    "        labels= labels.cpu().numpy()\n",
    "        preds=preds.cpu().numpy()\n",
    "        con_mat = confusion_matrix(labels, preds)   # Confusion matrix compares true class with predicted class\n",
    "        # load best model weights\n",
    "        model.load_state_dict(torch.load(best_model_params_path))\n",
    "    writer.close()\n",
    "    return model, con_mat   # We want to return the model because its the model, also confusion matrix for later analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is your RESNET\n",
    "# Initialize CNN with kaiming\n",
    "def init_cnn(m):\n",
    "    # Set the weights of the RESNET\n",
    "    if getattr(m, 'bias', None) is not None: nn.init.constant_(m.bias, 0)\n",
    "    if isinstance(m, (nn.Conv2d,nn.Linear)): nn.init.kaiming_normal_(m.weight)\n",
    "    for l in m.children(): init_cnn(l)\n",
    "\n",
    "\n",
    "# noop function for returning nothing\n",
    "def noop(x): return x\n",
    "# activation function(RELU)\n",
    "act_fn = nn.ReLU(inplace=True)\n",
    "\n",
    "# Flatten\n",
    "class Flatten(nn.Module):\n",
    "    def forward(self, x): return x.view(x.size(0), -1)\n",
    "\n",
    "# Make a convolution\n",
    "def conv(ni, nf, ks=3, stride=1, bias=False):\n",
    "    return nn.Conv2d(ni, nf, kernel_size=ks, stride=stride, padding=ks//2, bias=bias)\n",
    "\n",
    "# Create a convuolutional layer with convolution and batch norm\n",
    "def conv_layer(ni, nf, ks=3, stride=1, zero_bn=False, act=True):\n",
    "    bn = nn.BatchNorm2d(nf) # get a 2d batch norm from Pytorhc\n",
    "    nn.init.constant_(bn.weight, 0. if zero_bn else 1.)\n",
    "    layers = [conv(ni, nf, ks, stride=stride), bn]\n",
    "    if act: layers.append(act_fn) # add in the activation function if act is true\n",
    "    return nn.Sequential(*layers)\n",
    "\n",
    "\n",
    "# Resblock\n",
    "class ResBlock(nn.Module):\n",
    "    def __init__(self, expansion, ni, nh, stride = 1):\n",
    "        super().__init__()\n",
    "        # ni - number of inputs channels, nf - number of filters\n",
    "        # nh - number of filters in first conv\n",
    "        # expansion is 1 for resnet 18, 34 and 4 for larger networks\n",
    "        nf, ni = nh*expansion, ni*expansion\n",
    "        layers = [conv_layer(ni, nh, 3, stride = stride), # for resnet < 34 2 convs per resblock\n",
    "                 conv_layer(nh, nf, 3, zero_bn = True, act = False)\n",
    "                 ] if expansion == 1 else [ # for RESNET > 34 then 3 convs per block with bottleneck\n",
    "                            conv_layer(ni, nh, 1),\n",
    "                            conv_layer(nh, nh, 3, stride = stride),\n",
    "                            conv_layer(nh, nf, 1, zero_bn = True, act = False)\n",
    "        ]\n",
    "        self.convs = nn.Sequential(*layers) # Creates the conv layers\n",
    "        self.idconv = noop if ni==nf else conv_layer(ni, nf, 1, act = False) # id convolution ()\n",
    "        self.pool = noop if stride== 1 else nn.AvgPool2d(2, ceil_mode = True) # average pool on \n",
    "        \n",
    "    def forward(self, x): \n",
    "        # Forward function adds the convolution part to the id part \n",
    "        #return act_fn(self.convs(x)) + self.idconv(self.pool(x))\n",
    "        return act_fn(self.convs(x) + self.idconv(self.pool(x)))\n",
    "\n",
    "# XResnet\n",
    "class XResNet(nn.Sequential):\n",
    "    @classmethod\n",
    "    def create(cls, expansion, layers, c_in=3, c_out=1000):\n",
    "        nfs = [c_in, (c_in + 1)*8, 64, 64] # number of filters in stem layer (c_in is number of image channels)\n",
    "        stem = [conv_layer(nfs[i], nfs[i+1], stride=2 if i==0 else 1)\n",
    "            for i in range(3)]\n",
    "\n",
    "        nfs = [64//expansion,64,128,256,512]\n",
    "        res_layers = [cls._make_layer(expansion, nfs[i], nfs[i+1],\n",
    "                                      n_blocks=l, stride=1 if i==0 else 2)\n",
    "                  for i,l in enumerate(layers)]\n",
    "        res = cls(\n",
    "        *stem,\n",
    "        nn.MaxPool2d(kernel_size=3, stride = 2, padding = 1), # then a max pooling layer\n",
    "        *res_layers,\n",
    "        nn.AdaptiveAvgPool2d(1), Flatten(), \n",
    "        nn.Linear(nfs[-1]*expansion, c_out)\n",
    "        )\n",
    "        init_cnn(res)\n",
    "        return res\n",
    "        \n",
    "    @staticmethod\n",
    "    def _make_layer(expansion, ni, nf, n_blocks, stride): # returns a resblock\n",
    "        return nn.Sequential(\n",
    "        *[ResBlock(expansion, ni if i==0 else nf, nf, stride if i==0 else 1)\n",
    "         for i in range(n_blocks)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def xresnet18 (**kwargs): return XResNet.create(1, [2, 2,  2, 2], **kwargs)\n",
    "def xresnet34 (**kwargs): return XResNet.create(1, [3, 4,  6, 3], **kwargs)\n",
    "def xresnet50 (**kwargs): return XResNet.create(4, [3, 4,  6, 3], **kwargs)\n",
    "model = xresnet18(c_in = 1, c_out = 2)\n",
    "#model = xresnet34(c_in = 1, c_out = 2)\n",
    "#model = xresnet50(c_in = 1, c_out = 2)\n",
    "model = model.to(device)\n",
    "\n",
    "# Label smoothing cross entropy\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "def reduce_loss(loss, reduction='mean'):\n",
    "    return loss.mean() if reduction=='mean' else loss.sum() if reduction=='sum' else loss\n",
    "\n",
    "class LabelSmoothingCrossEntropy(nn.Module):\n",
    "    def __init__(self, ε:float=0.1, reduction='mean'):\n",
    "        super().__init__()\n",
    "        self.ε,self.reduction = ε,reduction\n",
    "    \n",
    "    def forward(self, output, target):\n",
    "        c = output.size()[-1]\n",
    "        log_preds = F.log_softmax(output, dim=-1)\n",
    "        loss = reduce_loss(-log_preds.sum(dim=-1), self.reduction)\n",
    "        nll = F.nll_loss(log_preds, target, reduction=self.reduction)\n",
    "        return lin_comb(loss/c, nll, self.ε)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions that shows the image, true class, predicted class and degree of prediction\n",
    "\n",
    "def images_to_probs(net, images):\n",
    "    '''\n",
    "    Generates predictions and corresponding probabilities from a trained\n",
    "    network and a list of images\n",
    "    '''\n",
    "    output = net(images)\n",
    "    # convert output probabilities to predicted class\n",
    "    _, preds_tensor = torch.max(output, 1)\n",
    "    preds = np.squeeze(preds_tensor.numpy())\n",
    "    return preds, [F.softmax(el, dim=0)[i].item() for i, el in zip(preds, output)]\n",
    "\n",
    "\n",
    "def plot_classes_preds(net, images, labels):\n",
    "    '''\n",
    "    Generates matplotlib Figure using a trained network, along with images\n",
    "    and labels from a batch, that shows the network's top prediction along\n",
    "    with its probability, alongside the actual label, coloring this\n",
    "    information based on whether the prediction was correct or not.\n",
    "    Uses the \"images_to_probs\" function.\n",
    "    '''\n",
    "    preds, probs = images_to_probs(net, images)\n",
    "    # plot the images in the batch, along with predicted and true labels\n",
    "    fig = plt.figure(figsize=(12, 48))\n",
    "    for idx in np.arange(4):\n",
    "        ax = fig.add_subplot(1, 4, idx+1, xticks=[], yticks=[])\n",
    "        matplotlib_imshow(images[idx], one_channel=True)\n",
    "        ax.set_title(\"{0}, {1:.1f}%\\n(label: {2})\".format(\n",
    "            labels[preds[idx]],\n",
    "            probs[idx] * 100.0,\n",
    "            labels[labels[idx]]),\n",
    "                    color=(\"green\" if preds[idx]==labels[idx].item() else \"red\"))\n",
    "    return fig\n",
    "\n",
    "def matplotlib_imshow(img, one_channel=True):\n",
    "    if one_channel:\n",
    "        img = img.mean(dim=0)\n",
    "    img = img / 2 + 0.5     # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    if one_channel:\n",
    "        plt.imshow(npimg, cmap=\"Greys\")\n",
    "    else:\n",
    "        plt.imshow(np.transpose(npimg, (1, 2, 0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def confusion_matrix_calc(data_loader_test, classes, model_ft):       \n",
    "        y_pred = []\n",
    "        y_true = []\n",
    "        for inputs, labels, imNo in data_loader_test:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "                output = model_ft(inputs) # Feed Network\n",
    "\n",
    "                output = (torch.max(torch.exp(output), 1)[1]).data.cpu().numpy()\n",
    "                y_pred.extend(output) # Save Prediction\n",
    "                \n",
    "                labels = labels.data.cpu().numpy()\n",
    "                y_true.extend(labels) # Save Truth\n",
    "\n",
    "        # constant for classes\n",
    "        # classes = ('Alive', 'Dead')\n",
    "\n",
    "        # Build confusion matrix\n",
    "        cf_matrix = confusion_matrix(y_true, y_pred)\n",
    "        return cf_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(92178, {'train': 92178, 'val': 39505})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(10)\n",
    "imIdx = torch.randperm(101106).tolist()\n",
    "\n",
    "## Create dataset\n",
    "dataSetTrain = DNADataset(imDr, get_transform(train = True), labels, imDx=imIdx)\n",
    "dataSetTest = DNADataset(imDr, get_transform(train = False), labels, imDx=imIdx)\n",
    "\n",
    "# ## Create dataloaders\n",
    "# Get subset\n",
    "torch.manual_seed(10)\n",
    "indices = torch.randperm(len(dataSetTrain)).tolist()\n",
    "\n",
    "noTrain = int(len(dataSetTrain)*0.7)\n",
    "\n",
    "dataset_train = torch.utils.data.Subset(dataSetTrain, indices[-noTrain:])\n",
    "dataset_test = torch.utils.data.Subset(dataSetTest, indices[:-noTrain])\n",
    "#len(indices), len(indices[:-50]), len(indices[-50:]), 50/191, type(dataset_test)\n",
    "\n",
    "dataset_sizes = {'train': len(dataset_train), 'val': len(dataset_test)}\n",
    "\n",
    "# define training and validation data loaders\n",
    "data_loader_train = torch.utils.data.DataLoader(\n",
    "    dataset_train, batch_size=20, shuffle=True, num_workers=0)\n",
    "\n",
    "data_loader_test = torch.utils.data.DataLoader(\n",
    "    dataset_test, batch_size=1, shuffle=False, num_workers=0)\n",
    "\n",
    "\n",
    "# Collate function (gathers together the outputs)\n",
    "# def collate_fn(batch):\n",
    "#     return tuple(zip(*batch))\n",
    "\n",
    "len(indices[-noTrain:]), dataset_sizes\n",
    "#dataset_test[0][1], dataset_test[3][1], dataset_test[-1][1], dataSetTrain.imgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Observe that all parameters are being optimized\n",
    "optimizer_ft = optim.Adam(model.parameters(), weight_decay=1e-2) # standard ADAM optimiser\n",
    "\n",
    "# Decay LR by a factor of 0.1 every 7 epochs\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/2\n",
      "----------\n",
      "train Loss: 0.2135 Acc: 0.9251\n",
      "val Loss: 0.2087 Acc: 0.9243\n",
      "\n",
      "Epoch 1/2\n",
      "----------\n",
      "train Loss: 0.2128 Acc: 0.9251\n",
      "val Loss: 0.2101 Acc: 0.9243\n",
      "\n",
      "Epoch 2/2\n",
      "----------\n",
      "train Loss: 0.2115 Acc: 0.9253\n",
      "val Loss: 0.2090 Acc: 0.9243\n",
      "\n",
      "Training complete in 25m 55s\n",
      "Best val Acc: 0.924263\n"
     ]
    }
   ],
   "source": [
    "model_ft, con_mat = train_model(model, criterion, optimizer_ft, exp_lr_scheduler,\n",
    "                       data_loader_train,data_loader_test,num_epochs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "cf_matrix = confusion_matrix_calc(data_loader_test, labels, model_ft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAoIAAAGfCAYAAADLULPNAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAAgHElEQVR4nO3debRkd1Uv8O/uTkKQIYgBhSSQBMIzkTGEAOLDIFNAIPEBIZDg8Hi2KCiigrDkGUDkgS5xgUy2iqCCgC6VqGFwYFTB7gAGEgYzMGQizEMYMtz9/qhquLbpvtUnt27dqvp8ss6695w6dWrXXX0r++59fr9fdXcAAFg+W2YdAAAAsyERBABYUhJBAIAlJREEAFhSEkEAgCUlEQQAWFISQQCAOVBVr6qqK6rqw3t4vKrqJVV1flWdU1XHrnVNiSAAwHx4dZIT9/L4Q5IcNd62JXnFWheUCAIAzIHufleSL+zllJOS/EmPvDfJzarqVnu75n7rGeB1vsABh1i6BJjINy5996xDAObE/gcfWbOO4erPXbhuOc4Bt7jdz2RUxdtle3dv38fLHJLk06v2Lx4fu2xPT5h6IggAwN6Nk759TfyuN4kgAMAQK9fOOoLdXZLksFX7h46P7ZF7BAEAhuiV9dvWx5lJfnw8evheSb7c3XtsCycqggAAc6Gq/jzJCUkOrqqLk5yRZP8k6e5XJjkryUOTnJ/k60l+aq1rSgQBAIZYWbdK3kS6+7FrPN5JnrQv15QIAgAM0OvX0p0Z9wgCACwpFUEAgCE2uDU8DRJBAIAhtIYBAJhXKoIAAENsvgml95lEEABgCK1hAADmlYogAMAQRg0DACwnE0oDADC3VAQBAIbQGgYAWFJawwAAzCsVQQCAIUwoDQCwpLSGAQCYVyqCAABDGDUMALCktIYBAJhXKoIAAENoDQMALKfu+Z8+RmsYAGBJqQgCAAyxAINFJIIAAEO4RxAAYEktQEXQPYIAAEtKRRAAYIiV+R81LBEEABhCaxgAgHmlIggAMIRRwwAAS0prGACAeaUiCAAwhNYwAMCSWoBEUGsYAGBJqQgCAAzQbUJpAIDlpDUMAMC8UhEEABhiAeYRlAgCAAyhNQwAwLxSEQQAGEJrGABgSWkNAwAwr1QEAQCG0BoGAFhSWsMAAMwrFUEAgCEWoCIoEQQAGGIB7hHUGgYAWFIqggAAQ2gNAwAsKa1hAADmlYogAMAQWsMAAEtKaxgAgHmlIggAMITWMADAklqARFBrGABgSakIAgAM0T3rCK43iSAAwBBawwAAzCsVQQCAIRagIigRBAAYwoTSAADMKxVBAIAhFqA1rCIIADBE9/ptE6iqE6vqY1V1flU94zoev01Vvb2qPlBV51TVQ9e6pkQQAGCTq6qtSV6W5CFJjkny2Ko6ZrfTnpXkjd19tySnJnn5Wtfda2u4qn4vyR7T1O7+hbVeAABgIW1sa/j4JOd394VJUlWvT3JSkvNWndNJbjr+/qAkl6510bUqgjuTnJ3kwCTHJvnP8XbXJAdMHjsAwIJZWVm3raq2VdXOVdu23V7tkCSfXrV/8fjYas9OcnpVXZzkrCQ/v9Zb2GtFsLtfkyRV9bNJfqi7rxnvvzLJu9e6OAAAa+vu7Um2X8/LPDbJq7v7d6rq3kn+tKru2L3neW4mHTX83RmVGr8w3r/x+BgAwHLa2HkEL0ly2Kr9Q8fHVntCkhOTpLv/raoOTHJwkiv2dNFJE8EXJPlAVb09SSW5b0blRwCApdQrk432XSc7khxVVUdklACemuRxu53zqST3T/Lqqjo6o1v7Pru3i06UCHb3H1fVm5Pcc3zoV7v78n0IHgCAgbr7mqp6cpK3Jtma5FXdfW5VPTfJzu4+M8kvJ/mDqnpqRgNHfrJ773PTTJQIVlUleUCSI7v7ueN5ao7v7n+/Pm8KAGBubfCE0t19VkaDQFYf+/VV35+X5D77cs1J5xF8eZJ7Z3QTYpJ8NaO5bAAAllOvrN82I5PeI3jP7j62qj6QJN39xaoyfQwAwBybNBG8ejyjdSdJVd0iyfwvsAcAMNTGDhaZikkTwZck+eskt6yq30zyqIyWMQEAWE4bfI/gNEw6avi1VXV2RkOSK8nJ3f2RqUYGALCZLUsiWFU3z2gywj9fdWz/7r56WoEBADBdk7aG35/RbNZfzKgieLMkl1fVZ5L8dHefPZ3wAAA2qb1P0TcXJp0+5h+SPLS7D+7u70nykCR/l+TnMppaBgBguaysrN82I5Mmgvfq7rfu2unutyW5d3e/N8kNphIZAABTNWkieFlV/WpV3Xa8PT3JZ8ZTysz/nZJsqAc/6ISc++F35aPnvSdPf9qTZh0OsEk96/kvyn1/9NScfPoTZx0KXLeVXr9tRiZNBB+X5NAkfzPebjM+tjXJKdMIjMW0ZcuWvOTFv5mHPfz03Oku98tjHnNyjj76qFmHBWxCJz/0gXnli5436zBgz5ZlZZHu/lySn9/Dw+evXzgsuuPvcbdccMEnctFFn0qSvPGNb8ojHv7gfOQj/znjyIDN5ri73imXXPaZWYcBC23S6WNukeTpSX4gyYG7jnf3j0wpLhbUrQ/5vnz64ku/vX/xJZfl+HvcbYYRAcBAC7CyyKSt4dcm+WiSI5I8J8knkuzY08lVta2qdlbVzpWVK693kAAAm02vrKzbNiuTJoLf091/lOTq7n5nd//vJHusBnb39u4+rruP27LlRusSKIvh0ksuz2GH3vrb+4cecqtceunlM4wIAJbXpIngrhVELquqH62quyW5+ZRiYoHt2PnB3P72R+Twww/L/vvvn1NOOSl/+3dvm3VYALDvFmDU8KQrizyvqg5K8stJfi/JTZM8dWpRsbCuvfbaPOUXn5Wz/v512bplS179mjfkvPM+PuuwgE3oaWe8IDs+cE6+9KWv5P4nn56fe8Lj88iHP3jWYcF3zHC073qpnvLyKPsdcMj830kJbIhvXPruWYcAzIn9Dz6yZh3Dlc87fd1ynBs9689m8n4mHTV8REbTxxy++jnd/YjphAUAsMktwKjhSVvDf5Pkj5L8bawkAgAw0zWC18ukieA3u/slU40EAIANNWki+OKqOiPJ25J8a9fB7n7/VKICANjslqg1fKckj89o7sBdddDOXuYSBABYaAswanjSRPDRSY7s7qumGQwAABtn0kTww0luluSK6YUCADBHlqg1fLMkH62qHfmv9wiaPgYAWEqzXCN4vUyaCJ4x1SgAANhwEyWC3f3OaQcCADBXFqA1vGWSk6rqXlW1o6q+VlVXVdW1VfWVaQcHALBprfT6bTMyUSKY5KVJHpvkP5PcMMn/SfKyaQUFAMD0TZoIprvPT7K1u6/t7j9OcuL0wgIA2OR6Zf22GZl0sMjXq+qAJB+sqt9Kcln2IYkEAFg4y3KPYEarimxJ8uQkVyY5LMkjpxUUAADTN+mo4U9W1S3G3z9nuiEBAGx+vegVwRp5dlV9LsnHkny8qj5bVb++MeEBAGxSSzBq+KlJ7pPkHt198+7+7iT3THKfqnrq1KMDAGBq1moNPz7JA7v7c7sOdPeFVXV6krcl+d1pBgcAsGktwRJz+69OAnfp7s9W1f5TigkAYPNb9HsEk1w18DEAADa5tSqCd9nDUnKV5MApxAMAMB8WoCK410Swu7duVCAAAPOke/4TQauDAAAsqUmXmAMAYLVFbw0DALAHC5AIag0DACwpFUEAgAEWYa1hiSAAwBALkAhqDQMALCkVQQCAIeZ/qWGJIADAEItwj6DWMADAklIRBAAYYgEqghJBAIAhFuAeQa1hAIAlpSIIADDAIgwWkQgCAAyhNQwAwLxSEQQAGEBrGABgWS1Aa1giCAAwQC9AIugeQQCAJaUiCAAwxAJUBCWCAAADaA0DADC3VAQBAIZYgIqgRBAAYACtYQAA5pZEEABggF5Zv20SVXViVX2sqs6vqmfs4ZxTquq8qjq3ql631jW1hgEABtjI1nBVbU3ysiQPTHJxkh1VdWZ3n7fqnKOSPDPJfbr7i1V1y7WuqyIIALD5HZ/k/O6+sLuvSvL6JCftds5PJ3lZd38xSbr7irUuKhEEABiia922qtpWVTtXbdt2e7VDknx61f7F42Or3SHJHarqX6rqvVV14lpvQWsYAGCA9WwNd/f2JNuv52X2S3JUkhOSHJrkXVV1p+7+0p6eoCIIALD5XZLksFX7h46PrXZxkjO7++ruvijJxzNKDPdIIggAMECv1LptE9iR5KiqOqKqDkhyapIzdzvnbzKqBqaqDs6oVXzh3i6qNQwAMMBGjhru7muq6slJ3ppka5JXdfe5VfXcJDu7+8zxYw+qqvOSXJvkad39+b1dt7p7qoHvd8Ah030BYGF849J3zzoEYE7sf/CRE5XRpunSH7zfuuU4t/7Xt8/k/agIAgAM0D3zXPR6kwgCAAxgrWEAAOaWiiAAwAATjvbd1CSCAAADTHm87YbQGgYAWFIqggAAA2gNAwAsqUVIBLWGAQCWlIogAMAAizBYRCIIADCA1jAAAHNLRRAAYABrDQMALClrDQMAMLdUBAEABljRGgYAWE6LcI+g1jAAwJJSEQQAGGAR5hGUCAIADLAIK4toDQMALCkVQQCAAbSGAQCW1CJMH6M1DACwpFQEAQAGWIR5BCWCAAADGDUMAMDcUhEEABhgEQaLSAQBAAZYhHsEtYYBAJaUiiAAwACLMFhEIggAMMAi3COoNQwAsKRUBAEABliEwSISQQCAAbSGAQCYWyqCAAADLMCgYYkgAMAQi9AalggCAAywCINF3CMIALCkVAQBAAZYmXUA60AiCAAwQEdrGACAOaUiCAAwwMoCzB8jEQQAGGBFaxgAgHmlIggAMMAiDBaRCAIADLAI08doDQMALCkVQQCAAbSGAQCWlNYwAABzS0UQAGCARagISgQBAAZYhHsEtYYBAJaUiiAAwAAr818QlAgCAAxhrWEAAOaWiiAAwAA96wDWgUQQAGCARZg+RmsYAGBJqQgCAAywUvM/WEQiCAAwwCLcI6g1DACwpFQEAQAGWITBIhJBAIABFmFlEa1hAIAlpSIIADCAJeYAAJZUr+M2iao6sao+VlXnV9Uz9nLeI6uqq+q4ta4pEQQA2OSqamuSlyV5SJJjkjy2qo65jvNukuQpSd43yXUlggAAA6zU+m0TOD7J+d19YXdfleT1SU66jvN+I8kLk3xzkotKBAEABlhZx62qtlXVzlXbtt1e7pAkn161f/H42LdV1bFJDuvuv5/0PRgsAgAwY929Pcn2oc+vqi1JXpTkJ/fleRJBAIABNniJuUuSHLZq/9DxsV1ukuSOSd5RozWQvy/JmVX1iO7euaeLSgQBAAbY4AmldyQ5qqqOyCgBPDXJ43Y92N1fTnLwrv2qekeSX9lbEpi4RxAAYNPr7muSPDnJW5N8JMkbu/vcqnpuVT1i6HVVBAEABtjotYa7+6wkZ+127Nf3cO4Jk1xTIggAMMBGJ4LToDUMALCkVAQBAAbo+V9qWCIIADCE1jAAAHNLRRAAYIBFqAhKBAEABtjglUWmQmsYAGBJqQgCAAywwUvMTYVEEABggEW4R1BrGABgSakIAgAMsAgVQYkgAMAARg0DADC3VAQBAAYwahgAYEm5RxAAYEm5RxAAgLmlIggAMMDKAtQEJYIAAAMswj2CWsMAAEtKRRAAYID5bwxLBAEABtEaBgBgbu21IlhVX81eKp/dfdN1jwgAYA4s/Moi3X2TJKmq30hyWZI/TVJJTktyq6lHBwCwSS3C9DGTtoYf0d0v7+6vdvdXuvsVSU6aZmAAAEzXpInglVV1WlVtraotVXVakiunGRgAwGbW67jNyqSJ4OOSnJLkM+Pt0eNjAABLaWUdt1mZaPqY7v5EtIIBABbKRBXBqrpDVf1TVX14vH/nqnrWdEMDANi8VtLrts3KpK3hP0jyzCRXJ0l3n5Pk1GkFBQCw2S3TPYLf1d3/vtuxa9Y7GAAANs6kS8x9rqpul3HSWlWPymheQQCApbQIS8xNmgg+Kcn2JN9fVZckuSjJ6VOLCgBgk1uECaUnHTV8YZIHVNWNkmzp7q9ONywAAKZtokSwqn5pt/0k+XKSs7v7g+sfFgDA5jb/9cDJW8PHjbe/He8/LMk5SZ5YVX/R3b81jeAAADarZbpH8NAkx3b315Kkqs5I8vdJ7pvk7CQSQQCAOTNpInjLJN9atX91ku/t7m9U1bf28BwAgIXVC9AcnjQRfG2S91XVm8b7D0/yuvHgkfOmEhkAwCa2NK3h7v6NqnpLkh8cH3pid+8cf3/aVCIDAGCqJq0Iprt3VNUnkxyYJFV1m+7+1NQiAwDYxBZhHsGJlpirqkdU1X9mNJH0O8df3zzNwAAANrNlWmv4N5LcK8nHu/uIJA9I8t6pRQUAwNRNmghe3d2fT7KlqrZ099szmlcQAGApraTXbZuVSe8R/FJV3TjJu5K8tqquSHLl9MICANjcFmHU8KQVwZOSfCPJU5O8JckFGU0hA/vswQ86Ied++F356HnvydOf9qRZhwNsUs96/oty3x89NSef/sRZhwILa6JEsLuv7O5rk3xXRsvM/VkWY4k9NtiWLVvykhf/Zh728NNzp7vcL495zMk5+uijZh0WsAmd/NAH5pUvet6sw4A96nX8b1YmHTX8M1V1eUbrC+/MaFm5nXt/Fvx3x9/jbrnggk/koos+lauvvjpvfOOb8oiHP3jWYQGb0HF3vVMOuulNZh0G7NHKOm6zMuk9gr+S5I7d/blpBsPiu/Uh35dPX3zpt/cvvuSyHH+Pu80wIgBYXpMmghck+fqkF62qbUm2JUltPShbttxoQGgAAJvXMq01/Mwk/1pV70vyrV0Hu/sXruvk7t6eZHuS7HfAIfP/U2LdXHrJ5Tns0Ft/e//QQ26VSy+9fIYRAcAwizBqeNJE8PeT/HOSD2Ux3jczsmPnB3P72x+Rww8/LJdccnlOOeWkPP7HjRwGgFmYNBHcv7t/aaqRsBSuvfbaPOUXn5Wz/v512bplS179mjfkvPM+PuuwgE3oaWe8IDs+cE6+9KWv5P4nn56fe8Lj80iDy9hEVnr+m57VE7yJqnp+kk9kNHXM6tbwF9Z6rtYwMKlvXPruWYcAzIn9Dz6yZh3D6bf9X+uW4/zZJ/9qJu9n0orgY8dfn7nqWCc5cn3DAQBgo0yUCHb3EdMOBABgnsxyjeD1MmlFMFV1xyTHJDlw17Hu/pNpBAUAsNktzfQxVXVGkhMySgTPSvKQJO9JIhEEAJhTEy0xl+RRSe6f5PLu/qkkd0ly0NSiAgDY5JZpiblvdPdKVV1TVTdNckWSw6YYFwDAprZM9wjurKqbJfmDJGcn+VqSf5tWUAAATN+ko4Z/bvztK6vqLUlu2t3nTC8sAIDNbeEHi1TVsXt7rLvfv/4hAQBsfouw5u5aFcHfGX89MMlxSf4jSSW5c5KdSe49vdAAAJimvSaC3X2/JKmqv0pybHd/aLx/xyTPnnp0AACb1CTL9G52k04f8z92JYFJ0t0fTnL0dEICANj8VtLrtk2iqk6sqo9V1flV9YzrePyXquq8qjqnqv6pqm671jUnTQTPqao/rKoTxtsfJDFYBABgA1TV1iQvy2hRj2OSPLaqjtnttA8kOa6775zkL5P81lrXnTQR/Kkk5yZ5yng7b3wMAGApbfCE0scnOb+7L+zuq5K8PslJq0/o7rd399fHu+9NcuhaF510+phvJvnd8QYAsPTWc/qYqtqWZNuqQ9u7e/uq/UOSfHrV/sVJ7rmXSz4hyZvXet1J1xq+T0aDQ267+jndfeQkzwcAWDTrubLIOOnbvuaJE6iq0zOa7eWH1zp30pVF/ijJUzNaVeTa4aEBADDAJfmvy/seOj72X1TVA5L8WpIf7u5vrXXRSRPBL3f3muVFAIBlscHTx+xIclRVHZFRAnhqksetPqGq7pbk95Oc2N1XTHLRSRPBt1fVbyf5qyTfzi6tLAIALKuNXFmku6+pqicneWuSrUle1d3nVtVzk+zs7jOT/HaSGyf5i6pKkk919yP2dt1JE8FdNyPeffy1knSSH9m3twEAwBDdfVaSs3Y79uurvn/Avl5zrbWGf2n87d/teo0kn03ynu6+aF9fDABgUaznqOFZWWsewZuMtxuPt5tkNArlzVV16pRjAwDYtDZ6ZZFpWGut4edc1/GqunmSf8xoMkMAAObQpPcI/hfd/YUa34UIALCMNnjU8FQMSgSr6n5JvrjOsQAAzI1ZtnTXy1qDRT6U/Ld3efMklyb58WkFBQDA9K1VEXzYbvud5PPdfeWU4gEAmAuLMGp4rcEin9yoQAAA5snKAtwjuNb0MQAALKhBg0UAAJbd/NcDJYIAAIMswqhhrWEAgCWlIggAMMAiVAQlggAAAyzCyiJawwAAS0pFEABgAK1hAIAltQgri2gNAwAsKRVBAIABFmGwiEQQAGCARbhHUGsYAGBJqQgCAAygNQwAsKS0hgEAmFsqggAAAyzCPIISQQCAAVYW4B5BrWEAgCWlIggAMIDWMADAktIaBgBgbqkIAgAMoDUMALCktIYBAJhbKoIAAANoDQMALCmtYQAA5paKIADAAFrDAABLqntl1iFcb1rDAABLSkUQAGCAFa1hAIDl1EYNAwAwr1QEAQAG0BoGAFhSWsMAAMwtFUEAgAEWYYk5iSAAwACLsLKI1jAAwJJSEQQAGGARBotIBAEABjB9DADAklqEiqB7BAEAlpSKIADAAKaPAQBYUlrDAADMLRVBAIABjBoGAFhSWsMAAMwtFUEAgAGMGgYAWFK9APcIag0DACwpFUEAgAG0hgEAlpRRwwAAzC0VQQCAARZhsIhEEABgAK1hAADmlkQQAGCA7l63bRJVdWJVfayqzq+qZ1zH4zeoqjeMH39fVR2+1jUlggAAA/Q6bmupqq1JXpbkIUmOSfLYqjpmt9OekOSL3X37JL+b5IVrXVciCACw+R2f5PzuvrC7r0ry+iQn7XbOSUleM/7+L5Pcv6pqbxed+mCRa666ZK8BsJyqalt3b591HMDm5/OCzWo9c5yq2pZk26pD23f7d39Ikk+v2r84yT13u8y3z+nua6rqy0m+J8nn9vS6KoLMyra1TwFI4vOCJdDd27v7uFXbhvzxIxEEANj8Lkly2Kr9Q8fHrvOcqtovyUFJPr+3i0oEAQA2vx1JjqqqI6rqgCSnJjlzt3POTPIT4+8fleSfe40hySaUZlbc7wNMyucFS298z9+Tk7w1ydYkr+ruc6vquUl2dveZSf4oyZ9W1flJvpBRsrhXtQizYgMAsO+0hgEAlpREEABgSUkE2aOquraqPlhV51bVf1TVL1fVpv43U1U/WVUvnXUcsIiq6vCq+vBux55dVb+yD9d4R1Udt/7RrZ+q+tqsY4CNYrAIe/ON7r5rklTVLZO8LslNk5wxy6AAgPWxqas7bB7dfUVGk7o+uUYOr6p3V9X7x9sPJklVnVBV76yqN1XVhVX1gqo6rar+vao+VFW3G5/38PGC2B+oqn+squ8dH79FVf3DuAr5h1X1yao6ePzY6ePrfLCqfn+87mKq6qeq6uNV9e9J7jOTHxAsuXGl74Xj39GPV9X/HB+/YVW9vqo+UlV/neSGq57ziqraOf59f86q45+oqv83/l3fWVXHVtVbq+qCqnri+JwbV9U/jT9/PlRVJ616/v+tqo9V1Xuq6s93VSyr6nZV9ZaqOnv8+fX94+NHVNW/ja/zvA36kcGmIBFkYt19YUZD1m+Z5IokD+zuY5M8JslLVp16lyRPTHJ0kscnuUN3H5/kD5P8/Pic9yS5V3ffLaP1Ep8+Pn5GRvMe/UBG6yTeJkmq6ujx69xnXKW8NslpVXWrJM/JKAH8oYwW4gZmY7/x7/ov5judg59N8vXuPnp87O6rzv+17j4uyZ2T/HBV3XnVY58a/66/O8mrM5oT7V4Z/b4nyTeT/Nj4M+h+SX5n/EfqPZI8MqPPoYckWd2G3p7k57v77kl+JcnLx8dfnOQV3X2nJJddr58AzBmtYYbaP8lLq+quGSVld1j12I7uvixJquqCJG8bH/9QRh/YyWhG9DeME7kDklw0Pv5DSX4sSbr7LVX1xfHx+2f0P5Ad4/Wzb5hRMnrPJO/o7s+OX+8Nu8UCrJ89zTe26/hfjb+eneTw8ff3zfgPxe4+p6rOWfW8U8brq+6X5FYZ/SG36/FdE+V+KMmNu/urSb5aVd+qqpsluTLJ86vqvklWMlpj9Xsz+qPwTd39zSTfrKq/TUYVxCQ/mOQvxp8hSXKD8df7ZJQ8JsmfJnnhmj8JWBASQSZWVUdmlPRdkdFf9p/J6K/uLRn9db7Lt1Z9v7JqfyXf+Tf3e0le1N1nVtUJSZ691ssneU13P3O3mE7ex7cBDPf5JN+927Gb5zt/yO36Xb82a/z/paqOyKgqd4/u/mJVvTrJgatOWf25sftnyn5JTktyiyR37+6rq+oTuz1/d1uSfGnXfc/XwaS6LCWtYSZSVbdI8sokLx0vV3NQksu6eyWj9u/WfbzkQfnOGok/ser4vyQ5ZfyaD8p3/qfzT0keNR60kqq6eVXdNsn7MmopfU9V7Z/k0fv85oCJdPfXklxWVT+SjH4Pk5yY0a0ee/KuJI8bn3/HjNrAyWjg2ZVJvjy+R/gh+xjOQUmuGCeB90ty2/Hxf0ny8Ko6cFwFfNg49q8kuaiqHj2OparqLques2sFhtP2MQ6YaxJB9uaG45u1z03yjxm1eHfdn/PyJD9RVf+R5Psz+kDfF8/OqEVzdpLPrTr+nCQPqtEUFY9OcnmSr3b3eUmeleRt49bSPyS51bgF/ewk/5bRh/lH9vldAvvix5P836r6YJJ/TvKc7r5gL+e/IsmNq+ojSZ6bUds43f0fST6Q5KMZzUjwL/sYx2uTHFdVHxrH9NHxdXdk1FY+J8mbM2otf3n8nNOSPGH8uXVukl0DTJ6S5Enjax2yj3HAXLPEHJtKVd0gybXjNRXvndEN3HedcVjAHKmqG3f316rquzKqSG7r7vfPOi7YjNwjyGZzmyRvrNHE1Vcl+ekZxwPMn+1VdUxG9wy+RhIIe6YiCACwpNwjCACwpCSCAABLSiIIALCkJIIAAEtKIggAsKT+P+tZAUcgCexRAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 864x504 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_cm_ratio = pd.DataFrame(cf_matrix / np.sum(cf_matrix, axis=1)[:, None], index=[i for i in labels],\n",
    "                     columns=[i for i in labels])\n",
    "plt.figure(figsize=(12, 7))\n",
    "sn.heatmap(df_cm_ratio, annot=True)\n",
    "# plt.save(\"Confusion_matrix_ratio.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x504 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_cm_raw = pd.DataFrame(cf_matrix, index=[i for i in labels],\n",
    "                     columns=[i for i in labels])\n",
    "plt.figure(figsize=(12, 7))\n",
    "sn.heatmap(df_cm_raw, annot=True)\n",
    "# plt.save(\"Confusion_matrix_raw.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[    0,  2992],\n",
       "       [    0, 36513]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cf_matrix"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
