{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To note: Running this on different systems (i.e. local, SCW, server) will result in slight changes needing to the code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/scipy/__init__.py:138: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.4)\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion} is required for this version of \"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.pyplot._IonContext at 0x7f2203fa1850>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load libraries\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import sys\n",
    "import torchvision\n",
    "import torchvision.transforms as T\n",
    "import torchvision.models as models\n",
    "from PIL import Image\n",
    "from PIL import ImageEnhance\n",
    "import matplotlib.pyplot as plt\n",
    "import imagesize\n",
    "import subprocess\n",
    "sys.path\n",
    "from IPython.core.debugger import set_trace\n",
    "import scipy.ndimage\n",
    "import matplotlib.patches as patches\n",
    "# plt.rcParams['figure.figsize'] = [12,12]\n",
    "# sys.path.append('/workspace/myFile/Mask_RCNN_Tutorial/')\n",
    "from tqdm import tqdm\n",
    "from torch import nn as nn\n",
    "from torch import optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "import re\n",
    "import time\n",
    "import copy\n",
    "import pylab\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from tempfile import TemporaryDirectory\n",
    "import torch.backends.cudnn as cudnn\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "import seaborn as sn\n",
    "import pandas as pd\n",
    "import glob\n",
    "# Rather than have a messy notebook with a load of functions we can store them in separate .py files and import them\n",
    "\n",
    "cudnn.benchmark = True\n",
    "plt.ion()   # interactive mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "writer = SummaryWriter(\"Experiments/TENSORBOARD\")    # This determines the tensorboard file name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DNADataset(object):\n",
    "    def __init__(self, root, transforms, labels, imDx = False):\n",
    "        self.root, self.transforms, self.labels = root, transforms, labels\n",
    "    \n",
    "        # load all image files, sorting them to ensure they are aligned\n",
    "        self.imgDir = glob.glob(root+\"*/*.tiff\")\n",
    "        Damagednuclei= [x for x in self.imgDir if 'Damaged_nuclei_' in x]\n",
    "        Undamagednuclei= [x for x in self.imgDir if \"No_damage_nuclei\" in x]\n",
    "        #np.random.shuffle(Undamagednuclei)\n",
    "        #Undamagednuclei=Undamagednuclei[:10000]\n",
    "        self.imgDir= Damagednuclei+Undamagednuclei\n",
    "        size80=[]\n",
    "        for x in self.imgDir:\n",
    "            img = Image.open(x) # Open image\n",
    "            w,h=img.size\n",
    "            if w<=80 and h<=80:\n",
    "                size80.append(x)\n",
    "        self.imgDir=size80              \n",
    "        \n",
    "        self.imgs = sorted(self.imgDir) # list of images\n",
    "\n",
    "        \n",
    "\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.imgs[idx]\n",
    "       \n",
    "        # Transform images into tensors\n",
    "        img = Image.open(img_path) # Open image\n",
    "        w,h=img.size\n",
    "        img = np.array(img) # Convert image into an array\n",
    "        img = np.float32(np.divide(img, 2**16)) # Ensure all values are floats\n",
    "        \n",
    "        result=np.zeros((80,80), dtype=np.float32)\n",
    "        x_center = (80 - w) // 2\n",
    "        y_center = (80 - h) // 2 # copy img image into center of result image\n",
    "        result[y_center:y_center+h, x_center:x_center+w] = img\n",
    "        img = result\n",
    "        \n",
    "        targetlab=\"\"\n",
    "        if img_path.find('No_damage_nuclei') != -1:\n",
    "            targetlab= 'Undamaged'\n",
    "        if img_path.find('Damaged_nuclei_') != -1:\n",
    "            targetlab= 'Damaged'  # Find labels corresponding to image\n",
    "        target = self.labels.index(targetlab) # Get the label and assign to a value\n",
    "        \n",
    "        # Convert label to tensor\n",
    "        #torch.to\n",
    "        \n",
    "        if self.transforms is not None:\n",
    "            img = self.transforms(img)\n",
    "#             #print('In the transforms')\n",
    "        imNo = idx\n",
    "        return img, target, imNo\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.imgs)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "imDr = \"/workspace/myFile/Output/17052023/\"  # Image patches directory\n",
    "\n",
    "labels = ['Damaged', 'Undamaged']  # Your labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For data augmentation\n",
    "def get_transform(train):\n",
    "    transforms = []\n",
    "\n",
    "    transforms.append(T.ToTensor())\n",
    "    #transforms.append(T.Normalize([0.0019368887995516483], [0.00672996630111016]))\n",
    "    #transforms.append(T.RandomHorizontalFlip(0.5))\n",
    "    \n",
    "    if train:\n",
    "        transforms.append(T.RandomHorizontalFlip(p=1))\n",
    "        transforms.append(T.RandomVerticalFlip(p=1))\n",
    "    \n",
    "    return T.Compose(transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, scheduler, train, test, num_epochs=25):\n",
    "    since = time.time()\n",
    "    # Create a temporary directory to save training checkpoints\n",
    "    with TemporaryDirectory() as tempdir:\n",
    "        best_model_params_path = os.path.join(tempdir, 'best_model_params.pt')\n",
    "\n",
    "        torch.save(model.state_dict(), best_model_params_path)\n",
    "        best_acc = 0.0\n",
    "        \n",
    "        for epoch in range(num_epochs):\n",
    "            print(f'Epoch {epoch}/{num_epochs - 1}')\n",
    "            print('-' * 10)\n",
    "            dataset_train = torch.utils.data.Subset(dataSetTrain, train[epoch])\n",
    "            dataset_test = torch.utils.data.Subset(dataSetTest, test[epoch])\n",
    "            data_loader_train = torch.utils.data.DataLoader(\n",
    "                dataset_train, batch_size=128, shuffle=True, num_workers=0)\n",
    "\n",
    "            data_loader_test = torch.utils.data.DataLoader(\n",
    "                dataset_test, batch_size=128, shuffle=False, num_workers=0)\n",
    "            # Each epoch has a training and validation phase\n",
    "            for phase in ['val']:\n",
    "                if phase == 'train':\n",
    "                    model.train()  # Set model to training mode\n",
    "                    dataloaders = data_loader_train\n",
    "                else:\n",
    "                    model.eval()   # Set model to evaluate mode\n",
    "                    dataloaders = data_loader_test\n",
    "\n",
    "                running_loss = 0.0\n",
    "                running_corrects = 0\n",
    "                damaged_len=0\n",
    "                damaged_corrects = 0\n",
    "                undamaged_len=0\n",
    "                undamaged_corrects = 0\n",
    "\n",
    "                # Iterate over data.\n",
    "                for inputs, labels, imNo in dataloaders:\n",
    "                    inputs = inputs.to(device)\n",
    "                    labels = labels.to(device)\n",
    "\n",
    "                    # zero the parameter gradients\n",
    "                    optimizer.zero_grad()\n",
    "\n",
    "                    # forward\n",
    "                    # track history if only in train\n",
    "                    with torch.set_grad_enabled(phase == 'train'):\n",
    "                        outputs = model(inputs)\n",
    "                        _, preds = torch.max(outputs, 1)\n",
    "                        loss = criterion(outputs, labels)\n",
    "                        # backward + optimize only if in training phase\n",
    "                        if phase == 'train':\n",
    "                            loss.backward()\n",
    "                            optimizer.step()\n",
    "\n",
    "                    # statistics\n",
    "                    running_loss += loss.item() * inputs.size(0)    # Loss\n",
    "                    nada=torch.tensor(np.zeros(len(labels))).to(device)\n",
    "                    uno=nada+1\n",
    "                    falseneg=preds+1\n",
    "                    falsepos=preds-1\n",
    "                    FPplusTN=torch.sum(labels==nada)\n",
    "                    TPplusFN=torch.sum(labels==uno)\n",
    "                    FN=torch.sum(labels==falseneg)\n",
    "                    FP=torch.sum(labels==falsepos)\n",
    "                    TN=FPplusTN-FP\n",
    "                    TP=TPplusFN-FN\n",
    "                    running_corrects += torch.sum(preds == labels.data) # Accuracy\n",
    "                    damaged_len+=TPplusFN\n",
    "                    damaged_corrects += TP\n",
    "                    undamaged_len+=FPplusTN\n",
    "                    undamaged_corrects += TN\n",
    "                damaged_acc = damaged_corrects / damaged_len\n",
    "                undamaged_acc = undamaged_corrects/undamaged_len\n",
    "                epoch_acc= (damaged_acc+undamaged_acc)/2\n",
    "                proper_acc=(damaged_corrects+undamaged_corrects)/(damaged_len+undamaged_len)\n",
    "                if phase == 'train':\n",
    "                    scheduler.step()\n",
    "\n",
    "                epoch_loss = running_loss / dataset_sizes[phase]    # Loss metric per epoch\n",
    "                #epoch_acc = running_corrects.double() / dataset_sizes[phase]    # Accuracy metric per epoch\n",
    "\n",
    "                if phase == \"train\":    # This is the tensorboard code that writes accuracy and loss metrics\n",
    "                    writer.add_scalar(\"Train/Accuracy\", epoch_acc, epoch)\n",
    "                    writer.add_scalar(\"Train/Loss\", epoch_loss, epoch)\n",
    "                else:\n",
    "                    writer.add_scalar(\"Validation/Accuracy\", epoch_acc, epoch)\n",
    "                    writer.add_scalar(\"Validation/Loss\", epoch_loss, epoch)\n",
    "\n",
    "                print(f'{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n",
    "                print(\"proper accuracy=\")\n",
    "                print(proper_acc)\n",
    "                print(\"damaged accuracy=\")\n",
    "                print(damaged_acc)\n",
    "                print(\"undamaged accuracy=\")\n",
    "                print(undamaged_acc)\n",
    "                con_matter= torch.tensor([[damaged_corrects, damaged_len-damaged_corrects],[undamaged_len-undamaged_corrects,undamaged_corrects]])\n",
    "                con_matter=con_matter.cpu().numpy()\n",
    "                print(con_matter)\n",
    "                # deep copy the model\n",
    "                if phase == 'val' and epoch_acc >= best_acc: \n",
    "                    # This compares validation accuracy to previous bests and adjusts model weights accordingly\n",
    "                    best_acc = epoch_acc\n",
    "                    torch.save(model.state_dict(), best_model_params_path)\n",
    "                    con_mat= torch.tensor([[damaged_corrects, damaged_len-damaged_corrects],[undamaged_len-undamaged_corrects,undamaged_corrects]])\n",
    "\n",
    "            print()\n",
    "\n",
    "        time_elapsed = time.time() - since  # Nice way to measure training time but info also stored (indirectly) by tensorboard\n",
    "        print(\n",
    "            f'Training complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')\n",
    "        print(f'Best val Acc: {best_acc:4f}')\n",
    "        #labels= labels.cpu().numpy()\n",
    "        #preds=preds.cpu().numpy()\n",
    "        model.load_state_dict(torch.load(best_model_params_path))\n",
    "    writer.close()\n",
    "    return model, con_mat   # We want to return the model because its the model, also confusion matrix for later analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is your RESNET\n",
    "# Initialize CNN with kaiming\n",
    "def init_cnn(m):\n",
    "    # Set the weights of the RESNET\n",
    "    if getattr(m, 'bias', None) is not None: nn.init.constant_(m.bias, 0)\n",
    "    if isinstance(m, (nn.Conv2d,nn.Linear)): nn.init.kaiming_normal_(m.weight)\n",
    "    for l in m.children(): init_cnn(l)\n",
    "\n",
    "\n",
    "# noop function for returning nothing\n",
    "def noop(x): return x\n",
    "# activation function(RELU)\n",
    "act_fn = nn.ReLU(inplace=True)\n",
    "\n",
    "# Flatten\n",
    "class Flatten(nn.Module):\n",
    "    def forward(self, x): return x.view(x.size(0), -1)\n",
    "\n",
    "# Make a convolution\n",
    "def conv(ni, nf, ks=3, stride=1, bias=False):\n",
    "    return nn.Conv2d(ni, nf, kernel_size=ks, stride=stride, padding=ks//2, bias=bias)\n",
    "\n",
    "# Create a convuolutional layer with convolution and batch norm\n",
    "def conv_layer(ni, nf, ks=3, stride=1, zero_bn=False, act=True):\n",
    "    bn = nn.BatchNorm2d(nf) # get a 2d batch norm from Pytorhc\n",
    "    nn.init.constant_(bn.weight, 0. if zero_bn else 1.)\n",
    "    layers = [conv(ni, nf, ks, stride=stride), bn]\n",
    "    if act: layers.append(act_fn) # add in the activation function if act is true\n",
    "    return nn.Sequential(*layers)\n",
    "\n",
    "\n",
    "# Resblock\n",
    "class ResBlock(nn.Module):\n",
    "    def __init__(self, expansion, ni, nh, stride = 1):\n",
    "        super().__init__()\n",
    "        # ni - number of inputs channels, nf - number of filters\n",
    "        # nh - number of filters in first conv\n",
    "        # expansion is 1 for resnet 18, 34 and 4 for larger networks\n",
    "        nf, ni = nh*expansion, ni*expansion\n",
    "        layers = [conv_layer(ni, nh, 3, stride = stride), # for resnet < 34 2 convs per resblock\n",
    "                 conv_layer(nh, nf, 3, zero_bn = True, act = False)\n",
    "                 ] if expansion == 1 else [ # for RESNET > 34 then 3 convs per block with bottleneck\n",
    "                            conv_layer(ni, nh, 1),\n",
    "                            conv_layer(nh, nh, 3, stride = stride),\n",
    "                            conv_layer(nh, nf, 1, zero_bn = True, act = False)\n",
    "        ]\n",
    "        self.convs = nn.Sequential(*layers) # Creates the conv layers\n",
    "        self.idconv = noop if ni==nf else conv_layer(ni, nf, 1, act = False) # id convolution ()\n",
    "        self.pool = noop if stride== 1 else nn.AvgPool2d(2, ceil_mode = True) # average pool on \n",
    "        \n",
    "    def forward(self, x): \n",
    "        # Forward function adds the convolution part to the id part \n",
    "        #return act_fn(self.convs(x)) + self.idconv(self.pool(x))\n",
    "        return act_fn(self.convs(x) + self.idconv(self.pool(x)))\n",
    "\n",
    "# XResnet\n",
    "class XResNet(nn.Sequential):\n",
    "    @classmethod\n",
    "    def create(cls, expansion, layers, c_in=3, c_out=1000):\n",
    "        nfs = [c_in, (c_in + 1)*8, 64, 64] # number of filters in stem layer (c_in is number of image channels)\n",
    "        stem = [conv_layer(nfs[i], nfs[i+1], stride=2 if i==0 else 1)\n",
    "            for i in range(3)]\n",
    "\n",
    "        nfs = [64//expansion,64,128,256,512]\n",
    "        res_layers = [cls._make_layer(expansion, nfs[i], nfs[i+1],\n",
    "                                      n_blocks=l, stride=1 if i==0 else 2)\n",
    "                  for i,l in enumerate(layers)]\n",
    "        res = cls(\n",
    "        *stem,\n",
    "        nn.MaxPool2d(kernel_size=3, stride = 2, padding = 1), # then a max pooling layer\n",
    "        *res_layers,\n",
    "        nn.AdaptiveAvgPool2d(1), Flatten(), \n",
    "        nn.Linear(nfs[-1]*expansion, c_out)\n",
    "        )\n",
    "        init_cnn(res)\n",
    "        return res\n",
    "        \n",
    "    @staticmethod\n",
    "    def _make_layer(expansion, ni, nf, n_blocks, stride): # returns a resblock\n",
    "        return nn.Sequential(\n",
    "        *[ResBlock(expansion, ni if i==0 else nf, nf, stride if i==0 else 1)\n",
    "         for i in range(n_blocks)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def xresnet18 (**kwargs): return XResNet.create(1, [2, 2,  2, 2], **kwargs)\n",
    "def xresnet34 (**kwargs): return XResNet.create(1, [3, 4,  6, 3], **kwargs)\n",
    "def xresnet50 (**kwargs): return XResNet.create(4, [3, 4,  6, 3], **kwargs)\n",
    "model = xresnet18(c_in = 1, c_out = 2)\n",
    "#model34 = xresnet34(c_in = 1, c_out = 2)\n",
    "#model50 = xresnet50(c_in = 1, c_out = 2)\n",
    "model.load_state_dict(torch.load(\"/workspace/myFile/Output/17052023/NEWbest_model_params.pt\"))\n",
    "model = model.to(device)\n",
    "\n",
    "# Label smoothing cross entropy\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "def reduce_loss(loss, reduction='mean'):\n",
    "    return loss.mean() if reduction=='mean' else loss.sum() if reduction=='sum' else loss\n",
    "\n",
    "class LabelSmoothingCrossEntropy(nn.Module):\n",
    "    def __init__(self, ε:float=0.1, reduction='mean'):\n",
    "        super().__init__()\n",
    "        self.ε,self.reduction = ε,reduction\n",
    "    \n",
    "    def forward(self, output, target):\n",
    "        c = output.size()[-1]\n",
    "        log_preds = F.log_softmax(output, dim=-1)\n",
    "        loss = reduce_loss(-log_preds.sum(dim=-1), self.reduction)\n",
    "        nll = F.nll_loss(log_preds, target, reduction=self.reduction)\n",
    "        return lin_comb(loss/c, nll, self.ε)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions that shows the image, true class, predicted class and degree of prediction\n",
    "\n",
    "def images_to_probs(net, images):\n",
    "    '''\n",
    "    Generates predictions and corresponding probabilities from a trained\n",
    "    network and a list of images\n",
    "    '''\n",
    "    output = net(images)\n",
    "    # convert output probabilities to predicted class\n",
    "    _, preds_tensor = torch.max(output, 1)\n",
    "    preds = np.squeeze(preds_tensor.numpy())\n",
    "    return preds, [F.softmax(el, dim=0)[i].item() for i, el in zip(preds, output)]\n",
    "\n",
    "\n",
    "def plot_classes_preds(net, images, labels):\n",
    "    '''\n",
    "    Generates matplotlib Figure using a trained network, along with images\n",
    "    and labels from a batch, that shows the network's top prediction along\n",
    "    with its probability, alongside the actual label, coloring this\n",
    "    information based on whether the prediction was correct or not.\n",
    "    Uses the \"images_to_probs\" function.\n",
    "    '''\n",
    "    preds, probs = images_to_probs(net, images)\n",
    "    # plot the images in the batch, along with predicted and true labels\n",
    "    fig = plt.figure(figsize=(12, 48))\n",
    "    for idx in np.arange(4):\n",
    "        ax = fig.add_subplot(1, 4, idx+1, xticks=[], yticks=[])\n",
    "        matplotlib_imshow(images[idx], one_channel=True)\n",
    "        ax.set_title(\"{0}, {1:.1f}%\\n(label: {2})\".format(\n",
    "            labels[preds[idx]],\n",
    "            probs[idx] * 100.0,\n",
    "            labels[labels[idx]]),\n",
    "                    color=(\"green\" if preds[idx]==labels[idx].item() else \"red\"))\n",
    "    return fig\n",
    "\n",
    "def matplotlib_imshow(img, one_channel=True):\n",
    "    if one_channel:\n",
    "        img = img.mean(dim=0)\n",
    "    img = img / 2 + 0.5     # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    if one_channel:\n",
    "        plt.imshow(npimg, cmap=\"Greys\")\n",
    "    else:\n",
    "        plt.imshow(np.transpose(npimg, (1, 2, 0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def confusion_matrix_calc(data_loader_test, classes, model_ft):       \n",
    "        y_pred = []\n",
    "        y_true = []\n",
    "        for inputs, labels, imNo in data_loader_test:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "                output = model_ft(inputs) # Feed Network\n",
    "\n",
    "                output = (torch.max(torch.exp(output), 1)[1]).data.cpu().numpy()\n",
    "                y_pred.extend(output) # Save Prediction\n",
    "                \n",
    "                labels = labels.data.cpu().numpy()\n",
    "                y_true.extend(labels) # Save Truth\n",
    "\n",
    "        # constant for classes\n",
    "        # classes = ('Alive', 'Dead')\n",
    "\n",
    "        # Build confusion matrix\n",
    "        cf_matrix = confusion_matrix(y_true, y_pred)\n",
    "        return cf_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': 105347, 'val': 1}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k=5 #NUMBER OF K FOLDS\n",
    "epoch=5 #NUMBER OF EPOCHS\n",
    "\n",
    "torch.manual_seed(10)\n",
    "imIdx = torch.randperm(1).tolist()\n",
    "\n",
    "## Create dataset\n",
    "dataSetTrain = DNADataset(imDr, get_transform(train = True), labels, imDx=imIdx)\n",
    "dataSetTest = DNADataset(imDr, get_transform(train = False), labels, imDx=imIdx)\n",
    "\n",
    "data_loader_train=[]\n",
    "data_loader_test=[]\n",
    "\n",
    "# ## Create dataloaders\n",
    "# Get subset\n",
    "torch.manual_seed(10)\n",
    "indices = torch.randperm(len(dataSetTrain)).tolist()\n",
    "\n",
    "noTrain = int(len(dataSetTrain)*0.7)\n",
    "train=[]\n",
    "test=[]\n",
    "indices = torch.randperm(len(dataSetTrain)).tolist()\n",
    "TotalSet=list(range(len(dataSetTrain)))\n",
    "Kfifth = len(dataSetTrain)//k\n",
    "split= epoch%k\n",
    "train.append(TotalSet[(split+1)*Kfifth:]+TotalSet[:Kfifth*split])\n",
    "\n",
    "indices = torch.randperm(len(dataSetTest)).tolist()\n",
    "TotalSet=list(range(len(dataSetTrain)))\n",
    "test.append(TotalSet)\n",
    "\n",
    "#dataset_train = torch.utils.data.Subset(dataSetTrain, indices[-noTrain:])\n",
    "\n",
    "#dataset_test = torch.utils.data.Subset(dataSetTest, indices[:-noTrain])\n",
    "#len(indices), len(indices[:-50]), len(indices[-50:]), 50/191, type(dataset_test)\n",
    "\n",
    "dataset_sizes = {'train': len(train[0]), 'val': len(test)}\n",
    "dataset_sizes\n",
    "#dataset_train = torch.utils.data.Subset(dataSetTrain, train)\n",
    "#data_loader_train.append(dataset_train)\n",
    "#dataset_testo = torch.utils.data.Subset(dataSetTest, test)\n",
    "#data_loader_test.append(dataset_testo)\n",
    "# define training and validation data loaders\n",
    "\n",
    "\n",
    "# Collate function (gathers together the outputs)\n",
    "# def collate_fn(batch):\n",
    "#     return tuple(zip(*batch))\n",
    "\n",
    "#len(indices[-noTrain:]), dataset_sizes\n",
    "#dataset_test[0][1], dataset_test[3][1], dataset_test[-1][1], dataSetTrain.imgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_weights= [0.924865,0.075135] #1-(#inclass/ #intotal )\n",
    "class_weights = torch.Tensor(class_weights)\n",
    "class_weights=class_weights.to(device)\n",
    "criterion = nn.CrossEntropyLoss(weight = class_weights) \n",
    "\n",
    "# Observe that all parameters are being optimized\n",
    "optimizer_ft = optim.Adam(model.parameters(), weight_decay=1e-2) # standard ADAM optimiser\n",
    "\n",
    "# Decay LR by a factor of 0.1 every 7 epochs\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/0\n",
      "----------\n",
      "val Loss: 21785.3552 Acc: 0.9281\n",
      "proper accuracy=\n",
      "tensor(0.9003, device='cuda:0')\n",
      "damaged accuracy=\n",
      "tensor(0.8954, device='cuda:0')\n",
      "undamaged accuracy=\n",
      "tensor(0.9607, device='cuda:0')\n",
      "[[109054  12735]\n",
      " [   389   9505]]\n",
      "\n",
      "Training complete in 2m 31s\n",
      "Best val Acc: 0.928059\n"
     ]
    }
   ],
   "source": [
    "model_ft, con_mat = train_model(model, criterion, optimizer_ft, exp_lr_scheduler, \n",
    "                                    train,test,num_epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cf_matrix = confusion_matrix_calc(data_loader_test, labels, model_ft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x504 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "con_mat=con_mat.cpu().numpy()\n",
    "plotlabels=['Undamaged','Damaged']\n",
    "df_cm_ratio = pd.DataFrame(con_mat / np.sum(con_mat, axis=1)[:, None], index=[i for i in plotlabels],\n",
    "                     columns=[i for i in plotlabels])\n",
    "plt.figure(figsize=(12, 7))\n",
    "sn.heatmap(df_cm_ratio, annot=True)\n",
    "# plt.save(\"Confusion_matrix_ratio.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x504 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_cm_raw = pd.DataFrame(con_mat, index=[i for i in plotlabels],\n",
    "                     columns=[i for i in plotlabels])\n",
    "plt.figure(figsize=(12, 7))\n",
    "sn.heatmap(df_cm_raw, annot=True)\n",
    "# plt.save(\"Confusion_matrix_raw.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[109054,  12735],\n",
       "       [   389,   9505]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "con_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_loader_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotlabels=['Undamaged','Damaged']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
