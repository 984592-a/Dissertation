{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To note: Running this on different systems (i.e. local, SCW, server) will result in slight changes needing to the code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/scipy/__init__.py:138: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.4)\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion} is required for this version of \"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.pyplot._IonContext at 0x7f4e245855b0>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load libraries\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import sys\n",
    "import torchvision\n",
    "import torchvision.transforms as T\n",
    "import torchvision.models as models\n",
    "from PIL import Image\n",
    "from PIL import ImageEnhance\n",
    "import matplotlib.pyplot as plt\n",
    "import imagesize\n",
    "import subprocess\n",
    "sys.path\n",
    "from IPython.core.debugger import set_trace\n",
    "import scipy.ndimage\n",
    "import matplotlib.patches as patches\n",
    "# plt.rcParams['figure.figsize'] = [12,12]\n",
    "# sys.path.append('/workspace/myFile/Mask_RCNN_Tutorial/')\n",
    "from tqdm import tqdm\n",
    "from torch import nn as nn\n",
    "from torch import optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "import re\n",
    "import time\n",
    "import copy\n",
    "import pylab\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from tempfile import TemporaryDirectory\n",
    "import torch.backends.cudnn as cudnn\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "import seaborn as sn\n",
    "import pandas as pd\n",
    "import glob\n",
    "# Rather than have a messy notebook with a load of functions we can store them in separate .py files and import them\n",
    "\n",
    "cudnn.benchmark = True\n",
    "plt.ion()   # interactive mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "writer = SummaryWriter(\"Experiments/TENSORBOARD\")    # This determines the tensorboard file name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DNADataset(object):\n",
    "    def __init__(self, root, transforms, labels, imDx = False):\n",
    "        self.root, self.transforms, self.labels = root, transforms, labels\n",
    "    \n",
    "        # load all image files, sorting them to ensure they are aligned\n",
    "        self.imgDir = glob.glob(root+\"*/*.tiff\")\n",
    "        Damagednuclei= [x for x in self.imgDir if 'Damaged_nuclei_' in x]\n",
    "        Undamagednuclei= [x for x in self.imgDir if \"No_damage_nuclei\" in x]\n",
    "        #np.random.shuffle(Undamagednuclei)\n",
    "        #Undamagednuclei=Undamagednuclei[:10000]\n",
    "        self.imgDir= Damagednuclei+Undamagednuclei\n",
    "        size80=[]\n",
    "        for x in self.imgDir:\n",
    "            img = Image.open(x) # Open image\n",
    "            w,h=img.size\n",
    "            if w<=80 and h<=80:\n",
    "                size80.append(x)\n",
    "        self.imgDir=size80              \n",
    "        \n",
    "        self.imgs = sorted(self.imgDir) # list of images\n",
    "\n",
    "        \n",
    "\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.imgs[idx]\n",
    "       \n",
    "        # Transform images into tensors\n",
    "        img = Image.open(img_path) # Open image\n",
    "        w,h=img.size\n",
    "        img = np.array(img) # Convert image into an array\n",
    "        img = np.float32(np.divide(img, 2**16)) # Ensure all values are floats\n",
    "        \n",
    "        result=np.zeros((80,80), dtype=np.float32)\n",
    "        x_center = (80 - w) // 2\n",
    "        y_center = (80 - h) // 2 # copy img image into center of result image\n",
    "        result[y_center:y_center+h, x_center:x_center+w] = img\n",
    "        img = result\n",
    "        \n",
    "        targetlab=\"\"\n",
    "        if img_path.find('No_damage_nuclei') != -1:\n",
    "            targetlab= 'Undamaged'\n",
    "        if img_path.find('Damaged_nuclei_') != -1:\n",
    "            targetlab= 'Damaged'  # Find labels corresponding to image\n",
    "        target = self.labels.index(targetlab) # Get the label and assign to a value\n",
    "        \n",
    "        # Convert label to tensor\n",
    "        #torch.to\n",
    "        \n",
    "        if self.transforms is not None:\n",
    "            img = self.transforms(img)\n",
    "#             #print('In the transforms')\n",
    "        imNo = idx\n",
    "        return img, target, imNo\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.imgs)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "root=\"/workspace/myFile/Output/17052023/\"\n",
    "p= glob.glob(root+\"*/*.tiff\")\n",
    "Damagednuclei= [x for x in p if 'Damaged_nuclei_' in x]\n",
    "Undamagednuclei= [x for x in p if \"No_damage_nuclei\" in x]\n",
    "#np.random.shuffle(Undamagednuclei)\n",
    "#Undamagednuclei=Undamagednuclei[:10000]\n",
    "#Undamagednuclei"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "imDr = \"/workspace/myFile/Output/17052023/\"  # Image patches directory\n",
    "\n",
    "labels = ['Damaged', 'Undamaged']  # Your labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For data augmentation\n",
    "def get_transform(train):\n",
    "    transforms = []\n",
    "\n",
    "    transforms.append(T.ToTensor())\n",
    "    #transforms.append(T.Normalize([0.0019368887995516483], [0.00672996630111016]))\n",
    "    #transforms.append(T.RandomHorizontalFlip(0.5))\n",
    "    \n",
    "    if train:\n",
    "        transforms.append(T.RandomHorizontalFlip(p=1))\n",
    "        transforms.append(T.RandomVerticalFlip(p=1))\n",
    "    \n",
    "    return T.Compose(transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, scheduler, dataloaderTrain, dataloaderTest, num_epochs=25):\n",
    "    since = time.time()\n",
    "    # Create a temporary directory to save training checkpoints\n",
    "    with TemporaryDirectory() as tempdir:\n",
    "        best_model_params_path = os.path.join(tempdir, 'best_model_params.pt')\n",
    "\n",
    "        torch.save(model.state_dict(), best_model_params_path)\n",
    "        best_acc = 0.0\n",
    "        \n",
    "        for epoch in range(num_epochs):\n",
    "            print(f'Epoch {epoch}/{num_epochs - 1}')\n",
    "            print('-' * 10)\n",
    "\n",
    "            # Each epoch has a training and validation phase\n",
    "            for phase in ['train', 'val']:\n",
    "                if phase == 'train':\n",
    "                    model.train()  # Set model to training mode\n",
    "                    dataloaders = dataloaderTrain\n",
    "                else:\n",
    "                    model.eval()   # Set model to evaluate mode\n",
    "                    dataloaders = dataloaderTest\n",
    "\n",
    "                running_loss = 0.0\n",
    "                running_corrects = 0\n",
    "                damaged_len=0\n",
    "                damaged_corrects = 0\n",
    "                undamaged_len=0\n",
    "                undamaged_corrects = 0\n",
    "\n",
    "                # Iterate over data.\n",
    "                for inputs, labels, imNo in dataloaders:\n",
    "                    inputs = inputs.to(device)\n",
    "                    labels = labels.to(device)\n",
    "\n",
    "                    # zero the parameter gradients\n",
    "                    optimizer.zero_grad()\n",
    "\n",
    "                    # forward\n",
    "                    # track history if only in train\n",
    "                    with torch.set_grad_enabled(phase == 'train'):\n",
    "                        outputs = model(inputs)\n",
    "                        _, preds = torch.max(outputs, 1)\n",
    "                        loss = criterion(outputs, labels)\n",
    "                        # backward + optimize only if in training phase\n",
    "                        if phase == 'train':\n",
    "                            loss.backward()\n",
    "                            optimizer.step()\n",
    "\n",
    "                    # statistics\n",
    "                    running_loss += loss.item() * inputs.size(0)    # Loss\n",
    "                    nada=torch.tensor(np.zeros(len(labels))).to(device)\n",
    "                    uno=nada+1\n",
    "                    falseneg=preds+1\n",
    "                    falsepos=preds-1\n",
    "                    FPplusTN=torch.sum(labels==nada)\n",
    "                    TPplusFN=torch.sum(labels==uno)\n",
    "                    FN=torch.sum(labels==falseneg)\n",
    "                    FP=torch.sum(labels==falsepos)\n",
    "                    TN=FPplusTN-FP\n",
    "                    TP=TPplusFN-FN\n",
    "                    running_corrects += torch.sum(preds == labels.data) # Accuracy\n",
    "                    damaged_len+=TPplusFN\n",
    "                    damaged_corrects += TP\n",
    "                    undamaged_len+=FPplusTN\n",
    "                    undamaged_corrects += TN\n",
    "                damaged_acc = damaged_corrects / damaged_len\n",
    "                undamaged_acc = undamaged_corrects/undamaged_len\n",
    "                epoch_acc= (damaged_acc+undamaged_acc)/2\n",
    "                \n",
    "                if phase == 'train':\n",
    "                    scheduler.step()\n",
    "\n",
    "                epoch_loss = running_loss / dataset_sizes[phase]    # Loss metric per epoch\n",
    "                #epoch_acc = running_corrects.double() / dataset_sizes[phase]    # Accuracy metric per epoch\n",
    "\n",
    "                if phase == \"train\":    # This is the tensorboard code that writes accuracy and loss metrics\n",
    "                    writer.add_scalar(\"Train/Accuracy\", epoch_acc, epoch)\n",
    "                    writer.add_scalar(\"Train/Loss\", epoch_loss, epoch)\n",
    "                else:\n",
    "                    writer.add_scalar(\"Validation/Accuracy\", epoch_acc, epoch)\n",
    "                    writer.add_scalar(\"Validation/Loss\", epoch_loss, epoch)\n",
    "\n",
    "                print(f'{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n",
    "\n",
    "                # deep copy the model\n",
    "                if phase == 'val' and epoch_acc >= best_acc: \n",
    "                    # This compares validation accuracy to previous bests and adjusts model weights accordingly\n",
    "                    best_acc = epoch_acc\n",
    "                    torch.save(model.state_dict(), best_model_params_path)\n",
    "\n",
    "            print()\n",
    "\n",
    "        time_elapsed = time.time() - since  # Nice way to measure training time but info also stored (indirectly) by tensorboard\n",
    "        print(\n",
    "            f'Training complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')\n",
    "        print(f'Best val Acc: {best_acc:4f}')\n",
    "        labels= labels.cpu().numpy()\n",
    "        preds=preds.cpu().numpy()\n",
    "        con_mat = confusion_matrix(labels, preds)   # Confusion matrix compares true class with predicted class\n",
    "        # load best model weights\n",
    "        model.load_state_dict(torch.load(best_model_params_path))\n",
    "    writer.close()\n",
    "    return model, con_mat   # We want to return the model because its the model, also confusion matrix for later analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is your RESNET\n",
    "# Initialize CNN with kaiming\n",
    "def init_cnn(m):\n",
    "    # Set the weights of the RESNET\n",
    "    if getattr(m, 'bias', None) is not None: nn.init.constant_(m.bias, 0)\n",
    "    if isinstance(m, (nn.Conv2d,nn.Linear)): nn.init.kaiming_normal_(m.weight)\n",
    "    for l in m.children(): init_cnn(l)\n",
    "\n",
    "\n",
    "# noop function for returning nothing\n",
    "def noop(x): return x\n",
    "# activation function(RELU)\n",
    "act_fn = nn.ReLU(inplace=True)\n",
    "\n",
    "# Flatten\n",
    "class Flatten(nn.Module):\n",
    "    def forward(self, x): return x.view(x.size(0), -1)\n",
    "\n",
    "# Make a convolution\n",
    "def conv(ni, nf, ks=3, stride=1, bias=False):\n",
    "    return nn.Conv2d(ni, nf, kernel_size=ks, stride=stride, padding=ks//2, bias=bias)\n",
    "\n",
    "# Create a convuolutional layer with convolution and batch norm\n",
    "def conv_layer(ni, nf, ks=3, stride=1, zero_bn=False, act=True):\n",
    "    bn = nn.BatchNorm2d(nf) # get a 2d batch norm from Pytorhc\n",
    "    nn.init.constant_(bn.weight, 0. if zero_bn else 1.)\n",
    "    layers = [conv(ni, nf, ks, stride=stride), bn]\n",
    "    if act: layers.append(act_fn) # add in the activation function if act is true\n",
    "    return nn.Sequential(*layers)\n",
    "\n",
    "\n",
    "# Resblock\n",
    "class ResBlock(nn.Module):\n",
    "    def __init__(self, expansion, ni, nh, stride = 1):\n",
    "        super().__init__()\n",
    "        # ni - number of inputs channels, nf - number of filters\n",
    "        # nh - number of filters in first conv\n",
    "        # expansion is 1 for resnet 18, 34 and 4 for larger networks\n",
    "        nf, ni = nh*expansion, ni*expansion\n",
    "        layers = [conv_layer(ni, nh, 3, stride = stride), # for resnet < 34 2 convs per resblock\n",
    "                 conv_layer(nh, nf, 3, zero_bn = True, act = False)\n",
    "                 ] if expansion == 1 else [ # for RESNET > 34 then 3 convs per block with bottleneck\n",
    "                            conv_layer(ni, nh, 1),\n",
    "                            conv_layer(nh, nh, 3, stride = stride),\n",
    "                            conv_layer(nh, nf, 1, zero_bn = True, act = False)\n",
    "        ]\n",
    "        self.convs = nn.Sequential(*layers) # Creates the conv layers\n",
    "        self.idconv = noop if ni==nf else conv_layer(ni, nf, 1, act = False) # id convolution ()\n",
    "        self.pool = noop if stride== 1 else nn.AvgPool2d(2, ceil_mode = True) # average pool on \n",
    "        \n",
    "    def forward(self, x): \n",
    "        # Forward function adds the convolution part to the id part \n",
    "        #return act_fn(self.convs(x)) + self.idconv(self.pool(x))\n",
    "        return act_fn(self.convs(x) + self.idconv(self.pool(x)))\n",
    "\n",
    "# XResnet\n",
    "class XResNet(nn.Sequential):\n",
    "    @classmethod\n",
    "    def create(cls, expansion, layers, c_in=3, c_out=1000):\n",
    "        nfs = [c_in, (c_in + 1)*8, 64, 64] # number of filters in stem layer (c_in is number of image channels)\n",
    "        stem = [conv_layer(nfs[i], nfs[i+1], stride=2 if i==0 else 1)\n",
    "            for i in range(3)]\n",
    "\n",
    "        nfs = [64//expansion,64,128,256,512]\n",
    "        res_layers = [cls._make_layer(expansion, nfs[i], nfs[i+1],\n",
    "                                      n_blocks=l, stride=1 if i==0 else 2)\n",
    "                  for i,l in enumerate(layers)]\n",
    "        res = cls(\n",
    "        *stem,\n",
    "        nn.MaxPool2d(kernel_size=3, stride = 2, padding = 1), # then a max pooling layer\n",
    "        *res_layers,\n",
    "        nn.AdaptiveAvgPool2d(1), Flatten(), \n",
    "        nn.Linear(nfs[-1]*expansion, c_out)\n",
    "        )\n",
    "        init_cnn(res)\n",
    "        return res\n",
    "        \n",
    "    @staticmethod\n",
    "    def _make_layer(expansion, ni, nf, n_blocks, stride): # returns a resblock\n",
    "        return nn.Sequential(\n",
    "        *[ResBlock(expansion, ni if i==0 else nf, nf, stride if i==0 else 1)\n",
    "         for i in range(n_blocks)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def xresnet18 (**kwargs): return XResNet.create(1, [2, 2,  2, 2], **kwargs)\n",
    "def xresnet34 (**kwargs): return XResNet.create(1, [3, 4,  6, 3], **kwargs)\n",
    "def xresnet50 (**kwargs): return XResNet.create(4, [3, 4,  6, 3], **kwargs)\n",
    "model18 = xresnet18(c_in = 1, c_out = 2)\n",
    "model34 = xresnet34(c_in = 1, c_out = 2)\n",
    "model50 = xresnet50(c_in = 1, c_out = 2)\n",
    "\n",
    "\n",
    "# Label smoothing cross entropy\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "def reduce_loss(loss, reduction='mean'):\n",
    "    return loss.mean() if reduction=='mean' else loss.sum() if reduction=='sum' else loss\n",
    "\n",
    "class LabelSmoothingCrossEntropy(nn.Module):\n",
    "    def __init__(self, ε:float=0.1, reduction='mean'):\n",
    "        super().__init__()\n",
    "        self.ε,self.reduction = ε,reduction\n",
    "    \n",
    "    def forward(self, output, target):\n",
    "        c = output.size()[-1]\n",
    "        log_preds = F.log_softmax(output, dim=-1)\n",
    "        loss = reduce_loss(-log_preds.sum(dim=-1), self.reduction)\n",
    "        nll = F.nll_loss(log_preds, target, reduction=self.reduction)\n",
    "        return lin_comb(loss/c, nll, self.ε)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions that shows the image, true class, predicted class and degree of prediction\n",
    "\n",
    "def images_to_probs(net, images):\n",
    "    '''\n",
    "    Generates predictions and corresponding probabilities from a trained\n",
    "    network and a list of images\n",
    "    '''\n",
    "    output = net(images)\n",
    "    # convert output probabilities to predicted class\n",
    "    _, preds_tensor = torch.max(output, 1)\n",
    "    preds = np.squeeze(preds_tensor.numpy())\n",
    "    return preds, [F.softmax(el, dim=0)[i].item() for i, el in zip(preds, output)]\n",
    "\n",
    "\n",
    "def plot_classes_preds(net, images, labels):\n",
    "    '''\n",
    "    Generates matplotlib Figure using a trained network, along with images\n",
    "    and labels from a batch, that shows the network's top prediction along\n",
    "    with its probability, alongside the actual label, coloring this\n",
    "    information based on whether the prediction was correct or not.\n",
    "    Uses the \"images_to_probs\" function.\n",
    "    '''\n",
    "    preds, probs = images_to_probs(net, images)\n",
    "    # plot the images in the batch, along with predicted and true labels\n",
    "    fig = plt.figure(figsize=(12, 48))\n",
    "    for idx in np.arange(4):\n",
    "        ax = fig.add_subplot(1, 4, idx+1, xticks=[], yticks=[])\n",
    "        matplotlib_imshow(images[idx], one_channel=True)\n",
    "        ax.set_title(\"{0}, {1:.1f}%\\n(label: {2})\".format(\n",
    "            labels[preds[idx]],\n",
    "            probs[idx] * 100.0,\n",
    "            labels[labels[idx]]),\n",
    "                    color=(\"green\" if preds[idx]==labels[idx].item() else \"red\"))\n",
    "    return fig\n",
    "\n",
    "def matplotlib_imshow(img, one_channel=True):\n",
    "    if one_channel:\n",
    "        img = img.mean(dim=0)\n",
    "    img = img / 2 + 0.5     # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    if one_channel:\n",
    "        plt.imshow(npimg, cmap=\"Greys\")\n",
    "    else:\n",
    "        plt.imshow(np.transpose(npimg, (1, 2, 0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def confusion_matrix_calc(data_loader_test, classes, model_ft):       \n",
    "        y_pred = []\n",
    "        y_true = []\n",
    "        for inputs, labels, imNo in data_loader_test:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "                output = model_ft(inputs) # Feed Network\n",
    "\n",
    "                output = (torch.max(torch.exp(output), 1)[1]).data.cpu().numpy()\n",
    "                y_pred.extend(output) # Save Prediction\n",
    "                \n",
    "                labels = labels.data.cpu().numpy()\n",
    "                y_true.extend(labels) # Save Truth\n",
    "\n",
    "        # constant for classes\n",
    "        # classes = ('Alive', 'Dead')\n",
    "\n",
    "        # Build confusion matrix\n",
    "        cf_matrix = confusion_matrix(y_true, y_pred)\n",
    "        return cf_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(92178, {'train': 92178, 'val': 39505})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(10)\n",
    "imIdx = torch.randperm(1).tolist()\n",
    "\n",
    "## Create dataset\n",
    "dataSetTrain = DNADataset(imDr, get_transform(train = True), labels, imDx=imIdx)\n",
    "dataSetTest = DNADataset(imDr, get_transform(train = False), labels, imDx=imIdx)\n",
    "\n",
    "# ## Create dataloaders\n",
    "# Get subset\n",
    "torch.manual_seed(10)\n",
    "indices = torch.randperm(len(dataSetTrain)).tolist()\n",
    "\n",
    "noTrain = int(len(dataSetTrain)*0.7)\n",
    "\n",
    "dataset_train = torch.utils.data.Subset(dataSetTrain, indices[-noTrain:])\n",
    "\n",
    "dataset_test = torch.utils.data.Subset(dataSetTest, indices[:-noTrain])\n",
    "#len(indices), len(indices[:-50]), len(indices[-50:]), 50/191, type(dataset_test)\n",
    "\n",
    "dataset_sizes = {'train': len(dataset_train), 'val': len(dataset_test)}\n",
    "\n",
    "# define training and validation data loaders\n",
    "data_loader_train = torch.utils.data.DataLoader(\n",
    "    dataset_train, batch_size=128, shuffle=True, num_workers=0)\n",
    "\n",
    "data_loader_test = torch.utils.data.DataLoader(\n",
    "    dataset_test, batch_size=128, shuffle=False, num_workers=0)\n",
    "\n",
    "# Collate function (gathers together the outputs)\n",
    "# def collate_fn(batch):\n",
    "#     return tuple(zip(*batch))\n",
    "\n",
    "len(indices[-noTrain:]), dataset_sizes\n",
    "#dataset_test[0][1], dataset_test[3][1], dataset_test[-1][1], dataSetTrain.imgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/9\n",
      "----------\n",
      "train Loss: 0.6128 Acc: 0.7229\n",
      "val Loss: 1.2424 Acc: 0.5752\n",
      "\n",
      "Epoch 1/9\n",
      "----------\n",
      "train Loss: 0.4542 Acc: 0.7985\n",
      "val Loss: 1.1330 Acc: 0.5817\n",
      "\n",
      "Epoch 2/9\n",
      "----------\n",
      "train Loss: 0.4210 Acc: 0.8137\n",
      "val Loss: 0.6184 Acc: 0.6513\n",
      "\n",
      "Epoch 3/9\n",
      "----------\n",
      "train Loss: 0.4041 Acc: 0.8223\n",
      "val Loss: 0.7367 Acc: 0.5943\n",
      "\n",
      "Epoch 4/9\n",
      "----------\n",
      "train Loss: 0.3927 Acc: 0.8260\n",
      "val Loss: 0.4648 Acc: 0.7854\n",
      "\n",
      "Epoch 5/9\n",
      "----------\n",
      "train Loss: 0.3853 Acc: 0.8335\n",
      "val Loss: 0.4158 Acc: 0.8310\n",
      "\n",
      "Epoch 6/9\n",
      "----------\n",
      "train Loss: 0.3762 Acc: 0.8357\n",
      "val Loss: 0.6494 Acc: 0.6552\n",
      "\n",
      "Epoch 7/9\n",
      "----------\n",
      "train Loss: 0.3472 Acc: 0.8533\n",
      "val Loss: 0.3694 Acc: 0.8410\n",
      "\n",
      "Epoch 8/9\n",
      "----------\n",
      "train Loss: 0.3311 Acc: 0.8593\n",
      "val Loss: 0.3645 Acc: 0.8435\n",
      "\n",
      "Epoch 9/9\n",
      "----------\n",
      "train Loss: 0.3277 Acc: 0.8614\n",
      "val Loss: 0.3692 Acc: 0.8428\n",
      "\n",
      "Training complete in 28m 30s\n",
      "Best val Acc: 0.843536\n",
      "[[ 2565   427]\n",
      " [ 6215 30298]]\n",
      "Epoch 0/9\n",
      "----------\n",
      "train Loss: 0.5912 Acc: 0.7369\n",
      "val Loss: 1.4667 Acc: 0.5005\n",
      "\n",
      "Epoch 1/9\n",
      "----------\n",
      "train Loss: 0.4501 Acc: 0.7986\n",
      "val Loss: 0.5763 Acc: 0.6705\n",
      "\n",
      "Epoch 2/9\n",
      "----------\n",
      "train Loss: 0.4243 Acc: 0.8116\n",
      "val Loss: 0.7893 Acc: 0.5649\n",
      "\n",
      "Epoch 3/9\n",
      "----------\n",
      "train Loss: 0.4065 Acc: 0.8207\n",
      "val Loss: 0.5695 Acc: 0.7504\n",
      "\n",
      "Epoch 4/9\n",
      "----------\n",
      "train Loss: 0.3963 Acc: 0.8264\n",
      "val Loss: 0.8136 Acc: 0.5383\n",
      "\n",
      "Epoch 5/9\n",
      "----------\n",
      "train Loss: 0.3840 Acc: 0.8317\n",
      "val Loss: 0.3876 Acc: 0.8255\n",
      "\n",
      "Epoch 6/9\n",
      "----------\n",
      "train Loss: 0.3739 Acc: 0.8381\n",
      "val Loss: 0.4052 Acc: 0.8223\n",
      "\n",
      "Epoch 7/9\n",
      "----------\n",
      "train Loss: 0.3377 Acc: 0.8576\n",
      "val Loss: 0.4300 Acc: 0.8135\n",
      "\n",
      "Epoch 8/9\n",
      "----------\n",
      "train Loss: 0.3304 Acc: 0.8584\n",
      "val Loss: 0.3610 Acc: 0.8424\n",
      "\n",
      "Epoch 9/9\n",
      "----------\n",
      "train Loss: 0.3246 Acc: 0.8638\n",
      "val Loss: 0.3658 Acc: 0.8430\n",
      "\n",
      "Training complete in 31m 39s\n",
      "Best val Acc: 0.843002\n",
      "[[ 2565   427]\n",
      " [ 6254 30259]]\n",
      "Epoch 0/9\n",
      "----------\n",
      "train Loss: 0.8178 Acc: 0.7221\n",
      "val Loss: 0.7832 Acc: 0.5563\n",
      "\n",
      "Epoch 1/9\n",
      "----------\n",
      "train Loss: 0.4527 Acc: 0.8005\n",
      "val Loss: 0.8088 Acc: 0.5251\n",
      "\n",
      "Epoch 2/9\n",
      "----------\n",
      "train Loss: 0.4267 Acc: 0.8109\n",
      "val Loss: 0.4685 Acc: 0.7977\n",
      "\n",
      "Epoch 3/9\n",
      "----------\n",
      "train Loss: 0.4140 Acc: 0.8171\n",
      "val Loss: 1.5929 Acc: 0.5028\n",
      "\n",
      "Epoch 4/9\n",
      "----------\n",
      "train Loss: 0.4039 Acc: 0.8220\n",
      "val Loss: 1.0681 Acc: 0.5045\n",
      "\n",
      "Epoch 5/9\n",
      "----------\n",
      "train Loss: 0.3952 Acc: 0.8275\n",
      "val Loss: 0.5085 Acc: 0.7399\n",
      "\n",
      "Epoch 6/9\n",
      "----------\n",
      "train Loss: 0.3853 Acc: 0.8321\n",
      "val Loss: 1.4515 Acc: 0.5189\n",
      "\n",
      "Epoch 7/9\n",
      "----------\n",
      "train Loss: 0.3554 Acc: 0.8478\n",
      "val Loss: 0.3760 Acc: 0.8367\n",
      "\n",
      "Epoch 8/9\n",
      "----------\n",
      "train Loss: 0.3500 Acc: 0.8520\n",
      "val Loss: 0.3986 Acc: 0.8258\n",
      "\n",
      "Epoch 9/9\n",
      "----------\n",
      "train Loss: 0.3430 Acc: 0.8550\n",
      "val Loss: 0.3741 Acc: 0.8400\n",
      "\n",
      "Training complete in 36m 5s\n",
      "Best val Acc: 0.840029\n",
      "[[ 2466   526]\n",
      " [ 5263 31250]]\n",
      "Epoch 0/9\n",
      "----------\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "only batches of spatial targets supported (3D tensors) but got targets of size: : [128]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_873/3137834303.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     21\u001b[0m                 \u001b[0moptimizer_ft\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSGD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmomentum\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mMomentum\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m                 \u001b[0mexp_lr_scheduler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlr_scheduler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mStepLR\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer_ft\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgamma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mGAMMA\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m                 model_ft, con_mat = train_model(model, criterion, optimizer_ft, exp_lr_scheduler,\n\u001b[0m\u001b[1;32m     24\u001b[0m                    data_loader_train,data_loader_test,num_epochs=10)\n\u001b[1;32m     25\u001b[0m                 \u001b[0mcf_matrix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfusion_matrix_calc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_loader_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_ft\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_873/3239080070.py\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, criterion, optimizer, scheduler, dataloaderTrain, dataloaderTest, num_epochs)\u001b[0m\n\u001b[1;32m     41\u001b[0m                         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m                         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m                         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m                         \u001b[0;31m# backward + optimize only if in training phase\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m                         \u001b[0;32mif\u001b[0m \u001b[0mphase\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'train'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/nn/modules/loss.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m   1148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1149\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1150\u001b[0;31m         return F.cross_entropy(input, target, weight=self.weight,\n\u001b[0m\u001b[1;32m   1151\u001b[0m                                \u001b[0mignore_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mignore_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1152\u001b[0m                                label_smoothing=self.label_smoothing)\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mcross_entropy\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction, label_smoothing)\u001b[0m\n\u001b[1;32m   2847\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msize_average\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mreduce\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2848\u001b[0m         \u001b[0mreduction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_get_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize_average\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2849\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcross_entropy_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_enum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_smoothing\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2850\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2851\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: only batches of spatial targets supported (3D tensors) but got targets of size: : [128]"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x504 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x504 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x504 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "class_weights= [0.924865,0.075135] #1-(#inclass/ #intotal )\n",
    "class_weights = torch.Tensor(class_weights)\n",
    "class_weights=class_weights.to(device)\n",
    "criterion = nn.CrossEntropyLoss(weight = class_weights) \n",
    "\n",
    "# Observe that all parameters are being optimized\n",
    "learning_rate=[0.2]#0.05,0.1,0.2,0.5]\n",
    "Momentum=[0.1,0.5]#,0.9,0.99]\n",
    "GAMMA=[0.05,0.1]#, 0.5, 0.8]\n",
    "#Batch_size= [16,32]#,64,128]\n",
    "model=[model18,model34,model50]\n",
    "\n",
    "#ADD IN A THING SO IT SAVES THE TENSORBOARD TO DIFFERENT BITS\n",
    "\n",
    "for learning_rate in learning_rate:\n",
    "    for GAMMA in GAMMA:\n",
    "        for Momentum in Momentum:\n",
    "            for model in model:\n",
    "                model = model.to(device)\n",
    "                # Decay LR by a factor of gamma every 7 epochs\n",
    "                optimizer_ft = optim.SGD(model.parameters(), lr=learning_rate, momentum=Momentum)\n",
    "                exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=GAMMA)\n",
    "                model_ft, con_mat = train_model(model, criterion, optimizer_ft, exp_lr_scheduler,\n",
    "                   data_loader_train,data_loader_test,num_epochs=10)\n",
    "                cf_matrix = confusion_matrix_calc(data_loader_test, labels, model_ft)\n",
    "                print(cf_matrix)\n",
    "                df_cm_ratio = pd.DataFrame(cf_matrix / np.sum(cf_matrix, axis=1)[:, None], index=[i for i in labels],\n",
    "                     columns=[i for i in labels])\n",
    "                plt.figure(figsize=(12, 7))\n",
    "                sn.heatmap(df_cm_ratio, annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#model_ft, con_mat = train_model(model, criterion, optimizer_ft, exp_lr_scheduler, \n",
    "                                    #data_loader_train,data_loader_test,num_epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cf_matrix = confusion_matrix_calc(data_loader_test, labels, model_ft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cm_ratio = pd.DataFrame(cf_matrix / np.sum(cf_matrix, axis=1)[:, None], index=[i for i in labels],\n",
    "                     columns=[i for i in labels])\n",
    "plt.figure(figsize=(12, 7))\n",
    "sn.heatmap(df_cm_ratio, annot=True)\n",
    "# plt.save(\"Confusion_matrix_ratio.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_cm_raw = pd.DataFrame(cf_matrix, index=[i for i in labels],\n",
    "                     columns=[i for i in labels])\n",
    "plt.figure(figsize=(12, 7))\n",
    "sn.heatmap(df_cm_raw, annot=True)\n",
    "# plt.save(\"Confusion_matrix_raw.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cf_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "7\n",
      "8\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "x=[5,7,8,4]\n",
    "for x in x:\n",
    "    print(x)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
