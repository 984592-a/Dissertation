{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To note: Running this on different systems (i.e. local, SCW, server) will result in slight changes needing to the code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/scipy/__init__.py:138: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.4)\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion} is required for this version of \"\n"
     ]
    }
   ],
   "source": [
    "# Load libraries\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import sys\n",
    "import torchvision\n",
    "import torchvision.transforms as T\n",
    "import torchvision.models as models\n",
    "from PIL import Image\n",
    "from PIL import ImageEnhance\n",
    "import matplotlib.pyplot as plt\n",
    "import imagesize\n",
    "import subprocess\n",
    "sys.path\n",
    "from IPython.core.debugger import set_trace\n",
    "import scipy.ndimage\n",
    "import matplotlib.patches as patches\n",
    "# plt.rcParams['figure.figsize'] = [12,12]\n",
    "# sys.path.append('/workspace/myFile/Mask_RCNN_Tutorial/')\n",
    "from tqdm import tqdm\n",
    "from torch import nn as nn\n",
    "from torch import optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "import re\n",
    "import time\n",
    "import copy\n",
    "import pylab\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from tempfile import TemporaryDirectory\n",
    "import torch.backends.cudnn as cudnn\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "import seaborn as sn\n",
    "import pandas as pd\n",
    "import glob\n",
    "# Rather than have a messy notebook with a load of functions we can store them in separate .py files and import them\n",
    "\n",
    "cudnn.benchmark = True\n",
    "plt.ion()   # interactive mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "writer = SummaryWriter(\"Experiments/TENSORBOARD\")    # This determines the tensorboard file name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DNADataset(object):\n",
    "    def __init__(self, root, transforms, labels, imDx = False):\n",
    "        self.root, self.transforms, self.labels = root, transforms, labels\n",
    "        self.imgDir=[]\n",
    "        # load all image files, sorting them to ensure they are aligned\n",
    "        for drug in [\"A\",\"B\",\"C\",\"D\",\"E\",\"F\"]:\n",
    "            self.imgDir = self.imgDir+glob.glob(root+drug+\"04*/*.tiff\")\n",
    "            self.imgDir = self.imgDir +glob.glob(root+drug+\"05*/*.tiff\")\n",
    "            self.imgDir =self.imgDir+ glob.glob(root+drug+\"06*/*.tiff\")\n",
    "        Damagednuclei= [x for x in self.imgDir if 'Damaged_nuclei_' in x]\n",
    "        Undamagednuclei= [x for x in self.imgDir if \"No_damage_nuclei\" in x]\n",
    "        #np.random.shuffle(Undamagednuclei)\n",
    "        #Undamagednuclei=Undamagednuclei[:10000]\n",
    "        self.imgDir= Damagednuclei+Undamagednuclei\n",
    "        size80=[]\n",
    "        for x in self.imgDir:\n",
    "            img = Image.open(x) # Open image\n",
    "            w,h=img.size\n",
    "            if w<=80 and h<=80:\n",
    "                size80.append(x)\n",
    "        self.imgDir=size80              \n",
    "        \n",
    "        self.imgs = sorted(self.imgDir) # list of images\n",
    "\n",
    "        \n",
    "\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.imgs[idx]\n",
    "       \n",
    "        # Transform images into tensors\n",
    "        img = Image.open(img_path) # Open image\n",
    "        w,h=img.size\n",
    "        img = np.array(img) # Convert image into an array\n",
    "        img = np.float32(np.divide(img, 2**16)) # Ensure all values are floats\n",
    "        \n",
    "        result=np.zeros((80,80), dtype=np.float32)\n",
    "        x_center = (80 - w) // 2\n",
    "        y_center = (80 - h) // 2 # copy img image into center of result image\n",
    "        result[y_center:y_center+h, x_center:x_center+w] = img\n",
    "        img = result\n",
    "        \n",
    "        targetlab=\"\"\n",
    "        if img_path.find('No_damage_nuclei') != -1:\n",
    "            targetlab= 'Undamaged'\n",
    "        if img_path.find('Damaged_nuclei_') != -1:\n",
    "            targetlab= 'Damaged'  # Find labels corresponding to image\n",
    "        target = self.labels.index(targetlab) # Get the label and assign to a value\n",
    "        \n",
    "        # Convert label to tensor\n",
    "        #torch.to\n",
    "        \n",
    "        if self.transforms is not None:\n",
    "            img = self.transforms(img)\n",
    "#             #print('In the transforms')\n",
    "        imNo = idx\n",
    "        return img, target, imNo\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.imgs)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "imDr = \"/workspace/myFile/Output/17052023/\"  # Image patches directory\n",
    "\n",
    "labels = ['Damaged', 'Undamaged']  # Your labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For data augmentation\n",
    "def get_transform(train):\n",
    "    transforms = []\n",
    "\n",
    "    transforms.append(T.ToTensor())\n",
    "    #transforms.append(T.Normalize([0.0019368887995516483], [0.00672996630111016]))\n",
    "    #transforms.append(T.RandomHorizontalFlip(0.5))\n",
    "    \n",
    "    if train:\n",
    "        transforms.append(T.RandomHorizontalFlip(p=1))\n",
    "        transforms.append(T.RandomVerticalFlip(p=1))\n",
    "    \n",
    "    return T.Compose(transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, scheduler, train, test, num_epochs=25):\n",
    "    since = time.time()\n",
    "    # Create a temporary directory to save training checkpoints\n",
    "    with TemporaryDirectory() as tempdir:\n",
    "        best_model_params_path = os.path.join(tempdir, 'best_model_params.pt')\n",
    "\n",
    "        torch.save(model.state_dict(), best_model_params_path)\n",
    "        best_acc = 0.0\n",
    "        \n",
    "        for epoch in range(num_epochs):\n",
    "            print(f'Epoch {epoch}/{num_epochs - 1}')\n",
    "            print('-' * 10)\n",
    "            dataset_train = torch.utils.data.Subset(dataSetTrain, train[epoch])\n",
    "            dataset_test = torch.utils.data.Subset(dataSetTest, test[epoch])\n",
    "            data_loader_train = torch.utils.data.DataLoader(\n",
    "                dataset_train, batch_size=128, shuffle=True, num_workers=0)\n",
    "\n",
    "            data_loader_test = torch.utils.data.DataLoader(\n",
    "                dataset_test, batch_size=128, shuffle=False, num_workers=0)\n",
    "            # Each epoch has a training and validation phase\n",
    "            for phase in ['val']:\n",
    "                if phase == 'train':\n",
    "                    model.train()  # Set model to training mode\n",
    "                    dataloaders = data_loader_train\n",
    "                else:\n",
    "                    model.eval()   # Set model to evaluate mode\n",
    "                    dataloaders = data_loader_test\n",
    "\n",
    "                running_loss = 0.0\n",
    "                running_corrects = 0\n",
    "                damaged_len=0\n",
    "                damaged_corrects = 0\n",
    "                undamaged_len=0\n",
    "                undamaged_corrects = 0\n",
    "\n",
    "                # Iterate over data.\n",
    "                for inputs, labels, imNo in dataloaders:\n",
    "                    inputs = inputs.to(device)\n",
    "                    labels = labels.to(device)\n",
    "\n",
    "                    # zero the parameter gradients\n",
    "                    optimizer.zero_grad()\n",
    "\n",
    "                    # forward\n",
    "                    # track history if only in train\n",
    "                    with torch.set_grad_enabled(phase == 'train'):\n",
    "                        outputs = model(inputs)\n",
    "                        _, preds = torch.max(outputs, 1)\n",
    "                        loss = criterion(outputs, labels)\n",
    "                        # backward + optimize only if in training phase\n",
    "                        if phase == 'train':\n",
    "                            loss.backward()\n",
    "                            optimizer.step()\n",
    "\n",
    "                    # statistics\n",
    "                    running_loss += loss.item() * inputs.size(0)    # Loss\n",
    "                    nada=torch.tensor(np.zeros(len(labels))).to(device)\n",
    "                    uno=nada+1\n",
    "                    falseneg=preds+1\n",
    "                    falsepos=preds-1\n",
    "                    FPplusTN=torch.sum(labels==nada)\n",
    "                    TPplusFN=torch.sum(labels==uno)\n",
    "                    FN=torch.sum(labels==falseneg)\n",
    "                    FP=torch.sum(labels==falsepos)\n",
    "                    TN=FPplusTN-FP\n",
    "                    TP=TPplusFN-FN\n",
    "                    running_corrects += torch.sum(preds == labels.data) # Accuracy\n",
    "                    damaged_len+=TPplusFN\n",
    "                    damaged_corrects += TP\n",
    "                    undamaged_len+=FPplusTN\n",
    "                    undamaged_corrects += TN\n",
    "                damaged_acc = damaged_corrects / damaged_len\n",
    "                undamaged_acc = undamaged_corrects/undamaged_len\n",
    "                epoch_acc= (damaged_acc+undamaged_acc)/2\n",
    "                proper_acc=(damaged_corrects+undamaged_corrects)/(damaged_len+undamaged_len)\n",
    "                if phase == 'train':\n",
    "                    scheduler.step()\n",
    "\n",
    "                epoch_loss = running_loss / dataset_sizes[phase]    # Loss metric per epoch\n",
    "                #epoch_acc = running_corrects.double() / dataset_sizes[phase]    # Accuracy metric per epoch\n",
    "\n",
    "                if phase == \"train\":    # This is the tensorboard code that writes accuracy and loss metrics\n",
    "                    writer.add_scalar(\"Train/Accuracy\", epoch_acc, epoch)\n",
    "                    writer.add_scalar(\"Train/Loss\", epoch_loss, epoch)\n",
    "                else:\n",
    "                    writer.add_scalar(\"Validation/Accuracy\", epoch_acc, epoch)\n",
    "                    writer.add_scalar(\"Validation/Loss\", epoch_loss, epoch)\n",
    "\n",
    "                print(f'{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n",
    "                print(\"proper accuracy=\")\n",
    "                print(proper_acc)\n",
    "                print(\"damaged accuracy=\")\n",
    "                print(damaged_acc)\n",
    "                print(\"undamaged accuracy=\")\n",
    "                print(undamaged_acc)\n",
    "                con_matter= torch.tensor([[damaged_corrects, damaged_len-damaged_corrects],[undamaged_len-undamaged_corrects,undamaged_corrects]])\n",
    "                con_matter=con_matter.cpu().numpy()\n",
    "                print(con_matter)\n",
    "                # deep copy the model\n",
    "                if phase == 'val' and epoch_acc >= best_acc: \n",
    "                    # This compares validation accuracy to previous bests and adjusts model weights accordingly\n",
    "                    best_acc = epoch_acc\n",
    "                    torch.save(model.state_dict(), best_model_params_path)\n",
    "                    con_mat= torch.tensor([[damaged_corrects, damaged_len-damaged_corrects],[undamaged_len-undamaged_corrects,undamaged_corrects]])\n",
    "\n",
    "            print()\n",
    "\n",
    "        time_elapsed = time.time() - since  # Nice way to measure training time but info also stored (indirectly) by tensorboard\n",
    "        print(\n",
    "            f'Training complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')\n",
    "        print(f'Best val Acc: {best_acc:4f}')\n",
    "        #labels= labels.cpu().numpy()\n",
    "        #preds=preds.cpu().numpy()\n",
    "        model.load_state_dict(torch.load(best_model_params_path))\n",
    "    writer.close()\n",
    "    return model, con_mat   # We want to return the model because its the model, also confusion matrix for later analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is your RESNET\n",
    "# Initialize CNN with kaiming\n",
    "def init_cnn(m):\n",
    "    # Set the weights of the RESNET\n",
    "    if getattr(m, 'bias', None) is not None: nn.init.constant_(m.bias, 0)\n",
    "    if isinstance(m, (nn.Conv2d,nn.Linear)): nn.init.kaiming_normal_(m.weight)\n",
    "    for l in m.children(): init_cnn(l)\n",
    "\n",
    "\n",
    "# noop function for returning nothing\n",
    "def noop(x): return x\n",
    "# activation function(RELU)\n",
    "act_fn = nn.ReLU(inplace=True)\n",
    "\n",
    "# Flatten\n",
    "class Flatten(nn.Module):\n",
    "    def forward(self, x): return x.view(x.size(0), -1)\n",
    "\n",
    "# Make a convolution\n",
    "def conv(ni, nf, ks=3, stride=1, bias=False):\n",
    "    return nn.Conv2d(ni, nf, kernel_size=ks, stride=stride, padding=ks//2, bias=bias)\n",
    "\n",
    "# Create a convuolutional layer with convolution and batch norm\n",
    "def conv_layer(ni, nf, ks=3, stride=1, zero_bn=False, act=True):\n",
    "    bn = nn.BatchNorm2d(nf) # get a 2d batch norm from Pytorhc\n",
    "    nn.init.constant_(bn.weight, 0. if zero_bn else 1.)\n",
    "    layers = [conv(ni, nf, ks, stride=stride), bn]\n",
    "    if act: layers.append(act_fn) # add in the activation function if act is true\n",
    "    return nn.Sequential(*layers)\n",
    "\n",
    "\n",
    "# Resblock\n",
    "class ResBlock(nn.Module):\n",
    "    def __init__(self, expansion, ni, nh, stride = 1):\n",
    "        super().__init__()\n",
    "        # ni - number of inputs channels, nf - number of filters\n",
    "        # nh - number of filters in first conv\n",
    "        # expansion is 1 for resnet 18, 34 and 4 for larger networks\n",
    "        nf, ni = nh*expansion, ni*expansion\n",
    "        layers = [conv_layer(ni, nh, 3, stride = stride), # for resnet < 34 2 convs per resblock\n",
    "                 conv_layer(nh, nf, 3, zero_bn = True, act = False)\n",
    "                 ] if expansion == 1 else [ # for RESNET > 34 then 3 convs per block with bottleneck\n",
    "                            conv_layer(ni, nh, 1),\n",
    "                            conv_layer(nh, nh, 3, stride = stride),\n",
    "                            conv_layer(nh, nf, 1, zero_bn = True, act = False)\n",
    "        ]\n",
    "        self.convs = nn.Sequential(*layers) # Creates the conv layers\n",
    "        self.idconv = noop if ni==nf else conv_layer(ni, nf, 1, act = False) # id convolution ()\n",
    "        self.pool = noop if stride== 1 else nn.AvgPool2d(2, ceil_mode = True) # average pool on \n",
    "        \n",
    "    def forward(self, x): \n",
    "        # Forward function adds the convolution part to the id part \n",
    "        #return act_fn(self.convs(x)) + self.idconv(self.pool(x))\n",
    "        return act_fn(self.convs(x) + self.idconv(self.pool(x)))\n",
    "\n",
    "# XResnet\n",
    "class XResNet(nn.Sequential):\n",
    "    @classmethod\n",
    "    def create(cls, expansion, layers, c_in=3, c_out=1000):\n",
    "        nfs = [c_in, (c_in + 1)*8, 64, 64] # number of filters in stem layer (c_in is number of image channels)\n",
    "        stem = [conv_layer(nfs[i], nfs[i+1], stride=2 if i==0 else 1)\n",
    "            for i in range(3)]\n",
    "\n",
    "        nfs = [64//expansion,64,128,256,512]\n",
    "        res_layers = [cls._make_layer(expansion, nfs[i], nfs[i+1],\n",
    "                                      n_blocks=l, stride=1 if i==0 else 2)\n",
    "                  for i,l in enumerate(layers)]\n",
    "        res = cls(\n",
    "        *stem,\n",
    "        nn.MaxPool2d(kernel_size=3, stride = 2, padding = 1), # then a max pooling layer\n",
    "        *res_layers,\n",
    "        nn.AdaptiveAvgPool2d(1), Flatten(), \n",
    "        nn.Linear(nfs[-1]*expansion, c_out)\n",
    "        )\n",
    "        init_cnn(res)\n",
    "        return res\n",
    "        \n",
    "    @staticmethod\n",
    "    def _make_layer(expansion, ni, nf, n_blocks, stride): # returns a resblock\n",
    "        return nn.Sequential(\n",
    "        *[ResBlock(expansion, ni if i==0 else nf, nf, stride if i==0 else 1)\n",
    "         for i in range(n_blocks)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def xresnet18 (**kwargs): return XResNet.create(1, [2, 2,  2, 2], **kwargs)\n",
    "def xresnet34 (**kwargs): return XResNet.create(1, [3, 4,  6, 3], **kwargs)\n",
    "def xresnet50 (**kwargs): return XResNet.create(4, [3, 4,  6, 3], **kwargs)\n",
    "model = xresnet18(c_in = 1, c_out = 2)\n",
    "#model34 = xresnet34(c_in = 1, c_out = 2)\n",
    "#model50 = xresnet50(c_in = 1, c_out = 2)\n",
    "model.load_state_dict(torch.load(\"/workspace/myFile/Output/17052023/best_model_params.pt\"))\n",
    "model = model.to(device)\n",
    "\n",
    "# Label smoothing cross entropy\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "def reduce_loss(loss, reduction='mean'):\n",
    "    return loss.mean() if reduction=='mean' else loss.sum() if reduction=='sum' else loss\n",
    "\n",
    "class LabelSmoothingCrossEntropy(nn.Module):\n",
    "    def __init__(self, ε:float=0.1, reduction='mean'):\n",
    "        super().__init__()\n",
    "        self.ε,self.reduction = ε,reduction\n",
    "    \n",
    "    def forward(self, output, target):\n",
    "        c = output.size()[-1]\n",
    "        log_preds = F.log_softmax(output, dim=-1)\n",
    "        loss = reduce_loss(-log_preds.sum(dim=-1), self.reduction)\n",
    "        nll = F.nll_loss(log_preds, target, reduction=self.reduction)\n",
    "        return lin_comb(loss/c, nll, self.ε)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions that shows the image, true class, predicted class and degree of prediction\n",
    "\n",
    "def images_to_probs(net, images):\n",
    "    '''\n",
    "    Generates predictions and corresponding probabilities from a trained\n",
    "    network and a list of images\n",
    "    '''\n",
    "    output = net(images)\n",
    "    # convert output probabilities to predicted class\n",
    "    _, preds_tensor = torch.max(output, 1)\n",
    "    preds = np.squeeze(preds_tensor.numpy())\n",
    "    return preds, [F.softmax(el, dim=0)[i].item() for i, el in zip(preds, output)]\n",
    "\n",
    "\n",
    "def plot_classes_preds(net, images, labels):\n",
    "    '''\n",
    "    Generates matplotlib Figure using a trained network, along with images\n",
    "    and labels from a batch, that shows the network's top prediction along\n",
    "    with its probability, alongside the actual label, coloring this\n",
    "    information based on whether the prediction was correct or not.\n",
    "    Uses the \"images_to_probs\" function.\n",
    "    '''\n",
    "    preds, probs = images_to_probs(net, images)\n",
    "    # plot the images in the batch, along with predicted and true labels\n",
    "    fig = plt.figure(figsize=(12, 48))\n",
    "    for idx in np.arange(4):\n",
    "        ax = fig.add_subplot(1, 4, idx+1, xticks=[], yticks=[])\n",
    "        matplotlib_imshow(images[idx], one_channel=True)\n",
    "        ax.set_title(\"{0}, {1:.1f}%\\n(label: {2})\".format(\n",
    "            labels[preds[idx]],\n",
    "            probs[idx] * 100.0,\n",
    "            labels[labels[idx]]),\n",
    "                    color=(\"green\" if preds[idx]==labels[idx].item() else \"red\"))\n",
    "    return fig\n",
    "\n",
    "def matplotlib_imshow(img, one_channel=True):\n",
    "    if one_channel:\n",
    "        img = img.mean(dim=0)\n",
    "    img = img / 2 + 0.5     # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    if one_channel:\n",
    "        plt.imshow(npimg, cmap=\"Greys\")\n",
    "    else:\n",
    "        plt.imshow(np.transpose(npimg, (1, 2, 0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def confusion_matrix_calc(data_loader_test, classes, model_ft):       \n",
    "        y_pred = []\n",
    "        y_true = []\n",
    "        for inputs, labels, imNo in data_loader_test:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "                output = model_ft(inputs) # Feed Network\n",
    "\n",
    "                output = (torch.max(torch.exp(output), 1)[1]).data.cpu().numpy()\n",
    "                y_pred.extend(output) # Save Prediction\n",
    "                \n",
    "                labels = labels.data.cpu().numpy()\n",
    "                y_true.extend(labels) # Save Truth\n",
    "\n",
    "        # constant for classes\n",
    "        # classes = ('Alive', 'Dead')\n",
    "\n",
    "        # Build confusion matrix\n",
    "        cf_matrix = confusion_matrix(y_true, y_pred)\n",
    "        return cf_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "k=5 #NUMBER OF K FOLDS\n",
    "epoch=5 #NUMBER OF EPOCHS\n",
    "\n",
    "torch.manual_seed(10)\n",
    "imIdx = torch.randperm(1).tolist()\n",
    "\n",
    "## Create dataset\n",
    "dataSetTrain = DNADataset(imDr, get_transform(train = True), labels, imDx=imIdx)\n",
    "dataSetTest = DNADataset(imDr, get_transform(train = False), labels, imDx=imIdx)\n",
    "\n",
    "data_loader_train=[]\n",
    "data_loader_test=[]\n",
    "\n",
    "# ## Create dataloaders\n",
    "# Get subset\n",
    "torch.manual_seed(10)\n",
    "indices = torch.randperm(len(dataSetTrain)).tolist()\n",
    "\n",
    "noTrain = int(len(dataSetTrain)*0.7)\n",
    "train=[]\n",
    "test=[]\n",
    "indices = torch.randperm(len(dataSetTrain)).tolist()\n",
    "TotalSet=list(range(len(dataSetTrain)))\n",
    "Kfifth = len(dataSetTrain)//k\n",
    "split= epoch%k\n",
    "train.append(TotalSet[(split+1)*Kfifth:]+TotalSet[:Kfifth*split])\n",
    "\n",
    "indices = torch.randperm(len(dataSetTest)).tolist()\n",
    "TotalSet=list(range(len(dataSetTrain)))\n",
    "test.append(TotalSet)\n",
    "\n",
    "#dataset_train = torch.utils.data.Subset(dataSetTrain, indices[-noTrain:])\n",
    "\n",
    "#dataset_test = torch.utils.data.Subset(dataSetTest, indices[:-noTrain])\n",
    "#len(indices), len(indices[:-50]), len(indices[-50:]), 50/191, type(dataset_test)\n",
    "\n",
    "dataset_sizes = {'train': len(train[0]), 'val': len(test)}\n",
    "\n",
    "#dataset_train = torch.utils.data.Subset(dataSetTrain, train)\n",
    "#data_loader_train.append(dataset_train)\n",
    "#dataset_testo = torch.utils.data.Subset(dataSetTest, test)\n",
    "#data_loader_test.append(dataset_testo)\n",
    "# define training and validation data loaders\n",
    "\n",
    "\n",
    "# Collate function (gathers together the outputs)\n",
    "# def collate_fn(batch):\n",
    "#     return tuple(zip(*batch))\n",
    "\n",
    "#len(indices[-noTrain:]), dataset_sizes\n",
    "#dataset_test[0][1], dataset_test[3][1], dataset_test[-1][1], dataSetTrain.imgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_weights= [0.924865,0.075135] #1-(#inclass/ #intotal )\n",
    "class_weights = torch.Tensor(class_weights)\n",
    "class_weights=class_weights.to(device)\n",
    "criterion = nn.CrossEntropyLoss(weight = class_weights) \n",
    "\n",
    "# Observe that all parameters are being optimized\n",
    "optimizer_ft = optim.Adam(model.parameters(), weight_decay=1e-2) # standard ADAM optimiser\n",
    "\n",
    "# Decay LR by a factor of 0.1 every 7 epochs\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/0\n",
      "----------\n",
      "val Loss: 9217.2987 Acc: 0.9378\n",
      "proper accuracy=\n",
      "tensor(0.9066, device='cuda:0')\n",
      "damaged accuracy=\n",
      "tensor(0.9021, device='cuda:0')\n",
      "undamaged accuracy=\n",
      "tensor(0.9735, device='cuda:0')\n",
      "[[51610  5604]\n",
      " [  103  3781]]\n",
      "\n",
      "Training complete in 1m 10s\n",
      "Best val Acc: 0.937766\n"
     ]
    }
   ],
   "source": [
    "model_ft, con_mat = train_model(model, criterion, optimizer_ft, exp_lr_scheduler, \n",
    "                                    train,test,num_epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cf_matrix = confusion_matrix_calc(data_loader_test, labels, model_ft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x504 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "con_mat=con_mat.cpu().numpy()\n",
    "plotlabels=['Undamaged','Damaged']\n",
    "df_cm_ratio = pd.DataFrame(con_mat / np.sum(con_mat, axis=1)[:, None], index=[i for i in plotlabels],\n",
    "                     columns=[i for i in plotlabels])\n",
    "plt.figure(figsize=(12, 7))\n",
    "sn.heatmap(df_cm_ratio, annot=True)\n",
    "# plt.save(\"Confusion_matrix_ratio.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x504 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_cm_raw = pd.DataFrame(con_mat, index=[i for i in plotlabels],\n",
    "                     columns=[i for i in plotlabels])\n",
    "plt.figure(figsize=(12, 7))\n",
    "sn.heatmap(df_cm_raw, annot=True)\n",
    "# plt.save(\"Confusion_matrix_raw.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[51610,  5604],\n",
       "       [  103,  3781]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "con_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_loader_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotlabels=['Undamaged','Damaged']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
