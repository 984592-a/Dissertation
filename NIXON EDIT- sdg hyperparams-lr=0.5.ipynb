{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To note: Running this on different systems (i.e. local, SCW, server) will result in slight changes needing to the code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/scipy/__init__.py:138: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.4)\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion} is required for this version of \"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.pyplot._IonContext at 0x7f50b19e9970>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load libraries\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import sys\n",
    "import torchvision\n",
    "import torchvision.transforms as T\n",
    "import torchvision.models as models\n",
    "from PIL import Image\n",
    "from PIL import ImageEnhance\n",
    "import matplotlib.pyplot as plt\n",
    "import imagesize\n",
    "import subprocess\n",
    "sys.path\n",
    "from IPython.core.debugger import set_trace\n",
    "import scipy.ndimage\n",
    "import matplotlib.patches as patches\n",
    "# plt.rcParams['figure.figsize'] = [12,12]\n",
    "# sys.path.append('/workspace/myFile/Mask_RCNN_Tutorial/')\n",
    "from tqdm import tqdm\n",
    "from torch import nn as nn\n",
    "from torch import optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "import re\n",
    "import time\n",
    "import copy\n",
    "import pylab\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from tempfile import TemporaryDirectory\n",
    "import torch.backends.cudnn as cudnn\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "import seaborn as sn\n",
    "import pandas as pd\n",
    "import glob\n",
    "# Rather than have a messy notebook with a load of functions we can store them in separate .py files and import them\n",
    "\n",
    "cudnn.benchmark = True\n",
    "plt.ion()   # interactive mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "writer = SummaryWriter(\"Experiments/TENSORBOARD\")    # This determines the tensorboard file name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DNADataset(object):\n",
    "    def __init__(self, root, transforms, labels, imDx = False):\n",
    "        self.root, self.transforms, self.labels = root, transforms, labels\n",
    "    \n",
    "        # load all image files, sorting them to ensure they are aligned\n",
    "        self.imgDir = glob.glob(root+\"*/*.tiff\")\n",
    "        Damagednuclei= [x for x in self.imgDir if 'Damaged_nuclei_' in x]\n",
    "        Undamagednuclei= [x for x in self.imgDir if \"No_damage_nuclei\" in x]\n",
    "        #np.random.shuffle(Undamagednuclei)\n",
    "        #Undamagednuclei=Undamagednuclei[:10000]\n",
    "        self.imgDir= Damagednuclei+Undamagednuclei\n",
    "        size80=[]\n",
    "        for x in self.imgDir:\n",
    "            img = Image.open(x) # Open image\n",
    "            w,h=img.size\n",
    "            if w<=80 and h<=80:\n",
    "                size80.append(x)\n",
    "        self.imgDir=size80              \n",
    "        \n",
    "        self.imgs = sorted(self.imgDir) # list of images\n",
    "\n",
    "        \n",
    "\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.imgs[idx]\n",
    "       \n",
    "        # Transform images into tensors\n",
    "        img = Image.open(img_path) # Open image\n",
    "        w,h=img.size\n",
    "        img = np.array(img) # Convert image into an array\n",
    "        img = np.float32(np.divide(img, 2**16)) # Ensure all values are floats\n",
    "        \n",
    "        result=np.zeros((80,80), dtype=np.float32)\n",
    "        x_center = (80 - w) // 2\n",
    "        y_center = (80 - h) // 2 # copy img image into center of result image\n",
    "        result[y_center:y_center+h, x_center:x_center+w] = img\n",
    "        img = result\n",
    "        \n",
    "        targetlab=\"\"\n",
    "        if img_path.find('No_damage_nuclei') != -1:\n",
    "            targetlab= 'Undamaged'\n",
    "        if img_path.find('Damaged_nuclei_') != -1:\n",
    "            targetlab= 'Damaged'  # Find labels corresponding to image\n",
    "        target = self.labels.index(targetlab) # Get the label and assign to a value\n",
    "        \n",
    "        # Convert label to tensor\n",
    "        #torch.to\n",
    "        \n",
    "        if self.transforms is not None:\n",
    "            img = self.transforms(img)\n",
    "#             #print('In the transforms')\n",
    "        imNo = idx\n",
    "        return img, target, imNo\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.imgs)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "root=\"/workspace/myFile/Output/17052023/\"\n",
    "p= glob.glob(root+\"*/*.tiff\")\n",
    "Damagednuclei= [x for x in p if 'Damaged_nuclei_' in x]\n",
    "Undamagednuclei= [x for x in p if \"No_damage_nuclei\" in x]\n",
    "#np.random.shuffle(Undamagednuclei)\n",
    "#Undamagednuclei=Undamagednuclei[:10000]\n",
    "#Undamagednuclei"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "imDr = \"/workspace/myFile/Output/17052023/\"  # Image patches directory\n",
    "\n",
    "labels = ['Damaged', 'Undamaged']  # Your labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For data augmentation\n",
    "def get_transform(train):\n",
    "    transforms = []\n",
    "\n",
    "    transforms.append(T.ToTensor())\n",
    "    #transforms.append(T.Normalize([0.0019368887995516483], [0.00672996630111016]))\n",
    "    #transforms.append(T.RandomHorizontalFlip(0.5))\n",
    "    \n",
    "    if train:\n",
    "        transforms.append(T.RandomHorizontalFlip(p=1))\n",
    "        transforms.append(T.RandomVerticalFlip(p=1))\n",
    "    \n",
    "    return T.Compose(transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, scheduler, dataloaderTrain, dataloaderTest, num_epochs=25):\n",
    "    since = time.time()\n",
    "    # Create a temporary directory to save training checkpoints\n",
    "    with TemporaryDirectory() as tempdir:\n",
    "        best_model_params_path = os.path.join(tempdir, 'best_model_params.pt')\n",
    "\n",
    "        torch.save(model.state_dict(), best_model_params_path)\n",
    "        best_acc = 0.0\n",
    "        \n",
    "        for epoch in range(num_epochs):\n",
    "            print(f'Epoch {epoch}/{num_epochs - 1}')\n",
    "            print('-' * 10)\n",
    "\n",
    "            # Each epoch has a training and validation phase\n",
    "            for phase in ['train', 'val']:\n",
    "                if phase == 'train':\n",
    "                    model.train()  # Set model to training mode\n",
    "                    dataloaders = dataloaderTrain\n",
    "                else:\n",
    "                    model.eval()   # Set model to evaluate mode\n",
    "                    dataloaders = dataloaderTest\n",
    "\n",
    "                running_loss = 0.0\n",
    "                running_corrects = 0\n",
    "                damaged_len=0\n",
    "                damaged_corrects = 0\n",
    "                undamaged_len=0\n",
    "                undamaged_corrects = 0\n",
    "\n",
    "                # Iterate over data.\n",
    "                for inputs, labels, imNo in dataloaders:\n",
    "                    inputs = inputs.to(device)\n",
    "                    labels = labels.to(device)\n",
    "\n",
    "                    # zero the parameter gradients\n",
    "                    optimizer.zero_grad()\n",
    "\n",
    "                    # forward\n",
    "                    # track history if only in train\n",
    "                    with torch.set_grad_enabled(phase == 'train'):\n",
    "                        outputs = model(inputs)\n",
    "                        _, preds = torch.max(outputs, 1)\n",
    "                        loss = criterion(outputs, labels)\n",
    "                        # backward + optimize only if in training phase\n",
    "                        if phase == 'train':\n",
    "                            loss.backward()\n",
    "                            optimizer.step()\n",
    "\n",
    "                    # statistics\n",
    "                    running_loss += loss.item() * inputs.size(0)    # Loss\n",
    "                    nada=torch.tensor(np.zeros(len(labels))).to(device)\n",
    "                    uno=nada+1\n",
    "                    falseneg=preds+1\n",
    "                    falsepos=preds-1\n",
    "                    FPplusTN=torch.sum(labels==nada)\n",
    "                    TPplusFN=torch.sum(labels==uno)\n",
    "                    FN=torch.sum(labels==falseneg)\n",
    "                    FP=torch.sum(labels==falsepos)\n",
    "                    TN=FPplusTN-FP\n",
    "                    TP=TPplusFN-FN\n",
    "                    running_corrects += torch.sum(preds == labels.data) # Accuracy\n",
    "                    damaged_len+=TPplusFN\n",
    "                    damaged_corrects += TP\n",
    "                    undamaged_len+=FPplusTN\n",
    "                    undamaged_corrects += TN\n",
    "                damaged_acc = damaged_corrects / damaged_len\n",
    "                undamaged_acc = undamaged_corrects/undamaged_len\n",
    "                epoch_acc= (damaged_acc+undamaged_acc)/2\n",
    "                \n",
    "                if phase == 'train':\n",
    "                    scheduler.step()\n",
    "\n",
    "                epoch_loss = running_loss / dataset_sizes[phase]    # Loss metric per epoch\n",
    "                #epoch_acc = running_corrects.double() / dataset_sizes[phase]    # Accuracy metric per epoch\n",
    "\n",
    "                if phase == \"train\":    # This is the tensorboard code that writes accuracy and loss metrics\n",
    "                    writer.add_scalar(\"Train/Accuracy\", epoch_acc, epoch)\n",
    "                    writer.add_scalar(\"Train/Loss\", epoch_loss, epoch)\n",
    "                else:\n",
    "                    writer.add_scalar(\"Validation/Accuracy\", epoch_acc, epoch)\n",
    "                    writer.add_scalar(\"Validation/Loss\", epoch_loss, epoch)\n",
    "\n",
    "                print(f'{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n",
    "\n",
    "                # deep copy the model\n",
    "                if phase == 'val' and epoch_acc >= best_acc: \n",
    "                    # This compares validation accuracy to previous bests and adjusts model weights accordingly\n",
    "                    best_acc = epoch_acc\n",
    "                    torch.save(model.state_dict(), best_model_params_path)\n",
    "\n",
    "            print()\n",
    "\n",
    "        time_elapsed = time.time() - since  # Nice way to measure training time but info also stored (indirectly) by tensorboard\n",
    "        print(\n",
    "            f'Training complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')\n",
    "        print(f'Best val Acc: {best_acc:4f}')\n",
    "        labels= labels.cpu().numpy()\n",
    "        preds=preds.cpu().numpy()\n",
    "        con_mat = confusion_matrix(labels, preds)   # Confusion matrix compares true class with predicted class\n",
    "        # load best model weights\n",
    "        model.load_state_dict(torch.load(best_model_params_path))\n",
    "    writer.close()\n",
    "    return model, con_mat   # We want to return the model because its the model, also confusion matrix for later analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is your RESNET\n",
    "# Initialize CNN with kaiming\n",
    "def init_cnn(m):\n",
    "    # Set the weights of the RESNET\n",
    "    if getattr(m, 'bias', None) is not None: nn.init.constant_(m.bias, 0)\n",
    "    if isinstance(m, (nn.Conv2d,nn.Linear)): nn.init.kaiming_normal_(m.weight)\n",
    "    for l in m.children(): init_cnn(l)\n",
    "\n",
    "\n",
    "# noop function for returning nothing\n",
    "def noop(x): return x\n",
    "# activation function(RELU)\n",
    "act_fn = nn.ReLU(inplace=True)\n",
    "\n",
    "# Flatten\n",
    "class Flatten(nn.Module):\n",
    "    def forward(self, x): return x.view(x.size(0), -1)\n",
    "\n",
    "# Make a convolution\n",
    "def conv(ni, nf, ks=3, stride=1, bias=False):\n",
    "    return nn.Conv2d(ni, nf, kernel_size=ks, stride=stride, padding=ks//2, bias=bias)\n",
    "\n",
    "# Create a convuolutional layer with convolution and batch norm\n",
    "def conv_layer(ni, nf, ks=3, stride=1, zero_bn=False, act=True):\n",
    "    bn = nn.BatchNorm2d(nf) # get a 2d batch norm from Pytorhc\n",
    "    nn.init.constant_(bn.weight, 0. if zero_bn else 1.)\n",
    "    layers = [conv(ni, nf, ks, stride=stride), bn]\n",
    "    if act: layers.append(act_fn) # add in the activation function if act is true\n",
    "    return nn.Sequential(*layers)\n",
    "\n",
    "\n",
    "# Resblock\n",
    "class ResBlock(nn.Module):\n",
    "    def __init__(self, expansion, ni, nh, stride = 1):\n",
    "        super().__init__()\n",
    "        # ni - number of inputs channels, nf - number of filters\n",
    "        # nh - number of filters in first conv\n",
    "        # expansion is 1 for resnet 18, 34 and 4 for larger networks\n",
    "        nf, ni = nh*expansion, ni*expansion\n",
    "        layers = [conv_layer(ni, nh, 3, stride = stride), # for resnet < 34 2 convs per resblock\n",
    "                 conv_layer(nh, nf, 3, zero_bn = True, act = False)\n",
    "                 ] if expansion == 1 else [ # for RESNET > 34 then 3 convs per block with bottleneck\n",
    "                            conv_layer(ni, nh, 1),\n",
    "                            conv_layer(nh, nh, 3, stride = stride),\n",
    "                            conv_layer(nh, nf, 1, zero_bn = True, act = False)\n",
    "        ]\n",
    "        self.convs = nn.Sequential(*layers) # Creates the conv layers\n",
    "        self.idconv = noop if ni==nf else conv_layer(ni, nf, 1, act = False) # id convolution ()\n",
    "        self.pool = noop if stride== 1 else nn.AvgPool2d(2, ceil_mode = True) # average pool on \n",
    "        \n",
    "    def forward(self, x): \n",
    "        # Forward function adds the convolution part to the id part \n",
    "        #return act_fn(self.convs(x)) + self.idconv(self.pool(x))\n",
    "        return act_fn(self.convs(x) + self.idconv(self.pool(x)))\n",
    "\n",
    "# XResnet\n",
    "class XResNet(nn.Sequential):\n",
    "    @classmethod\n",
    "    def create(cls, expansion, layers, c_in=3, c_out=1000):\n",
    "        nfs = [c_in, (c_in + 1)*8, 64, 64] # number of filters in stem layer (c_in is number of image channels)\n",
    "        stem = [conv_layer(nfs[i], nfs[i+1], stride=2 if i==0 else 1)\n",
    "            for i in range(3)]\n",
    "\n",
    "        nfs = [64//expansion,64,128,256,512]\n",
    "        res_layers = [cls._make_layer(expansion, nfs[i], nfs[i+1],\n",
    "                                      n_blocks=l, stride=1 if i==0 else 2)\n",
    "                  for i,l in enumerate(layers)]\n",
    "        res = cls(\n",
    "        *stem,\n",
    "        nn.MaxPool2d(kernel_size=3, stride = 2, padding = 1), # then a max pooling layer\n",
    "        *res_layers,\n",
    "        nn.AdaptiveAvgPool2d(1), Flatten(), \n",
    "        nn.Linear(nfs[-1]*expansion, c_out)\n",
    "        )\n",
    "        init_cnn(res)\n",
    "        return res\n",
    "        \n",
    "    @staticmethod\n",
    "    def _make_layer(expansion, ni, nf, n_blocks, stride): # returns a resblock\n",
    "        return nn.Sequential(\n",
    "        *[ResBlock(expansion, ni if i==0 else nf, nf, stride if i==0 else 1)\n",
    "         for i in range(n_blocks)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def xresnet18 (**kwargs): return XResNet.create(1, [2, 2,  2, 2], **kwargs)\n",
    "def xresnet34 (**kwargs): return XResNet.create(1, [3, 4,  6, 3], **kwargs)\n",
    "def xresnet50 (**kwargs): return XResNet.create(4, [3, 4,  6, 3], **kwargs)\n",
    "model18 = xresnet18(c_in = 1, c_out = 2)\n",
    "model34 = xresnet34(c_in = 1, c_out = 2)\n",
    "model50 = xresnet50(c_in = 1, c_out = 2)\n",
    "\n",
    "\n",
    "# Label smoothing cross entropy\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "def reduce_loss(loss, reduction='mean'):\n",
    "    return loss.mean() if reduction=='mean' else loss.sum() if reduction=='sum' else loss\n",
    "\n",
    "class LabelSmoothingCrossEntropy(nn.Module):\n",
    "    def __init__(self, ε:float=0.1, reduction='mean'):\n",
    "        super().__init__()\n",
    "        self.ε,self.reduction = ε,reduction\n",
    "    \n",
    "    def forward(self, output, target):\n",
    "        c = output.size()[-1]\n",
    "        log_preds = F.log_softmax(output, dim=-1)\n",
    "        loss = reduce_loss(-log_preds.sum(dim=-1), self.reduction)\n",
    "        nll = F.nll_loss(log_preds, target, reduction=self.reduction)\n",
    "        return lin_comb(loss/c, nll, self.ε)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions that shows the image, true class, predicted class and degree of prediction\n",
    "\n",
    "def images_to_probs(net, images):\n",
    "    '''\n",
    "    Generates predictions and corresponding probabilities from a trained\n",
    "    network and a list of images\n",
    "    '''\n",
    "    output = net(images)\n",
    "    # convert output probabilities to predicted class\n",
    "    _, preds_tensor = torch.max(output, 1)\n",
    "    preds = np.squeeze(preds_tensor.numpy())\n",
    "    return preds, [F.softmax(el, dim=0)[i].item() for i, el in zip(preds, output)]\n",
    "\n",
    "\n",
    "def plot_classes_preds(net, images, labels):\n",
    "    '''\n",
    "    Generates matplotlib Figure using a trained network, along with images\n",
    "    and labels from a batch, that shows the network's top prediction along\n",
    "    with its probability, alongside the actual label, coloring this\n",
    "    information based on whether the prediction was correct or not.\n",
    "    Uses the \"images_to_probs\" function.\n",
    "    '''\n",
    "    preds, probs = images_to_probs(net, images)\n",
    "    # plot the images in the batch, along with predicted and true labels\n",
    "    fig = plt.figure(figsize=(12, 48))\n",
    "    for idx in np.arange(4):\n",
    "        ax = fig.add_subplot(1, 4, idx+1, xticks=[], yticks=[])\n",
    "        matplotlib_imshow(images[idx], one_channel=True)\n",
    "        ax.set_title(\"{0}, {1:.1f}%\\n(label: {2})\".format(\n",
    "            labels[preds[idx]],\n",
    "            probs[idx] * 100.0,\n",
    "            labels[labels[idx]]),\n",
    "                    color=(\"green\" if preds[idx]==labels[idx].item() else \"red\"))\n",
    "    return fig\n",
    "\n",
    "def matplotlib_imshow(img, one_channel=True):\n",
    "    if one_channel:\n",
    "        img = img.mean(dim=0)\n",
    "    img = img / 2 + 0.5     # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    if one_channel:\n",
    "        plt.imshow(npimg, cmap=\"Greys\")\n",
    "    else:\n",
    "        plt.imshow(np.transpose(npimg, (1, 2, 0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def confusion_matrix_calc(data_loader_test, classes, model_ft):       \n",
    "        y_pred = []\n",
    "        y_true = []\n",
    "        for inputs, labels, imNo in data_loader_test:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "                output = model_ft(inputs) # Feed Network\n",
    "\n",
    "                output = (torch.max(torch.exp(output), 1)[1]).data.cpu().numpy()\n",
    "                y_pred.extend(output) # Save Prediction\n",
    "                \n",
    "                labels = labels.data.cpu().numpy()\n",
    "                y_true.extend(labels) # Save Truth\n",
    "\n",
    "        # constant for classes\n",
    "        # classes = ('Alive', 'Dead')\n",
    "\n",
    "        # Build confusion matrix\n",
    "        cf_matrix = confusion_matrix(y_true, y_pred)\n",
    "        return cf_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(92178, {'train': 92178, 'val': 39505})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(10)\n",
    "imIdx = torch.randperm(1).tolist()\n",
    "\n",
    "## Create dataset\n",
    "dataSetTrain = DNADataset(imDr, get_transform(train = True), labels, imDx=imIdx)\n",
    "dataSetTest = DNADataset(imDr, get_transform(train = False), labels, imDx=imIdx)\n",
    "\n",
    "# ## Create dataloaders\n",
    "# Get subset\n",
    "torch.manual_seed(10)\n",
    "indices = torch.randperm(len(dataSetTrain)).tolist()\n",
    "\n",
    "noTrain = int(len(dataSetTrain)*0.7)\n",
    "\n",
    "dataset_train = torch.utils.data.Subset(dataSetTrain, indices[-noTrain:])\n",
    "\n",
    "dataset_test = torch.utils.data.Subset(dataSetTest, indices[:-noTrain])\n",
    "#len(indices), len(indices[:-50]), len(indices[-50:]), 50/191, type(dataset_test)\n",
    "\n",
    "dataset_sizes = {'train': len(dataset_train), 'val': len(dataset_test)}\n",
    "\n",
    "# define training and validation data loaders\n",
    "data_loader_train = torch.utils.data.DataLoader(\n",
    "    dataset_train, batch_size=128, shuffle=True, num_workers=0)\n",
    "\n",
    "data_loader_test = torch.utils.data.DataLoader(\n",
    "    dataset_test, batch_size=128, shuffle=False, num_workers=0)\n",
    "\n",
    "# Collate function (gathers together the outputs)\n",
    "# def collate_fn(batch):\n",
    "#     return tuple(zip(*batch))\n",
    "\n",
    "len(indices[-noTrain:]), dataset_sizes\n",
    "#dataset_test[0][1], dataset_test[3][1], dataset_test[-1][1], dataSetTrain.imgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/9\n",
      "----------\n",
      "train Loss: 0.5851 Acc: 0.7417\n",
      "val Loss: 0.8288 Acc: 0.5152\n",
      "\n",
      "Epoch 1/9\n",
      "----------\n",
      "train Loss: 0.4390 Acc: 0.8009\n",
      "val Loss: 2.7567 Acc: 0.5084\n",
      "\n",
      "Epoch 2/9\n",
      "----------\n",
      "train Loss: 0.4181 Acc: 0.8134\n",
      "val Loss: 0.9620 Acc: 0.5106\n",
      "\n",
      "Epoch 3/9\n",
      "----------\n",
      "train Loss: 0.4049 Acc: 0.8232\n",
      "val Loss: 0.5555 Acc: 0.7223\n",
      "\n",
      "Epoch 4/9\n",
      "----------\n",
      "train Loss: 0.3963 Acc: 0.8260\n",
      "val Loss: 1.1200 Acc: 0.5779\n",
      "\n",
      "Epoch 5/9\n",
      "----------\n",
      "train Loss: 0.3888 Acc: 0.8337\n",
      "val Loss: 1.1112 Acc: 0.5077\n",
      "\n",
      "Epoch 6/9\n",
      "----------\n",
      "train Loss: 0.3807 Acc: 0.8346\n",
      "val Loss: 2.3931 Acc: 0.5099\n",
      "\n",
      "Epoch 7/9\n",
      "----------\n",
      "train Loss: 0.3515 Acc: 0.8501\n",
      "val Loss: 0.3645 Acc: 0.8402\n",
      "\n",
      "Epoch 8/9\n",
      "----------\n",
      "train Loss: 0.3391 Acc: 0.8546\n",
      "val Loss: 0.3650 Acc: 0.8417\n",
      "\n",
      "Epoch 9/9\n",
      "----------\n",
      "train Loss: 0.3335 Acc: 0.8583\n",
      "val Loss: 0.3715 Acc: 0.8408\n",
      "\n",
      "Training complete in 28m 51s\n",
      "Best val Acc: 0.841655\n",
      "[[ 2558   434]\n",
      " [ 6267 30246]]\n",
      "Epoch 0/9\n",
      "----------\n",
      "train Loss: 0.5902 Acc: 0.7442\n",
      "val Loss: 0.7333 Acc: 0.5175\n",
      "\n",
      "Epoch 1/9\n",
      "----------\n",
      "train Loss: 0.4433 Acc: 0.7996\n",
      "val Loss: 2.0365 Acc: 0.5091\n",
      "\n",
      "Epoch 2/9\n",
      "----------\n",
      "train Loss: 0.4205 Acc: 0.8125\n",
      "val Loss: 4.6963 Acc: 0.5011\n",
      "\n",
      "Epoch 3/9\n",
      "----------\n",
      "train Loss: 0.4080 Acc: 0.8180\n",
      "val Loss: 0.7518 Acc: 0.5470\n",
      "\n",
      "Epoch 4/9\n",
      "----------\n",
      "train Loss: 0.3983 Acc: 0.8243\n",
      "val Loss: 0.9604 Acc: 0.5128\n",
      "\n",
      "Epoch 5/9\n",
      "----------\n",
      "train Loss: 0.3865 Acc: 0.8321\n",
      "val Loss: 0.5089 Acc: 0.7529\n",
      "\n",
      "Epoch 6/9\n",
      "----------\n",
      "train Loss: 0.3793 Acc: 0.8350\n",
      "val Loss: 1.0574 Acc: 0.5170\n",
      "\n",
      "Epoch 7/9\n",
      "----------\n",
      "train Loss: 0.3429 Acc: 0.8533\n",
      "val Loss: 0.6025 Acc: 0.7422\n",
      "\n",
      "Epoch 8/9\n",
      "----------\n",
      "train Loss: 0.3325 Acc: 0.8587\n",
      "val Loss: 0.3589 Acc: 0.8467\n",
      "\n",
      "Epoch 9/9\n",
      "----------\n",
      "train Loss: 0.3269 Acc: 0.8598\n",
      "val Loss: 0.3619 Acc: 0.8459\n",
      "\n",
      "Training complete in 31m 32s\n",
      "Best val Acc: 0.846749\n",
      "[[ 2519   473]\n",
      " [ 5419 31094]]\n",
      "Epoch 0/9\n",
      "----------\n",
      "train Loss: 0.7570 Acc: 0.7209\n",
      "val Loss: 1.6244 Acc: 0.5110\n",
      "\n",
      "Epoch 1/9\n",
      "----------\n",
      "train Loss: 0.4510 Acc: 0.7972\n",
      "val Loss: 0.6912 Acc: 0.5732\n",
      "\n",
      "Epoch 2/9\n",
      "----------\n",
      "train Loss: 0.4314 Acc: 0.8084\n",
      "val Loss: 2.7135 Acc: 0.4997\n",
      "\n",
      "Epoch 3/9\n",
      "----------\n",
      "train Loss: 0.4200 Acc: 0.8126\n",
      "val Loss: 0.6538 Acc: 0.6425\n",
      "\n",
      "Epoch 4/9\n",
      "----------\n",
      "train Loss: 0.4080 Acc: 0.8188\n",
      "val Loss: 7.1710 Acc: 0.5000\n",
      "\n",
      "Epoch 5/9\n",
      "----------\n",
      "train Loss: 0.4075 Acc: 0.8192\n",
      "val Loss: 2.3310 Acc: 0.5091\n",
      "\n",
      "Epoch 6/9\n",
      "----------\n",
      "train Loss: 0.3930 Acc: 0.8261\n",
      "val Loss: 0.5885 Acc: 0.6932\n",
      "\n",
      "Epoch 7/9\n",
      "----------\n",
      "train Loss: 0.3640 Acc: 0.8406\n",
      "val Loss: 0.3724 Acc: 0.8382\n",
      "\n",
      "Epoch 8/9\n",
      "----------\n",
      "train Loss: 0.3575 Acc: 0.8454\n",
      "val Loss: 0.3848 Acc: 0.8327\n",
      "\n",
      "Epoch 9/9\n",
      "----------\n",
      "train Loss: 0.3510 Acc: 0.8479\n",
      "val Loss: 0.3742 Acc: 0.8362\n",
      "\n",
      "Training complete in 35m 45s\n",
      "Best val Acc: 0.838221\n",
      "[[ 2466   526]\n",
      " [ 5395 31118]]\n",
      "Epoch 0/9\n",
      "----------\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "only batches of spatial targets supported (3D tensors) but got targets of size: : [128]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_1161/1531703076.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     21\u001b[0m                 \u001b[0moptimizer_ft\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSGD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmomentum\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mMomentum\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m                 \u001b[0mexp_lr_scheduler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlr_scheduler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mStepLR\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer_ft\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgamma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mGAMMA\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m                 model_ft, con_mat = train_model(model, criterion, optimizer_ft, exp_lr_scheduler,\n\u001b[0m\u001b[1;32m     24\u001b[0m                    data_loader_train,data_loader_test,num_epochs=10)\n\u001b[1;32m     25\u001b[0m                 \u001b[0mcf_matrix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfusion_matrix_calc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_loader_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_ft\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_1161/3239080070.py\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, criterion, optimizer, scheduler, dataloaderTrain, dataloaderTest, num_epochs)\u001b[0m\n\u001b[1;32m     41\u001b[0m                         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m                         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m                         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m                         \u001b[0;31m# backward + optimize only if in training phase\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m                         \u001b[0;32mif\u001b[0m \u001b[0mphase\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'train'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/nn/modules/loss.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m   1148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1149\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1150\u001b[0;31m         return F.cross_entropy(input, target, weight=self.weight,\n\u001b[0m\u001b[1;32m   1151\u001b[0m                                \u001b[0mignore_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mignore_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1152\u001b[0m                                label_smoothing=self.label_smoothing)\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mcross_entropy\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction, label_smoothing)\u001b[0m\n\u001b[1;32m   2847\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msize_average\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mreduce\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2848\u001b[0m         \u001b[0mreduction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_get_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize_average\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2849\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcross_entropy_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_enum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_smoothing\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2850\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2851\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: only batches of spatial targets supported (3D tensors) but got targets of size: : [128]"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x504 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x504 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x504 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "class_weights= [0.924865,0.075135] #1-(#inclass/ #intotal )\n",
    "class_weights = torch.Tensor(class_weights)\n",
    "class_weights=class_weights.to(device)\n",
    "criterion = nn.CrossEntropyLoss(weight = class_weights) \n",
    "\n",
    "# Observe that all parameters are being optimized\n",
    "learning_rate=[0.5]#0.05,0.1,0.2,0.5]\n",
    "Momentum=[0.1,0.5]#,0.9,0.99]\n",
    "GAMMA=[0.05,0.1]#, 0.5, 0.8]\n",
    "#Batch_size= [16,32]#,64,128]\n",
    "model=[model18,model34,model50]\n",
    "\n",
    "#ADD IN A THING SO IT SAVES THE TENSORBOARD TO DIFFERENT BITS\n",
    "\n",
    "for learning_rate in learning_rate:\n",
    "    for GAMMA in GAMMA:\n",
    "        for Momentum in Momentum:\n",
    "            for model in model:\n",
    "                model = model.to(device)\n",
    "                # Decay LR by a factor of gamma every 7 epochs\n",
    "                optimizer_ft = optim.SGD(model.parameters(), lr=learning_rate, momentum=Momentum)\n",
    "                exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=GAMMA)\n",
    "                model_ft, con_mat = train_model(model, criterion, optimizer_ft, exp_lr_scheduler,\n",
    "                   data_loader_train,data_loader_test,num_epochs=10)\n",
    "                cf_matrix = confusion_matrix_calc(data_loader_test, labels, model_ft)\n",
    "                print(cf_matrix)\n",
    "                df_cm_ratio = pd.DataFrame(cf_matrix / np.sum(cf_matrix, axis=1)[:, None], index=[i for i in labels],\n",
    "                     columns=[i for i in labels])\n",
    "                plt.figure(figsize=(12, 7))\n",
    "                sn.heatmap(df_cm_ratio, annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#model_ft, con_mat = train_model(model, criterion, optimizer_ft, exp_lr_scheduler, \n",
    "                                    #data_loader_train,data_loader_test,num_epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cf_matrix = confusion_matrix_calc(data_loader_test, labels, model_ft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cm_ratio = pd.DataFrame(cf_matrix / np.sum(cf_matrix, axis=1)[:, None], index=[i for i in labels],\n",
    "                     columns=[i for i in labels])\n",
    "plt.figure(figsize=(12, 7))\n",
    "sn.heatmap(df_cm_ratio, annot=True)\n",
    "# plt.save(\"Confusion_matrix_ratio.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_cm_raw = pd.DataFrame(cf_matrix, index=[i for i in labels],\n",
    "                     columns=[i for i in labels])\n",
    "plt.figure(figsize=(12, 7))\n",
    "sn.heatmap(df_cm_raw, annot=True)\n",
    "# plt.save(\"Confusion_matrix_raw.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cf_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
