{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To note: Running this on different systems (i.e. local, SCW, server) will result in slight changes needing to the code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/scipy/__init__.py:138: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.4)\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion} is required for this version of \"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.pyplot._IonContext at 0x7fbc2b0aff70>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load libraries\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import sys\n",
    "import torchvision\n",
    "import torchvision.transforms as T\n",
    "import torchvision.models as models\n",
    "from PIL import Image\n",
    "from PIL import ImageEnhance\n",
    "import matplotlib.pyplot as plt\n",
    "import imagesize\n",
    "import subprocess\n",
    "sys.path\n",
    "from IPython.core.debugger import set_trace\n",
    "import scipy.ndimage\n",
    "import matplotlib.patches as patches\n",
    "# plt.rcParams['figure.figsize'] = [12,12]\n",
    "# sys.path.append('/workspace/myFile/Mask_RCNN_Tutorial/')\n",
    "from tqdm import tqdm\n",
    "from torch import nn as nn\n",
    "from torch import optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "import re\n",
    "import time\n",
    "import copy\n",
    "import pylab\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from tempfile import TemporaryDirectory\n",
    "import torch.backends.cudnn as cudnn\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "import seaborn as sn\n",
    "import pandas as pd\n",
    "import glob\n",
    "# Rather than have a messy notebook with a load of functions we can store them in separate .py files and import them\n",
    "\n",
    "cudnn.benchmark = True\n",
    "plt.ion()   # interactive mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "writer = SummaryWriter(\"Experiments/TENSORBOARD\")    # This determines the tensorboard file name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DNADataset(object):\n",
    "    def __init__(self, root, transforms, labels, imDx = False):\n",
    "        self.root, self.transforms, self.labels = root, transforms, labels\n",
    "    \n",
    "        # load all image files, sorting them to ensure they are aligned\n",
    "        self.imgDir = glob.glob(root+\"*/*.tiff\")\n",
    "        Damagednuclei= [x for x in self.imgDir if 'Damaged_nuclei_' in x]\n",
    "        Undamagednuclei= [x for x in self.imgDir if \"No_damage_nuclei\" in x]\n",
    "        #np.random.shuffle(Undamagednuclei)\n",
    "        #Undamagednuclei=Undamagednuclei[:10000]\n",
    "        self.imgDir= Damagednuclei+Undamagednuclei\n",
    "        size80=[]\n",
    "        for x in self.imgDir:\n",
    "            img = Image.open(x) # Open image\n",
    "            w,h=img.size\n",
    "            if w<=80 and h<=80:\n",
    "                size80.append(x)\n",
    "        self.imgDir=size80              \n",
    "        \n",
    "        self.imgs = sorted(self.imgDir) # list of images\n",
    "\n",
    "        \n",
    "\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.imgs[idx]\n",
    "       \n",
    "        # Transform images into tensors\n",
    "        img = Image.open(img_path) # Open image\n",
    "        w,h=img.size\n",
    "        img = np.array(img) # Convert image into an array\n",
    "        img = np.float32(np.divide(img, 2**16)) # Ensure all values are floats\n",
    "        \n",
    "        result=np.zeros((80,80), dtype=np.float32)\n",
    "        x_center = (80 - w) // 2\n",
    "        y_center = (80 - h) // 2 # copy img image into center of result image\n",
    "        result[y_center:y_center+h, x_center:x_center+w] = img\n",
    "        img = result\n",
    "        \n",
    "        targetlab=\"\"\n",
    "        if img_path.find('No_damage_nuclei') != -1:\n",
    "            targetlab= 'Undamaged'\n",
    "        if img_path.find('Damaged_nuclei_') != -1:\n",
    "            targetlab= 'Damaged'  # Find labels corresponding to image\n",
    "        target = self.labels.index(targetlab) # Get the label and assign to a value\n",
    "        \n",
    "        # Convert label to tensor\n",
    "        #torch.to\n",
    "        \n",
    "        if self.transforms is not None:\n",
    "            img = self.transforms(img)\n",
    "#             #print('In the transforms')\n",
    "        imNo = idx\n",
    "        return img, target, imNo\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.imgs)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "imDr = \"/workspace/myFile/Output/17052023/\"  # Image patches directory\n",
    "\n",
    "labels = ['Damaged', 'Undamaged']  # Your labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For data augmentation\n",
    "def get_transform(train):\n",
    "    transforms = []\n",
    "\n",
    "    transforms.append(T.ToTensor())\n",
    "    #transforms.append(T.Normalize([0.0019368887995516483], [0.00672996630111016]))\n",
    "    #transforms.append(T.RandomHorizontalFlip(0.5))\n",
    "    \n",
    "    if train:\n",
    "        transforms.append(T.RandomHorizontalFlip(p=1))\n",
    "        transforms.append(T.RandomVerticalFlip(p=1))\n",
    "    \n",
    "    return T.Compose(transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, scheduler, train, test, num_epochs=25):\n",
    "    since = time.time()\n",
    "    # Create a temporary directory to save training checkpoints\n",
    "    with TemporaryDirectory() as tempdir:\n",
    "        best_model_params_path = os.path.join(tempdir, 'best_model_params.pt')\n",
    "\n",
    "        torch.save(model.state_dict(), best_model_params_path)\n",
    "        best_acc = 0.0\n",
    "        \n",
    "        for epoch in range(num_epochs):\n",
    "            print(f'Epoch {epoch}/{num_epochs - 1}')\n",
    "            print('-' * 10)\n",
    "            dataset_train = torch.utils.data.Subset(dataSetTrain, train[epoch])\n",
    "            dataset_test = torch.utils.data.Subset(dataSetTest, test[epoch])\n",
    "            data_loader_train = torch.utils.data.DataLoader(\n",
    "                dataset_train, batch_size=128, shuffle=True, num_workers=0)\n",
    "\n",
    "            data_loader_test = torch.utils.data.DataLoader(\n",
    "                dataset_test, batch_size=128, shuffle=False, num_workers=0)\n",
    "            # Each epoch has a training and validation phase\n",
    "            for phase in ['val']:\n",
    "                if phase == 'train':\n",
    "                    model.train()  # Set model to training mode\n",
    "                    dataloaders = data_loader_train\n",
    "                else:\n",
    "                    model.eval()   # Set model to evaluate mode\n",
    "                    dataloaders = data_loader_test\n",
    "\n",
    "                running_loss = 0.0\n",
    "                running_corrects = 0\n",
    "                damaged_len=0\n",
    "                damaged_corrects = 0\n",
    "                undamaged_len=0\n",
    "                undamaged_corrects = 0\n",
    "\n",
    "                # Iterate over data.\n",
    "                for inputs, labels, imNo in dataloaders:\n",
    "                    inputs = inputs.to(device)\n",
    "                    labels = labels.to(device)\n",
    "\n",
    "                    # zero the parameter gradients\n",
    "                    optimizer.zero_grad()\n",
    "\n",
    "                    # forward\n",
    "                    # track history if only in train\n",
    "                    with torch.set_grad_enabled(phase == 'train'):\n",
    "                        outputs = model(inputs)\n",
    "                        _, preds = torch.max(outputs, 1)\n",
    "                        loss = criterion(outputs, labels)\n",
    "                        # backward + optimize only if in training phase\n",
    "                        if phase == 'train':\n",
    "                            loss.backward()\n",
    "                            optimizer.step()\n",
    "\n",
    "                    # statistics\n",
    "                    running_loss += loss.item() * inputs.size(0)    # Loss\n",
    "                    nada=torch.tensor(np.zeros(len(labels))).to(device)\n",
    "                    uno=nada+1\n",
    "                    falseneg=preds+1\n",
    "                    falsepos=preds-1\n",
    "                    FPplusTN=torch.sum(labels==nada)\n",
    "                    TPplusFN=torch.sum(labels==uno)\n",
    "                    FN=torch.sum(labels==falseneg)\n",
    "                    FP=torch.sum(labels==falsepos)\n",
    "                    TN=FPplusTN-FP\n",
    "                    TP=TPplusFN-FN\n",
    "                    running_corrects += torch.sum(preds == labels.data) # Accuracy\n",
    "                    damaged_len+=TPplusFN\n",
    "                    damaged_corrects += TP\n",
    "                    undamaged_len+=FPplusTN\n",
    "                    undamaged_corrects += TN\n",
    "                damaged_acc = damaged_corrects / damaged_len\n",
    "                undamaged_acc = undamaged_corrects/undamaged_len\n",
    "                epoch_acc= (damaged_acc+undamaged_acc)/2\n",
    "                proper_acc=(damaged_corrects+undamaged_corrects)/(damaged_len+undamaged_len)\n",
    "                if phase == 'train':\n",
    "                    scheduler.step()\n",
    "\n",
    "                epoch_loss = running_loss / dataset_sizes[phase]    # Loss metric per epoch\n",
    "                #epoch_acc = running_corrects.double() / dataset_sizes[phase]    # Accuracy metric per epoch\n",
    "\n",
    "                if phase == \"train\":    # This is the tensorboard code that writes accuracy and loss metrics\n",
    "                    writer.add_scalar(\"Train/Accuracy\", epoch_acc, epoch)\n",
    "                    writer.add_scalar(\"Train/Loss\", epoch_loss, epoch)\n",
    "                else:\n",
    "                    writer.add_scalar(\"Validation/Accuracy\", epoch_acc, epoch)\n",
    "                    writer.add_scalar(\"Validation/Loss\", epoch_loss, epoch)\n",
    "\n",
    "                print(f'{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n",
    "                print(\"proper accuracy=\")\n",
    "                print(proper_acc)\n",
    "                print(\"damaged accuracy=\")\n",
    "                print(damaged_acc)\n",
    "                print(\"undamaged accuracy=\")\n",
    "                print(undamaged_acc)\n",
    "                con_matter= torch.tensor([[damaged_corrects, damaged_len-damaged_corrects],[undamaged_len-undamaged_corrects,undamaged_corrects]])\n",
    "                con_matter=con_matter.cpu().numpy()\n",
    "                print(con_matter)\n",
    "                # deep copy the model\n",
    "                if phase == 'val' and epoch_acc >= best_acc: \n",
    "                    # This compares validation accuracy to previous bests and adjusts model weights accordingly\n",
    "                    best_acc = epoch_acc\n",
    "                    torch.save(model.state_dict(), best_model_params_path)\n",
    "                    con_mat= torch.tensor([[damaged_corrects, damaged_len-damaged_corrects],[undamaged_len-undamaged_corrects,undamaged_corrects]])\n",
    "\n",
    "            print()\n",
    "\n",
    "        time_elapsed = time.time() - since  # Nice way to measure training time but info also stored (indirectly) by tensorboard\n",
    "        print(\n",
    "            f'Training complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')\n",
    "        print(f'Best val Acc: {best_acc:4f}')\n",
    "        #labels= labels.cpu().numpy()\n",
    "        #preds=preds.cpu().numpy()\n",
    "        model.load_state_dict(torch.load(best_model_params_path))\n",
    "    writer.close()\n",
    "    return model, con_mat   # We want to return the model because its the model, also confusion matrix for later analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is your RESNET\n",
    "# Initialize CNN with kaiming\n",
    "def init_cnn(m):\n",
    "    # Set the weights of the RESNET\n",
    "    if getattr(m, 'bias', None) is not None: nn.init.constant_(m.bias, 0)\n",
    "    if isinstance(m, (nn.Conv2d,nn.Linear)): nn.init.kaiming_normal_(m.weight)\n",
    "    for l in m.children(): init_cnn(l)\n",
    "\n",
    "\n",
    "# noop function for returning nothing\n",
    "def noop(x): return x\n",
    "# activation function(RELU)\n",
    "act_fn = nn.ReLU(inplace=True)\n",
    "\n",
    "# Flatten\n",
    "class Flatten(nn.Module):\n",
    "    def forward(self, x): return x.view(x.size(0), -1)\n",
    "\n",
    "# Make a convolution\n",
    "def conv(ni, nf, ks=3, stride=1, bias=False):\n",
    "    return nn.Conv2d(ni, nf, kernel_size=ks, stride=stride, padding=ks//2, bias=bias)\n",
    "\n",
    "# Create a convuolutional layer with convolution and batch norm\n",
    "def conv_layer(ni, nf, ks=3, stride=1, zero_bn=False, act=True):\n",
    "    bn = nn.BatchNorm2d(nf) # get a 2d batch norm from Pytorhc\n",
    "    nn.init.constant_(bn.weight, 0. if zero_bn else 1.)\n",
    "    layers = [conv(ni, nf, ks, stride=stride), bn]\n",
    "    if act: layers.append(act_fn) # add in the activation function if act is true\n",
    "    return nn.Sequential(*layers)\n",
    "\n",
    "\n",
    "# Resblock\n",
    "class ResBlock(nn.Module):\n",
    "    def __init__(self, expansion, ni, nh, stride = 1):\n",
    "        super().__init__()\n",
    "        # ni - number of inputs channels, nf - number of filters\n",
    "        # nh - number of filters in first conv\n",
    "        # expansion is 1 for resnet 18, 34 and 4 for larger networks\n",
    "        nf, ni = nh*expansion, ni*expansion\n",
    "        layers = [conv_layer(ni, nh, 3, stride = stride), # for resnet < 34 2 convs per resblock\n",
    "                 conv_layer(nh, nf, 3, zero_bn = True, act = False)\n",
    "                 ] if expansion == 1 else [ # for RESNET > 34 then 3 convs per block with bottleneck\n",
    "                            conv_layer(ni, nh, 1),\n",
    "                            conv_layer(nh, nh, 3, stride = stride),\n",
    "                            conv_layer(nh, nf, 1, zero_bn = True, act = False)\n",
    "        ]\n",
    "        self.convs = nn.Sequential(*layers) # Creates the conv layers\n",
    "        self.idconv = noop if ni==nf else conv_layer(ni, nf, 1, act = False) # id convolution ()\n",
    "        self.pool = noop if stride== 1 else nn.AvgPool2d(2, ceil_mode = True) # average pool on \n",
    "        \n",
    "    def forward(self, x): \n",
    "        # Forward function adds the convolution part to the id part \n",
    "        #return act_fn(self.convs(x)) + self.idconv(self.pool(x))\n",
    "        return act_fn(self.convs(x) + self.idconv(self.pool(x)))\n",
    "\n",
    "# XResnet\n",
    "class XResNet(nn.Sequential):\n",
    "    @classmethod\n",
    "    def create(cls, expansion, layers, c_in=3, c_out=1000):\n",
    "        nfs = [c_in, (c_in + 1)*8, 64, 64] # number of filters in stem layer (c_in is number of image channels)\n",
    "        stem = [conv_layer(nfs[i], nfs[i+1], stride=2 if i==0 else 1)\n",
    "            for i in range(3)]\n",
    "\n",
    "        nfs = [64//expansion,64,128,256,512]\n",
    "        res_layers = [cls._make_layer(expansion, nfs[i], nfs[i+1],\n",
    "                                      n_blocks=l, stride=1 if i==0 else 2)\n",
    "                  for i,l in enumerate(layers)]\n",
    "        res = cls(\n",
    "        *stem,\n",
    "        nn.MaxPool2d(kernel_size=3, stride = 2, padding = 1), # then a max pooling layer\n",
    "        *res_layers,\n",
    "        nn.AdaptiveAvgPool2d(1), Flatten(), \n",
    "        nn.Linear(nfs[-1]*expansion, c_out)\n",
    "        )\n",
    "        init_cnn(res)\n",
    "        return res\n",
    "        \n",
    "    @staticmethod\n",
    "    def _make_layer(expansion, ni, nf, n_blocks, stride): # returns a resblock\n",
    "        return nn.Sequential(\n",
    "        *[ResBlock(expansion, ni if i==0 else nf, nf, stride if i==0 else 1)\n",
    "         for i in range(n_blocks)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def xresnet18 (**kwargs): return XResNet.create(1, [2, 2,  2, 2], **kwargs)\n",
    "def xresnet34 (**kwargs): return XResNet.create(1, [3, 4,  6, 3], **kwargs)\n",
    "def xresnet50 (**kwargs): return XResNet.create(4, [3, 4,  6, 3], **kwargs)\n",
    "model = xresnet18(c_in = 1, c_out = 2)\n",
    "#model34 = xresnet34(c_in = 1, c_out = 2)\n",
    "#model50 = xresnet50(c_in = 1, c_out = 2)\n",
    "model.load_state_dict(torch.load(\"/workspace/myFile/Output/17052023/undersampling_best_model_params.pt\"))\n",
    "model = model.to(device)\n",
    "\n",
    "# Label smoothing cross entropy\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "def reduce_loss(loss, reduction='mean'):\n",
    "    return loss.mean() if reduction=='mean' else loss.sum() if reduction=='sum' else loss\n",
    "\n",
    "class LabelSmoothingCrossEntropy(nn.Module):\n",
    "    def __init__(self, ε:float=0.1, reduction='mean'):\n",
    "        super().__init__()\n",
    "        self.ε,self.reduction = ε,reduction\n",
    "    \n",
    "    def forward(self, output, target):\n",
    "        c = output.size()[-1]\n",
    "        log_preds = F.log_softmax(output, dim=-1)\n",
    "        loss = reduce_loss(-log_preds.sum(dim=-1), self.reduction)\n",
    "        nll = F.nll_loss(log_preds, target, reduction=self.reduction)\n",
    "        return lin_comb(loss/c, nll, self.ε)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions that shows the image, true class, predicted class and degree of prediction\n",
    "\n",
    "def images_to_probs(net, images):\n",
    "    '''\n",
    "    Generates predictions and corresponding probabilities from a trained\n",
    "    network and a list of images\n",
    "    '''\n",
    "    output = net(images)\n",
    "    # convert output probabilities to predicted class\n",
    "    _, preds_tensor = torch.max(output, 1)\n",
    "    preds = np.squeeze(preds_tensor.numpy())\n",
    "    return preds, [F.softmax(el, dim=0)[i].item() for i, el in zip(preds, output)]\n",
    "\n",
    "\n",
    "def plot_classes_preds(net, images, labels):\n",
    "    '''\n",
    "    Generates matplotlib Figure using a trained network, along with images\n",
    "    and labels from a batch, that shows the network's top prediction along\n",
    "    with its probability, alongside the actual label, coloring this\n",
    "    information based on whether the prediction was correct or not.\n",
    "    Uses the \"images_to_probs\" function.\n",
    "    '''\n",
    "    preds, probs = images_to_probs(net, images)\n",
    "    # plot the images in the batch, along with predicted and true labels\n",
    "    fig = plt.figure(figsize=(12, 48))\n",
    "    for idx in np.arange(4):\n",
    "        ax = fig.add_subplot(1, 4, idx+1, xticks=[], yticks=[])\n",
    "        matplotlib_imshow(images[idx], one_channel=True)\n",
    "        ax.set_title(\"{0}, {1:.1f}%\\n(label: {2})\".format(\n",
    "            labels[preds[idx]],\n",
    "            probs[idx] * 100.0,\n",
    "            labels[labels[idx]]),\n",
    "                    color=(\"green\" if preds[idx]==labels[idx].item() else \"red\"))\n",
    "    return fig\n",
    "\n",
    "def matplotlib_imshow(img, one_channel=True):\n",
    "    if one_channel:\n",
    "        img = img.mean(dim=0)\n",
    "    img = img / 2 + 0.5     # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    if one_channel:\n",
    "        plt.imshow(npimg, cmap=\"Greys\")\n",
    "    else:\n",
    "        plt.imshow(np.transpose(npimg, (1, 2, 0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def confusion_matrix_calc(data_loader_test, classes, model_ft):       \n",
    "        y_pred = []\n",
    "        y_true = []\n",
    "        for inputs, labels, imNo in data_loader_test:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "                output = model_ft(inputs) # Feed Network\n",
    "\n",
    "                output = (torch.max(torch.exp(output), 1)[1]).data.cpu().numpy()\n",
    "                y_pred.extend(output) # Save Prediction\n",
    "                \n",
    "                labels = labels.data.cpu().numpy()\n",
    "                y_true.extend(labels) # Save Truth\n",
    "\n",
    "        # constant for classes\n",
    "        # classes = ('Alive', 'Dead')\n",
    "\n",
    "        # Build confusion matrix\n",
    "        cf_matrix = confusion_matrix(y_true, y_pred)\n",
    "        return cf_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': 105347, 'val': 1}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k=5 #NUMBER OF K FOLDS\n",
    "epoch=5 #NUMBER OF EPOCHS\n",
    "\n",
    "torch.manual_seed(10)\n",
    "imIdx = torch.randperm(1).tolist()\n",
    "\n",
    "## Create dataset\n",
    "dataSetTrain = DNADataset(imDr, get_transform(train = True), labels, imDx=imIdx)\n",
    "dataSetTest = DNADataset(imDr, get_transform(train = False), labels, imDx=imIdx)\n",
    "\n",
    "data_loader_train=[]\n",
    "data_loader_test=[]\n",
    "\n",
    "# ## Create dataloaders\n",
    "# Get subset\n",
    "torch.manual_seed(10)\n",
    "indices = torch.randperm(len(dataSetTrain)).tolist()\n",
    "\n",
    "noTrain = int(len(dataSetTrain)*0.7)\n",
    "train=[]\n",
    "test=[]\n",
    "indices = torch.randperm(len(dataSetTrain)).tolist()\n",
    "TotalSet=list(range(len(dataSetTrain)))\n",
    "Kfifth = len(dataSetTrain)//k\n",
    "split= epoch%k\n",
    "train.append(TotalSet[(split+1)*Kfifth:]+TotalSet[:Kfifth*split])\n",
    "\n",
    "indices = torch.randperm(len(dataSetTest)).tolist()\n",
    "TotalSet=list(range(len(dataSetTrain)))\n",
    "test.append(TotalSet)\n",
    "\n",
    "#dataset_train = torch.utils.data.Subset(dataSetTrain, indices[-noTrain:])\n",
    "\n",
    "#dataset_test = torch.utils.data.Subset(dataSetTest, indices[:-noTrain])\n",
    "#len(indices), len(indices[:-50]), len(indices[-50:]), 50/191, type(dataset_test)\n",
    "\n",
    "dataset_sizes = {'train': len(train[0]), 'val': len(test)}\n",
    "dataset_sizes\n",
    "#dataset_train = torch.utils.data.Subset(dataSetTrain, train)\n",
    "#data_loader_train.append(dataset_train)\n",
    "#dataset_testo = torch.utils.data.Subset(dataSetTest, test)\n",
    "#data_loader_test.append(dataset_testo)\n",
    "# define training and validation data loaders\n",
    "\n",
    "\n",
    "# Collate function (gathers together the outputs)\n",
    "# def collate_fn(batch):\n",
    "#     return tuple(zip(*batch))\n",
    "\n",
    "#len(indices[-noTrain:]), dataset_sizes\n",
    "#dataset_test[0][1], dataset_test[3][1], dataset_test[-1][1], dataSetTrain.imgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_weights= [0.924865,0.075135] #1-(#inclass/ #intotal )\n",
    "class_weights = torch.Tensor(class_weights)\n",
    "class_weights=class_weights.to(device)\n",
    "criterion = nn.CrossEntropyLoss(weight = class_weights) \n",
    "\n",
    "# Observe that all parameters are being optimized\n",
    "optimizer_ft = optim.Adam(model.parameters(), weight_decay=1e-2) # standard ADAM optimiser\n",
    "\n",
    "# Decay LR by a factor of 0.1 every 7 epochs\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/0\n",
      "----------\n",
      "val Loss: 50476.7885 Acc: 0.8346\n",
      "proper accuracy=\n",
      "tensor(0.8266, device='cuda:0')\n",
      "damaged accuracy=\n",
      "tensor(0.8252, device='cuda:0')\n",
      "undamaged accuracy=\n",
      "tensor(0.8440, device='cuda:0')\n",
      "[[100504  21285]\n",
      " [  1543   8351]]\n",
      "\n",
      "Training complete in 2m 20s\n",
      "Best val Acc: 0.834639\n"
     ]
    }
   ],
   "source": [
    "model_ft, con_mat = train_model(model, criterion, optimizer_ft, exp_lr_scheduler, \n",
    "                                    train,test,num_epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cf_matrix = confusion_matrix_calc(data_loader_test, labels, model_ft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x504 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "con_mat=con_mat.cpu().numpy()\n",
    "plotlabels=['Undamaged','Damaged']\n",
    "df_cm_ratio = pd.DataFrame(con_mat / np.sum(con_mat, axis=1)[:, None], index=[i for i in plotlabels],\n",
    "                     columns=[i for i in plotlabels])\n",
    "plt.figure(figsize=(12, 7))\n",
    "sn.heatmap(df_cm_ratio, annot=True)\n",
    "# plt.save(\"Confusion_matrix_ratio.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x504 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_cm_raw = pd.DataFrame(con_mat, index=[i for i in plotlabels],\n",
    "                     columns=[i for i in plotlabels])\n",
    "plt.figure(figsize=(12, 7))\n",
    "sn.heatmap(df_cm_raw, annot=True)\n",
    "# plt.save(\"Confusion_matrix_raw.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[100504,  21285],\n",
       "       [  1543,   8351]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "con_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_loader_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotlabels=['Undamaged','Damaged']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
