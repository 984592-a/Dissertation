{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To note: Running this on different systems (i.e. local, SCW, server) will result in slight changes needing to the code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/scipy/__init__.py:138: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.4)\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion} is required for this version of \"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.pyplot._IonContext at 0x7f11b7269850>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load libraries\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import sys\n",
    "import torchvision\n",
    "import torchvision.transforms as T\n",
    "import torchvision.models as models\n",
    "from PIL import Image\n",
    "from PIL import ImageEnhance\n",
    "import matplotlib.pyplot as plt\n",
    "import imagesize\n",
    "import subprocess\n",
    "sys.path\n",
    "from IPython.core.debugger import set_trace\n",
    "import scipy.ndimage\n",
    "import matplotlib.patches as patches\n",
    "# plt.rcParams['figure.figsize'] = [12,12]\n",
    "# sys.path.append('/workspace/myFile/Mask_RCNN_Tutorial/')\n",
    "from tqdm import tqdm\n",
    "from torch import nn as nn\n",
    "from torch import optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "import re\n",
    "import time\n",
    "import copy\n",
    "import pylab\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from tempfile import TemporaryDirectory\n",
    "import torch.backends.cudnn as cudnn\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "import seaborn as sn\n",
    "import pandas as pd\n",
    "import glob\n",
    "# Rather than have a messy notebook with a load of functions we can store them in separate .py files and import them\n",
    "\n",
    "cudnn.benchmark = True\n",
    "plt.ion()   # interactive mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard\n",
    "writer = SummaryWriter(\"Experiments/09085epoch\")    # This determines the tensorboard file name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DNADataset(object):\n",
    "    def __init__(self, root, transforms, labels, imDx = False):\n",
    "        self.root, self.transforms, self.labels = root, transforms, labels\n",
    "    \n",
    "        # load all image files, sorting them to ensure they are aligned\n",
    "        self.imgDir = glob.glob(root+\"*/*.tiff\")\n",
    "        Damagednuclei= [x for x in self.imgDir if 'Damaged_nuclei_' in x]\n",
    "        Undamagednuclei= [x for x in self.imgDir if \"No_damage_nuclei\" in x]\n",
    "        #np.random.shuffle(Undamagednuclei)\n",
    "        #Undamagednuclei=Undamagednuclei[:10000]\n",
    "        self.imgDir= Damagednuclei+Undamagednuclei\n",
    "        size80=[]\n",
    "        for x in self.imgDir:\n",
    "            img = Image.open(x) # Open image\n",
    "            w,h=img.size\n",
    "            if w<=80 and h<=80:\n",
    "                size80.append(x)\n",
    "        self.imgDir=size80              \n",
    "        \n",
    "        self.imgs = sorted(self.imgDir) # list of images\n",
    "\n",
    "        \n",
    "\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.imgs[idx]\n",
    "       \n",
    "        # Transform images into tensors\n",
    "        img = Image.open(img_path) # Open image\n",
    "        w,h=img.size\n",
    "        img = np.array(img) # Convert image into an array\n",
    "        img = np.float32(np.divide(img, 2**16)) # Ensure all values are floats\n",
    "        \n",
    "        result=np.zeros((80,80), dtype=np.float32)\n",
    "        x_center = (80 - w) // 2\n",
    "        y_center = (80 - h) // 2 # copy img image into center of result image\n",
    "        result[y_center:y_center+h, x_center:x_center+w] = img\n",
    "        img = result\n",
    "        \n",
    "        targetlab=\"\"\n",
    "        if img_path.find('No_damage_nuclei') != -1:\n",
    "            targetlab= 'Undamaged'\n",
    "        if img_path.find('Damaged_nuclei_') != -1:\n",
    "            targetlab= 'Damaged'  # Find labels corresponding to image\n",
    "        target = self.labels.index(targetlab) # Get the label and assign to a value\n",
    "        \n",
    "        # Convert label to tensor\n",
    "        #torch.to\n",
    "        \n",
    "        if self.transforms is not None:\n",
    "            img = self.transforms(img)\n",
    "#             #print('In the transforms')\n",
    "        imNo = idx\n",
    "        return img, target, imNo\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.imgs)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "root=\"/workspace/myFile/Output/17052023/\"\n",
    "p= glob.glob(root+\"*/*.tiff\")\n",
    "Damagednuclei= [x for x in p if 'Damaged_nuclei_' in x]\n",
    "Undamagednuclei= [x for x in p if \"No_damage_nuclei\" in x]\n",
    "#np.random.shuffle(Undamagednuclei)\n",
    "#Undamagednuclei=Undamagednuclei[:10000]\n",
    "#Undamagednuclei"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "imDr = \"/workspace/myFile/Output/17052023/\"  # Image patches directory\n",
    "\n",
    "labels = ['Damaged', 'Undamaged']  # Your labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For data augmentation\n",
    "def get_transform(train):\n",
    "    transforms = []\n",
    "\n",
    "    transforms.append(T.ToTensor())\n",
    "    #transforms.append(T.Normalize([0.0019368887995516483], [0.00672996630111016]))\n",
    "    #transforms.append(T.RandomHorizontalFlip(0.5))\n",
    "    \n",
    "    if train:\n",
    "        transforms.append(T.RandomHorizontalFlip(p=0.5))\n",
    "        transforms.append(T.RandomVerticalFlip(p=0.5))\n",
    "    \n",
    "    return T.Compose(transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, scheduler, train, test, num_epochs=25):\n",
    "    since = time.time()\n",
    "    # Create a temporary directory to save training checkpoints\n",
    "    with TemporaryDirectory() as tempdir:\n",
    "        best_model_params_path = os.path.join(tempdir, 'best_model_params.pt')\n",
    "\n",
    "        torch.save(model.state_dict(), best_model_params_path)\n",
    "        best_acc = 0.0\n",
    "        \n",
    "        for epoch in range(num_epochs):\n",
    "            print(f'Epoch {epoch}/{num_epochs - 1}')\n",
    "            print('-' * 10)\n",
    "            dataset_train = torch.utils.data.Subset(dataSetTrain, train[epoch])\n",
    "            dataset_test = torch.utils.data.Subset(dataSetTest, test[epoch])\n",
    "            data_loader_train = torch.utils.data.DataLoader(\n",
    "                dataset_train, batch_size=128, shuffle=True, num_workers=0)\n",
    "\n",
    "            data_loader_test = torch.utils.data.DataLoader(\n",
    "                dataset_test, batch_size=128, shuffle=False, num_workers=0)\n",
    "            # Each epoch has a training and validation phase\n",
    "            for phase in ['train', 'val']:\n",
    "                if phase == 'train':\n",
    "                    model.train()  # Set model to training mode\n",
    "                    dataloaders = data_loader_train\n",
    "                else:\n",
    "                    model.eval()   # Set model to evaluate mode\n",
    "                    dataloaders = data_loader_test\n",
    "\n",
    "                running_loss = 0.0\n",
    "                running_corrects = 0\n",
    "                damaged_len=0\n",
    "                damaged_corrects = 0\n",
    "                undamaged_len=0\n",
    "                undamaged_corrects = 0\n",
    "\n",
    "                # Iterate over data.\n",
    "                for inputs, labels, imNo in dataloaders:\n",
    "                    inputs = inputs.to(device)\n",
    "                    labels = labels.to(device)\n",
    "\n",
    "                    # zero the parameter gradients\n",
    "                    optimizer.zero_grad()\n",
    "\n",
    "                    # forward\n",
    "                    # track history if only in train\n",
    "                    with torch.set_grad_enabled(phase == 'train'):\n",
    "                        outputs = model(inputs)\n",
    "                        _, preds = torch.max(outputs, 1)\n",
    "                        loss = criterion(outputs, labels)\n",
    "                        # backward + optimize only if in training phase\n",
    "                        if phase == 'train':\n",
    "                            loss.backward()\n",
    "                            optimizer.step()\n",
    "\n",
    "                    # statistics\n",
    "                    running_loss += loss.item() * inputs.size(0)    # Loss\n",
    "                    nada=torch.tensor(np.zeros(len(labels))).to(device)\n",
    "                    uno=nada+1\n",
    "                    falseneg=preds+1\n",
    "                    falsepos=preds-1\n",
    "                    FPplusTN=torch.sum(labels==nada)\n",
    "                    TPplusFN=torch.sum(labels==uno)\n",
    "                    FN=torch.sum(labels==falseneg)\n",
    "                    FP=torch.sum(labels==falsepos)\n",
    "                    TN=FPplusTN-FP\n",
    "                    TP=TPplusFN-FN\n",
    "                    running_corrects += torch.sum(preds == labels.data) # Accuracy\n",
    "                    damaged_len+=TPplusFN\n",
    "                    damaged_corrects += TP\n",
    "                    undamaged_len+=FPplusTN\n",
    "                    undamaged_corrects += TN\n",
    "                damaged_acc = damaged_corrects / damaged_len\n",
    "                undamaged_acc = undamaged_corrects/undamaged_len\n",
    "                epoch_acc= (damaged_acc+undamaged_acc)/2\n",
    "                \n",
    "                if phase == 'train':\n",
    "                    scheduler.step()\n",
    "\n",
    "                epoch_loss = running_loss / dataset_sizes[phase]    # Loss metric per epoch\n",
    "                #epoch_acc = running_corrects.double() / dataset_sizes[phase]    # Accuracy metric per epoch\n",
    "\n",
    "                if phase == \"train\":    # This is the tensorboard code that writes accuracy and loss metrics\n",
    "                    writer.add_scalar(\"Train/Accuracy\", epoch_acc, epoch)\n",
    "                    writer.add_scalar(\"Train/Loss\", epoch_loss, epoch)\n",
    "                else:\n",
    "                    writer.add_scalar(\"Validation/Accuracy\", epoch_acc, epoch)\n",
    "                    writer.add_scalar(\"Validation/Loss\", epoch_loss, epoch)\n",
    "\n",
    "                print(f'{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n",
    "\n",
    "                # deep copy the model\n",
    "                if phase == 'val' and epoch_acc >= best_acc: \n",
    "                    # This compares validation accuracy to previous bests and adjusts model weights accordingly\n",
    "                    best_acc = epoch_acc\n",
    "                    torch.save(model.state_dict(), best_model_params_path)\n",
    "                    con_mat= torch.tensor([[damaged_corrects, damaged_len-damaged_corrects],[undamaged_len-undamaged_corrects,undamaged_corrects]])\n",
    "\n",
    "            print()\n",
    "\n",
    "        time_elapsed = time.time() - since  # Nice way to measure training time but info also stored (indirectly) by tensorboard\n",
    "        print(\n",
    "            f'Training complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')\n",
    "        print(f'Best val Acc: {best_acc:4f}')\n",
    "        #labels= labels.cpu().numpy()\n",
    "        #preds=preds.cpu().numpy()\n",
    "        model.load_state_dict(torch.load(best_model_params_path))\n",
    "    writer.close()\n",
    "    return model, con_mat, best_acc   # We want to return the model because its the model, also confusion matrix for later analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is your RESNET\n",
    "# Initialize CNN with kaiming\n",
    "def init_cnn(m):\n",
    "    # Set the weights of the RESNET\n",
    "    if getattr(m, 'bias', None) is not None: nn.init.constant_(m.bias, 0)\n",
    "    if isinstance(m, (nn.Conv2d,nn.Linear)): nn.init.kaiming_normal_(m.weight)\n",
    "    for l in m.children(): init_cnn(l)\n",
    "\n",
    "\n",
    "# noop function for returning nothing\n",
    "def noop(x): return x\n",
    "# activation function(RELU)\n",
    "act_fn = nn.ReLU(inplace=True)\n",
    "\n",
    "# Flatten\n",
    "class Flatten(nn.Module):\n",
    "    def forward(self, x): return x.view(x.size(0), -1)\n",
    "\n",
    "# Make a convolution\n",
    "def conv(ni, nf, ks=3, stride=1, bias=False):\n",
    "    return nn.Conv2d(ni, nf, kernel_size=ks, stride=stride, padding=ks//2, bias=bias)\n",
    "\n",
    "# Create a convuolutional layer with convolution and batch norm\n",
    "def conv_layer(ni, nf, ks=3, stride=1, zero_bn=False, act=True):\n",
    "    bn = nn.BatchNorm2d(nf) # get a 2d batch norm from Pytorhc\n",
    "    nn.init.constant_(bn.weight, 0. if zero_bn else 1.)\n",
    "    layers = [conv(ni, nf, ks, stride=stride), bn]\n",
    "    if act: layers.append(act_fn) # add in the activation function if act is true\n",
    "    return nn.Sequential(*layers)\n",
    "\n",
    "\n",
    "# Resblock\n",
    "class ResBlock(nn.Module):\n",
    "    def __init__(self, expansion, ni, nh, stride = 1):\n",
    "        super().__init__()\n",
    "        # ni - number of inputs channels, nf - number of filters\n",
    "        # nh - number of filters in first conv\n",
    "        # expansion is 1 for resnet 18, 34 and 4 for larger networks\n",
    "        nf, ni = nh*expansion, ni*expansion\n",
    "        layers = [conv_layer(ni, nh, 3, stride = stride), # for resnet < 34 2 convs per resblock\n",
    "                 conv_layer(nh, nf, 3, zero_bn = True, act = False)\n",
    "                 ] if expansion == 1 else [ # for RESNET > 34 then 3 convs per block with bottleneck\n",
    "                            conv_layer(ni, nh, 1),\n",
    "                            conv_layer(nh, nh, 3, stride = stride),\n",
    "                            conv_layer(nh, nf, 1, zero_bn = True, act = False)\n",
    "        ]\n",
    "        self.convs = nn.Sequential(*layers) # Creates the conv layers\n",
    "        self.idconv = noop if ni==nf else conv_layer(ni, nf, 1, act = False) # id convolution ()\n",
    "        self.pool = noop if stride== 1 else nn.AvgPool2d(2, ceil_mode = True) # average pool on \n",
    "        \n",
    "    def forward(self, x): \n",
    "        # Forward function adds the convolution part to the id part \n",
    "        #return act_fn(self.convs(x)) + self.idconv(self.pool(x))\n",
    "        return act_fn(self.convs(x) + self.idconv(self.pool(x)))\n",
    "\n",
    "# XResnet\n",
    "class XResNet(nn.Sequential):\n",
    "    @classmethod\n",
    "    def create(cls, expansion, layers, c_in=3, c_out=1000):\n",
    "        nfs = [c_in, (c_in + 1)*8, 64, 64] # number of filters in stem layer (c_in is number of image channels)\n",
    "        stem = [conv_layer(nfs[i], nfs[i+1], stride=2 if i==0 else 1)\n",
    "            for i in range(3)]\n",
    "\n",
    "        nfs = [64//expansion,64,128,256,512]\n",
    "        res_layers = [cls._make_layer(expansion, nfs[i], nfs[i+1],\n",
    "                                      n_blocks=l, stride=1 if i==0 else 2)\n",
    "                  for i,l in enumerate(layers)]\n",
    "        res = cls(\n",
    "        *stem,\n",
    "        nn.MaxPool2d(kernel_size=3, stride = 2, padding = 1), # then a max pooling layer\n",
    "        *res_layers,\n",
    "        nn.AdaptiveAvgPool2d(1), Flatten(), \n",
    "        nn.Linear(nfs[-1]*expansion, c_out)\n",
    "        )\n",
    "        init_cnn(res)\n",
    "        return res\n",
    "        \n",
    "    @staticmethod\n",
    "    def _make_layer(expansion, ni, nf, n_blocks, stride): # returns a resblock\n",
    "        return nn.Sequential(\n",
    "        *[ResBlock(expansion, ni if i==0 else nf, nf, stride if i==0 else 1)\n",
    "         for i in range(n_blocks)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def xresnet18 (**kwargs): return XResNet.create(1, [2, 2,  2, 2], **kwargs)\n",
    "def xresnet34 (**kwargs): return XResNet.create(1, [3, 4,  6, 3], **kwargs)\n",
    "def xresnet50 (**kwargs): return XResNet.create(4, [3, 4,  6, 3], **kwargs)\n",
    "model18 = xresnet18(c_in = 1, c_out = 2)\n",
    "model34 = xresnet34(c_in = 1, c_out = 2)\n",
    "model50 = xresnet50(c_in = 1, c_out = 2)\n",
    "\n",
    "# Label smoothing cross entropy\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "def reduce_loss(loss, reduction='mean'):\n",
    "    return loss.mean() if reduction=='mean' else loss.sum() if reduction=='sum' else loss\n",
    "\n",
    "class LabelSmoothingCrossEntropy(nn.Module):\n",
    "    def __init__(self, ε:float=0.1, reduction='mean'):\n",
    "        super().__init__()\n",
    "        self.ε,self.reduction = ε,reduction\n",
    "    \n",
    "    def forward(self, output, target):\n",
    "        c = output.size()[-1]\n",
    "        log_preds = F.log_softmax(output, dim=-1)\n",
    "        loss = reduce_loss(-log_preds.sum(dim=-1), self.reduction)\n",
    "        nll = F.nll_loss(log_preds, target, reduction=self.reduction)\n",
    "        return lin_comb(loss/c, nll, self.ε)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions that shows the image, true class, predicted class and degree of prediction\n",
    "\n",
    "def images_to_probs(net, images):\n",
    "    '''\n",
    "    Generates predictions and corresponding probabilities from a trained\n",
    "    network and a list of images\n",
    "    '''\n",
    "    output = net(images)\n",
    "    # convert output probabilities to predicted class\n",
    "    _, preds_tensor = torch.max(output, 1)\n",
    "    preds = np.squeeze(preds_tensor.numpy())\n",
    "    return preds, [F.softmax(el, dim=0)[i].item() for i, el in zip(preds, output)]\n",
    "\n",
    "\n",
    "def plot_classes_preds(net, images, labels):\n",
    "    '''\n",
    "    Generates matplotlib Figure using a trained network, along with images\n",
    "    and labels from a batch, that shows the network's top prediction along\n",
    "    with its probability, alongside the actual label, coloring this\n",
    "    information based on whether the prediction was correct or not.\n",
    "    Uses the \"images_to_probs\" function.\n",
    "    '''\n",
    "    preds, probs = images_to_probs(net, images)\n",
    "    # plot the images in the batch, along with predicted and true labels\n",
    "    fig = plt.figure(figsize=(12, 48))\n",
    "    for idx in np.arange(4):\n",
    "        ax = fig.add_subplot(1, 4, idx+1, xticks=[], yticks=[])\n",
    "        matplotlib_imshow(images[idx], one_channel=True)\n",
    "        ax.set_title(\"{0}, {1:.1f}%\\n(label: {2})\".format(\n",
    "            labels[preds[idx]],\n",
    "            probs[idx] * 100.0,\n",
    "            labels[labels[idx]]),\n",
    "                    color=(\"green\" if preds[idx]==labels[idx].item() else \"red\"))\n",
    "    return fig\n",
    "\n",
    "def matplotlib_imshow(img, one_channel=True):\n",
    "    if one_channel:\n",
    "        img = img.mean(dim=0)\n",
    "    img = img / 2 + 0.5     # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    if one_channel:\n",
    "        plt.imshow(npimg, cmap=\"Greys\")\n",
    "    else:\n",
    "        plt.imshow(np.transpose(npimg, (1, 2, 0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def confusion_matrix_calc(data_loader_test, classes, model_ft):       \n",
    "        y_pred = []\n",
    "        y_true = []\n",
    "        for inputs, labels, imNo in data_loader_test:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "                output = model_ft(inputs) # Feed Network\n",
    "\n",
    "                output = (torch.max(torch.exp(output), 1)[1]).data.cpu().numpy()\n",
    "                y_pred.extend(output) # Save Prediction\n",
    "                \n",
    "                labels = labels.data.cpu().numpy()\n",
    "                y_true.extend(labels) # Save Truth\n",
    "\n",
    "        # constant for classes\n",
    "        # classes = ('Alive', 'Dead')\n",
    "\n",
    "        # Build confusion matrix\n",
    "        cf_matrix = confusion_matrix(y_true, y_pred)\n",
    "        return cf_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "k=5 #NUMBER OF K FOLDS\n",
    "epoch=range(100) #NUMBER OF EPOCHS\n",
    "\n",
    "torch.manual_seed(10)\n",
    "imIdx = torch.randperm(1).tolist()\n",
    "\n",
    "## Create dataset\n",
    "dataSetTrain = DNADataset(imDr, get_transform(train = True), labels, imDx=imIdx)\n",
    "dataSetTest = DNADataset(imDr, get_transform(train = False), labels, imDx=imIdx)\n",
    "\n",
    "data_loader_train=[]\n",
    "data_loader_test=[]\n",
    "\n",
    "# ## Create dataloaders\n",
    "# Get subset\n",
    "torch.manual_seed(10)\n",
    "TotalSetTrain=list(range(len(dataSetTrain)))\n",
    "np.random.shuffle(TotalSetTrain)\n",
    "TotalSetTest=list(range(len(dataSetTest)))\n",
    "np.random.shuffle(TotalSetTest)\n",
    "\n",
    "train=[]\n",
    "test=[]\n",
    "for epoch in epoch:\n",
    "    \n",
    "    Kfifth = len(dataSetTrain)//k\n",
    "    split= epoch%k\n",
    "    train.append(TotalSetTrain[(split+1)*Kfifth:]+TotalSetTrain[:Kfifth*split])\n",
    "    test.append(TotalSetTest[split*Kfifth:(split+1)*Kfifth])\n",
    "\n",
    "#dataset_train = torch.utils.data.Subset(dataSetTrain, indices[-noTrain:])\n",
    "\n",
    "#dataset_test = torch.utils.data.Subset(dataSetTest, indices[:-noTrain])\n",
    "#len(indices), len(indices[:-50]), len(indices[-50:]), 50/191, type(dataset_test)\n",
    "\n",
    "dataset_sizes = {'train': len(train[0]), 'val': len(test[0])}\n",
    "\n",
    "#dataset_train = torch.utils.data.Subset(dataSetTrain, train)\n",
    "#data_loader_train.append(dataset_train)\n",
    "#dataset_testo = torch.utils.data.Subset(dataSetTest, test)\n",
    "#data_loader_test.append(dataset_testo)\n",
    "# define training and validation data loaders\n",
    "\n",
    "\n",
    "# Collate function (gathers together the outputs)\n",
    "# def collate_fn(batch):\n",
    "#     return tuple(zip(*batch))\n",
    "\n",
    "#len(indices[-noTrain:]), dataset_sizes\n",
    "#dataset_test[0][1], dataset_test[3][1], dataset_test[-1][1], dataSetTrain.imgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/99\n",
      "----------\n",
      "train Loss: 0.5840 Acc: 0.7351\n",
      "val Loss: 0.4828 Acc: 0.7710\n",
      "\n",
      "Epoch 1/99\n",
      "----------\n",
      "train Loss: 0.4573 Acc: 0.7934\n",
      "val Loss: 6.2612 Acc: 0.5000\n",
      "\n",
      "Epoch 2/99\n",
      "----------\n",
      "train Loss: 0.4484 Acc: 0.7953\n",
      "val Loss: 0.4256 Acc: 0.8102\n",
      "\n",
      "Epoch 3/99\n",
      "----------\n",
      "train Loss: 0.4231 Acc: 0.8121\n",
      "val Loss: 0.9268 Acc: 0.5569\n",
      "\n",
      "Epoch 4/99\n",
      "----------\n",
      "train Loss: 0.4141 Acc: 0.8151\n",
      "val Loss: 0.4253 Acc: 0.8062\n",
      "\n",
      "Epoch 5/99\n",
      "----------\n",
      "train Loss: 0.4037 Acc: 0.8203\n",
      "val Loss: 0.5884 Acc: 0.6926\n",
      "\n",
      "Epoch 6/99\n",
      "----------\n",
      "train Loss: 0.3975 Acc: 0.8261\n",
      "val Loss: 0.6032 Acc: 0.6831\n",
      "\n",
      "Epoch 7/99\n",
      "----------\n",
      "train Loss: 0.3790 Acc: 0.8357\n",
      "val Loss: 1.6108 Acc: 0.5108\n",
      "\n",
      "Epoch 8/99\n",
      "----------\n",
      "train Loss: 0.3759 Acc: 0.8376\n",
      "val Loss: 1.2185 Acc: 0.5108\n",
      "\n",
      "Epoch 9/99\n",
      "----------\n",
      "train Loss: 0.3722 Acc: 0.8389\n",
      "val Loss: 0.3694 Acc: 0.8439\n",
      "\n",
      "Epoch 10/99\n",
      "----------\n",
      "train Loss: 0.3725 Acc: 0.8419\n",
      "val Loss: 0.3619 Acc: 0.8463\n",
      "\n",
      "Epoch 11/99\n",
      "----------\n",
      "train Loss: 0.3655 Acc: 0.8440\n",
      "val Loss: 1.2646 Acc: 0.5102\n",
      "\n",
      "Epoch 12/99\n",
      "----------\n",
      "train Loss: 0.3658 Acc: 0.8438\n",
      "val Loss: 0.3518 Acc: 0.8522\n",
      "\n",
      "Epoch 13/99\n",
      "----------\n",
      "train Loss: 0.3632 Acc: 0.8454\n",
      "val Loss: 0.7476 Acc: 0.6117\n",
      "\n",
      "Epoch 14/99\n",
      "----------\n",
      "train Loss: 0.3499 Acc: 0.8514\n",
      "val Loss: 0.3483 Acc: 0.8523\n",
      "\n",
      "Epoch 15/99\n",
      "----------\n",
      "train Loss: 0.3483 Acc: 0.8533\n",
      "val Loss: 0.4214 Acc: 0.8131\n",
      "\n",
      "Epoch 16/99\n",
      "----------\n",
      "train Loss: 0.3455 Acc: 0.8542\n",
      "val Loss: 0.3326 Acc: 0.8592\n",
      "\n",
      "Epoch 17/99\n",
      "----------\n",
      "train Loss: 0.3456 Acc: 0.8525\n",
      "val Loss: 0.3312 Acc: 0.8606\n",
      "\n",
      "Epoch 18/99\n",
      "----------\n",
      "train Loss: 0.3442 Acc: 0.8557\n",
      "val Loss: 0.3532 Acc: 0.8519\n",
      "\n",
      "Epoch 19/99\n",
      "----------\n",
      "train Loss: 0.3383 Acc: 0.8594\n",
      "val Loss: 0.3483 Acc: 0.8499\n",
      "\n",
      "Epoch 20/99\n",
      "----------\n",
      "train Loss: 0.3395 Acc: 0.8571\n",
      "val Loss: 0.3395 Acc: 0.8550\n",
      "\n",
      "Epoch 21/99\n",
      "----------\n",
      "train Loss: 0.3308 Acc: 0.8625\n",
      "val Loss: 0.3152 Acc: 0.8703\n",
      "\n",
      "Epoch 22/99\n",
      "----------\n",
      "train Loss: 0.3290 Acc: 0.8644\n",
      "val Loss: 0.3682 Acc: 0.8346\n",
      "\n",
      "Epoch 23/99\n",
      "----------\n",
      "train Loss: 0.3278 Acc: 0.8618\n",
      "val Loss: 0.3233 Acc: 0.8613\n",
      "\n",
      "Epoch 24/99\n",
      "----------\n",
      "train Loss: 0.3243 Acc: 0.8645\n",
      "val Loss: 0.3243 Acc: 0.8647\n",
      "\n",
      "Epoch 25/99\n",
      "----------\n",
      "train Loss: 0.3221 Acc: 0.8661\n",
      "val Loss: 0.3462 Acc: 0.8531\n",
      "\n",
      "Epoch 26/99\n",
      "----------\n",
      "train Loss: 0.3206 Acc: 0.8663\n",
      "val Loss: 0.3054 Acc: 0.8760\n",
      "\n",
      "Epoch 27/99\n",
      "----------\n",
      "train Loss: 0.3214 Acc: 0.8642\n",
      "val Loss: 0.3126 Acc: 0.8707\n",
      "\n",
      "Epoch 28/99\n",
      "----------\n",
      "train Loss: 0.3125 Acc: 0.8709\n",
      "val Loss: 0.3047 Acc: 0.8721\n",
      "\n",
      "Epoch 29/99\n",
      "----------\n",
      "train Loss: 0.3075 Acc: 0.8724\n",
      "val Loss: 0.3100 Acc: 0.8679\n",
      "\n",
      "Epoch 30/99\n",
      "----------\n",
      "train Loss: 0.3066 Acc: 0.8712\n",
      "val Loss: 0.3042 Acc: 0.8750\n",
      "\n",
      "Epoch 31/99\n",
      "----------\n",
      "train Loss: 0.3051 Acc: 0.8730\n",
      "val Loss: 0.4633 Acc: 0.7760\n",
      "\n",
      "Epoch 32/99\n",
      "----------\n",
      "train Loss: 0.3031 Acc: 0.8732\n",
      "val Loss: 0.2873 Acc: 0.8845\n",
      "\n",
      "Epoch 33/99\n",
      "----------\n",
      "train Loss: 0.3048 Acc: 0.8731\n",
      "val Loss: 0.2934 Acc: 0.8729\n",
      "\n",
      "Epoch 34/99\n",
      "----------\n",
      "train Loss: 0.2986 Acc: 0.8778\n",
      "val Loss: 0.3110 Acc: 0.8639\n",
      "\n",
      "Epoch 35/99\n",
      "----------\n",
      "train Loss: 0.2926 Acc: 0.8814\n",
      "val Loss: 0.2989 Acc: 0.8746\n",
      "\n",
      "Epoch 36/99\n",
      "----------\n",
      "train Loss: 0.2910 Acc: 0.8794\n",
      "val Loss: 0.6490 Acc: 0.6442\n",
      "\n",
      "Epoch 37/99\n",
      "----------\n",
      "train Loss: 0.2874 Acc: 0.8827\n",
      "val Loss: 0.2716 Acc: 0.8898\n",
      "\n",
      "Epoch 38/99\n",
      "----------\n",
      "train Loss: 0.2876 Acc: 0.8807\n",
      "val Loss: 0.2823 Acc: 0.8835\n",
      "\n",
      "Epoch 39/99\n",
      "----------\n",
      "train Loss: 0.2840 Acc: 0.8831\n",
      "val Loss: 0.2732 Acc: 0.8888\n",
      "\n",
      "Epoch 40/99\n",
      "----------\n",
      "train Loss: 0.2807 Acc: 0.8842\n",
      "val Loss: 0.2961 Acc: 0.8796\n",
      "\n",
      "Epoch 41/99\n",
      "----------\n",
      "train Loss: 0.2792 Acc: 0.8861\n",
      "val Loss: 0.2667 Acc: 0.8945\n",
      "\n",
      "Epoch 42/99\n",
      "----------\n",
      "train Loss: 0.2714 Acc: 0.8898\n",
      "val Loss: 0.3155 Acc: 0.8672\n",
      "\n",
      "Epoch 43/99\n",
      "----------\n",
      "train Loss: 0.2721 Acc: 0.8877\n",
      "val Loss: 0.8607 Acc: 0.5795\n",
      "\n",
      "Epoch 44/99\n",
      "----------\n",
      "train Loss: 0.2657 Acc: 0.8924\n",
      "val Loss: 0.2627 Acc: 0.8977\n",
      "\n",
      "Epoch 45/99\n",
      "----------\n",
      "train Loss: 0.2658 Acc: 0.8922\n",
      "val Loss: 0.3337 Acc: 0.8559\n",
      "\n",
      "Epoch 46/99\n",
      "----------\n",
      "train Loss: 0.2695 Acc: 0.8902\n",
      "val Loss: 0.2795 Acc: 0.8869\n",
      "\n",
      "Epoch 47/99\n",
      "----------\n",
      "train Loss: 0.2617 Acc: 0.8940\n",
      "val Loss: 0.4757 Acc: 0.7831\n",
      "\n",
      "Epoch 48/99\n",
      "----------\n",
      "train Loss: 0.2603 Acc: 0.8959\n",
      "val Loss: 0.2917 Acc: 0.8779\n",
      "\n",
      "Epoch 49/99\n",
      "----------\n",
      "train Loss: 0.2533 Acc: 0.9000\n",
      "val Loss: 0.3235 Acc: 0.8641\n",
      "\n",
      "Epoch 50/99\n",
      "----------\n",
      "train Loss: 0.2520 Acc: 0.8996\n",
      "val Loss: 0.2558 Acc: 0.8992\n",
      "\n",
      "Epoch 51/99\n",
      "----------\n",
      "train Loss: 0.2507 Acc: 0.9004\n",
      "val Loss: 0.2372 Acc: 0.9090\n",
      "\n",
      "Epoch 52/99\n",
      "----------\n",
      "train Loss: 0.2480 Acc: 0.9019\n",
      "val Loss: 0.2362 Acc: 0.9118\n",
      "\n",
      "Epoch 53/99\n",
      "----------\n",
      "train Loss: 0.2453 Acc: 0.9014\n",
      "val Loss: 0.4350 Acc: 0.8123\n",
      "\n",
      "Epoch 54/99\n",
      "----------\n",
      "train Loss: 0.2425 Acc: 0.9052\n",
      "val Loss: 0.2770 Acc: 0.8835\n",
      "\n",
      "Epoch 55/99\n",
      "----------\n",
      "train Loss: 0.2448 Acc: 0.9028\n",
      "val Loss: 0.2420 Acc: 0.9085\n",
      "\n",
      "Epoch 56/99\n",
      "----------\n",
      "train Loss: 0.2400 Acc: 0.9052\n",
      "val Loss: 0.2307 Acc: 0.9089\n",
      "\n",
      "Epoch 57/99\n",
      "----------\n",
      "train Loss: 0.2362 Acc: 0.9084\n",
      "val Loss: 0.2250 Acc: 0.9167\n",
      "\n",
      "Epoch 58/99\n",
      "----------\n",
      "train Loss: 0.2362 Acc: 0.9069\n",
      "val Loss: 0.2319 Acc: 0.9110\n",
      "\n",
      "Epoch 59/99\n",
      "----------\n",
      "train Loss: 0.2347 Acc: 0.9081\n",
      "val Loss: 0.2337 Acc: 0.9101\n",
      "\n",
      "Epoch 60/99\n",
      "----------\n",
      "train Loss: 0.2315 Acc: 0.9099\n",
      "val Loss: 0.2403 Acc: 0.9104\n",
      "\n",
      "Epoch 61/99\n",
      "----------\n",
      "train Loss: 0.2291 Acc: 0.9119\n",
      "val Loss: 0.2231 Acc: 0.9146\n",
      "\n",
      "Epoch 62/99\n",
      "----------\n",
      "train Loss: 0.2272 Acc: 0.9133\n",
      "val Loss: 0.2250 Acc: 0.9148\n",
      "\n",
      "Epoch 63/99\n",
      "----------\n",
      "train Loss: 0.2261 Acc: 0.9143\n",
      "val Loss: 1.9445 Acc: 0.5188\n",
      "\n",
      "Epoch 64/99\n",
      "----------\n",
      "train Loss: 0.2268 Acc: 0.9123\n",
      "val Loss: 0.2096 Acc: 0.9249\n",
      "\n",
      "Epoch 65/99\n",
      "----------\n",
      "train Loss: 0.2221 Acc: 0.9139\n",
      "val Loss: 0.2225 Acc: 0.9193\n",
      "\n",
      "Epoch 66/99\n",
      "----------\n",
      "train Loss: 0.2221 Acc: 0.9152\n",
      "val Loss: 0.2122 Acc: 0.9194\n",
      "\n",
      "Epoch 67/99\n",
      "----------\n",
      "train Loss: 0.2210 Acc: 0.9173\n",
      "val Loss: 0.3195 Acc: 0.8640\n",
      "\n",
      "Epoch 68/99\n",
      "----------\n",
      "train Loss: 0.2197 Acc: 0.9169\n",
      "val Loss: 0.2156 Acc: 0.9194\n",
      "\n",
      "Epoch 69/99\n",
      "----------\n",
      "train Loss: 0.2212 Acc: 0.9149\n",
      "val Loss: 0.2086 Acc: 0.9204\n",
      "\n",
      "Epoch 70/99\n",
      "----------\n",
      "train Loss: 0.2165 Acc: 0.9157\n",
      "val Loss: 0.2223 Acc: 0.9192\n",
      "\n",
      "Epoch 71/99\n",
      "----------\n",
      "train Loss: 0.2172 Acc: 0.9166\n",
      "val Loss: 0.2097 Acc: 0.9224\n",
      "\n",
      "Epoch 72/99\n",
      "----------\n",
      "train Loss: 0.2164 Acc: 0.9184\n",
      "val Loss: 0.4131 Acc: 0.8287\n",
      "\n",
      "Epoch 73/99\n",
      "----------\n",
      "train Loss: 0.2180 Acc: 0.9176\n",
      "val Loss: 0.2104 Acc: 0.9223\n",
      "\n",
      "Epoch 74/99\n",
      "----------\n",
      "train Loss: 0.2177 Acc: 0.9190\n",
      "val Loss: 0.2047 Acc: 0.9243\n",
      "\n",
      "Epoch 75/99\n",
      "----------\n",
      "train Loss: 0.2178 Acc: 0.9171\n",
      "val Loss: 0.2213 Acc: 0.9185\n",
      "\n",
      "Epoch 76/99\n",
      "----------\n",
      "train Loss: 0.2134 Acc: 0.9193\n",
      "val Loss: 0.2216 Acc: 0.9163\n",
      "\n",
      "Epoch 77/99\n",
      "----------\n",
      "train Loss: 0.2144 Acc: 0.9189\n",
      "val Loss: 0.2068 Acc: 0.9247\n",
      "\n",
      "Epoch 78/99\n",
      "----------\n",
      "train Loss: 0.2155 Acc: 0.9190\n",
      "val Loss: 0.2110 Acc: 0.9233\n",
      "\n",
      "Epoch 79/99\n",
      "----------\n",
      "train Loss: 0.2139 Acc: 0.9209\n",
      "val Loss: 0.2309 Acc: 0.9093\n",
      "\n",
      "Epoch 80/99\n",
      "----------\n",
      "train Loss: 0.2118 Acc: 0.9216\n",
      "val Loss: 0.4578 Acc: 0.8151\n",
      "\n",
      "Epoch 81/99\n",
      "----------\n",
      "train Loss: 0.2122 Acc: 0.9203\n",
      "val Loss: 0.2056 Acc: 0.9242\n",
      "\n",
      "Epoch 82/99\n",
      "----------\n",
      "train Loss: 0.2121 Acc: 0.9207\n",
      "val Loss: 0.2080 Acc: 0.9257\n",
      "\n",
      "Epoch 83/99\n",
      "----------\n",
      "train Loss: 0.2131 Acc: 0.9186\n",
      "val Loss: 0.2022 Acc: 0.9273\n",
      "\n",
      "Epoch 84/99\n",
      "----------\n",
      "train Loss: 0.2128 Acc: 0.9208\n",
      "val Loss: 0.2361 Acc: 0.9068\n",
      "\n",
      "Epoch 85/99\n",
      "----------\n",
      "train Loss: 0.2106 Acc: 0.9230\n",
      "val Loss: 0.2135 Acc: 0.9218\n",
      "\n",
      "Epoch 86/99\n",
      "----------\n",
      "train Loss: 0.2131 Acc: 0.9196\n",
      "val Loss: 0.2671 Acc: 0.8962\n",
      "\n",
      "Epoch 87/99\n",
      "----------\n",
      "train Loss: 0.2089 Acc: 0.9231\n",
      "val Loss: 0.2127 Acc: 0.9219\n",
      "\n",
      "Epoch 88/99\n",
      "----------\n",
      "train Loss: 0.2137 Acc: 0.9196\n",
      "val Loss: 0.1988 Acc: 0.9286\n",
      "\n",
      "Epoch 89/99\n",
      "----------\n",
      "train Loss: 0.2100 Acc: 0.9208\n",
      "val Loss: 0.2057 Acc: 0.9264\n",
      "\n",
      "Epoch 90/99\n",
      "----------\n",
      "train Loss: 0.2095 Acc: 0.9213\n",
      "val Loss: 0.2366 Acc: 0.9087\n",
      "\n",
      "Epoch 91/99\n",
      "----------\n",
      "train Loss: 0.2095 Acc: 0.9209\n",
      "val Loss: 0.3228 Acc: 0.8667\n",
      "\n",
      "Epoch 92/99\n",
      "----------\n",
      "train Loss: 0.2109 Acc: 0.9204\n",
      "val Loss: 0.2422 Acc: 0.9062\n",
      "\n",
      "Epoch 93/99\n",
      "----------\n",
      "train Loss: 0.2099 Acc: 0.9203\n",
      "val Loss: 0.1977 Acc: 0.9315\n",
      "\n",
      "Epoch 94/99\n",
      "----------\n",
      "train Loss: 0.2092 Acc: 0.9224\n",
      "val Loss: 0.2018 Acc: 0.9283\n",
      "\n",
      "Epoch 95/99\n",
      "----------\n",
      "train Loss: 0.2112 Acc: 0.9210\n",
      "val Loss: 0.2201 Acc: 0.9160\n",
      "\n",
      "Epoch 96/99\n",
      "----------\n",
      "train Loss: 0.2099 Acc: 0.9208\n",
      "val Loss: 0.4774 Acc: 0.8191\n",
      "\n",
      "Epoch 97/99\n",
      "----------\n",
      "train Loss: 0.2094 Acc: 0.9209\n",
      "val Loss: 0.2123 Acc: 0.9221\n",
      "\n",
      "Epoch 98/99\n",
      "----------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.2091 Acc: 0.9223\n",
      "val Loss: 0.2126 Acc: 0.9205\n",
      "\n",
      "Epoch 99/99\n",
      "----------\n",
      "train Loss: 0.2099 Acc: 0.9224\n",
      "val Loss: 0.1974 Acc: 0.9301\n",
      "\n",
      "Training complete in 284m 14s\n",
      "Best val Acc: 0.931531\n",
      "[[21841  2550]\n",
      " [   63  1882]]\n",
      "Current hyperparameters: {'learning rate': 0.1, 'gamma': 0.5, 'Momentum': 0.9, 'Model': 'model18'}\n",
      "Best hyperparameters: {'learning rate': 0.1, 'gamma': 0.5, 'Momentum': 0.9, 'Model': 'model18'}\n",
      "Best score: 0.9315312\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x504 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "class_weights= [0.924865,0.075135] #1-(#inclass/ #intotal )\n",
    "class_weights = torch.Tensor(class_weights)\n",
    "class_weights=class_weights.to(device)\n",
    "criterion = nn.CrossEntropyLoss(weight = class_weights) \n",
    "\n",
    "# Observe that all parameters are being optimized\n",
    "learning_rate=[0.05, 0.1,0.2]\n",
    "Momentum=[0.5,0.9,0.99]\n",
    "GAMMA=[0.05, 0.1, 0.5]\n",
    "#Batch_size= [16,32]#,64,128]\n",
    "models=[model18, model34, model50]\n",
    "modelnames=[\"model18\",\"model34\",\"model50\"]\n",
    "#ADD IN A THING SO IT SAVES THE TENSORBOARD TO DIFFERENT BITS\n",
    "best_params = None\n",
    "best_score=0.00\n",
    "Current_params=None\n",
    "lrnum=1\n",
    "Momnum=1\n",
    "gamnum=2\n",
    "modnum=0\n",
    "\n",
    "model=models[modnum]\n",
    "model = model.to(device)\n",
    "optimizer_ft = optim.SGD(model.parameters(), lr=learning_rate[lrnum], momentum=Momentum[Momnum])\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=GAMMA[gamnum])\n",
    "writer = SummaryWriter(\"Experiments/BESTRUN100/lr\"+str(learning_rate[lrnum])+\"momentum\"+\n",
    "        str(Momentum[Momnum])+\"gamma\"+str(GAMMA[gamnum])+\"model\"+modelnames[modnum])  \n",
    "model_ft, con_mat, current_score = train_model(model, criterion, optimizer_ft, exp_lr_scheduler,\n",
    "   train,test,num_epochs=100)\n",
    "con_mat=con_mat.cpu().numpy()\n",
    "current_score=current_score.cpu().numpy()\n",
    "Current_params= {'learning rate': learning_rate[lrnum], 'gamma': GAMMA[gamnum], \n",
    "                   'Momentum': Momentum[Momnum], 'Model': modelnames[modnum]}\n",
    "print(con_mat)\n",
    "print(\"Current hyperparameters:\", Current_params)\n",
    "df_cm_ratio = pd.DataFrame(con_mat / np.sum(con_mat, axis=1)[:, None], index=[i for i in labels],\n",
    "                     columns=[i for i in labels])\n",
    "plt.figure(figsize=(12, 7))\n",
    "sn.heatmap(df_cm_ratio, annot=True)\n",
    "if current_score > best_score:\n",
    "    best_score = current_score\n",
    "    best_params = {'learning rate': learning_rate[lrnum], 'gamma': GAMMA[gamnum], \n",
    "                   'Momentum': Momentum[Momnum], 'Model': modelnames[modnum]}\n",
    "                            \n",
    "print(\"Best hyperparameters:\", best_params)\n",
    "print(\"Best score:\", best_score)\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cf_matrix = confusion_matrix_calc(data_loader_test, labels, model_ft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-7cd7e1710a8c598a\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-7cd7e1710a8c598a\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "!kill 1730\n",
    "%tensorboard --logdir Experiments/BESTRUN100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'learning rate': 0.1, 'gamma': 0.5, 'Momentum': 0.9, 'Model': 'model18'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(0.9315312, dtype=float32)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(best_params)\n",
    "best_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learning_rate=[0.05, 0.1,0.2]\n",
    "learning_rate[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model_ft.state_dict(), \"/workspace/myFile/Output/17052023/best_model_params.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'optimizer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_10968/4163751851.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'optimizer' is not defined"
     ]
    }
   ],
   "source": [
    "optimizer.state_dict()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
