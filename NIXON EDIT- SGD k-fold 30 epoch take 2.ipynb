{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To note: Running this on different systems (i.e. local, SCW, server) will result in slight changes needing to the code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/scipy/__init__.py:138: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.4)\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion} is required for this version of \"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.pyplot._IonContext at 0x7f1e3dff4f70>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load libraries\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import sys\n",
    "import torchvision\n",
    "import torchvision.transforms as T\n",
    "import torchvision.models as models\n",
    "from PIL import Image\n",
    "from PIL import ImageEnhance\n",
    "import matplotlib.pyplot as plt\n",
    "import imagesize\n",
    "import subprocess\n",
    "sys.path\n",
    "from IPython.core.debugger import set_trace\n",
    "import scipy.ndimage\n",
    "import matplotlib.patches as patches\n",
    "# plt.rcParams['figure.figsize'] = [12,12]\n",
    "# sys.path.append('/workspace/myFile/Mask_RCNN_Tutorial/')\n",
    "from tqdm import tqdm\n",
    "from torch import nn as nn\n",
    "from torch import optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "import re\n",
    "import time\n",
    "import copy\n",
    "import pylab\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from tempfile import TemporaryDirectory\n",
    "import torch.backends.cudnn as cudnn\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "import seaborn as sn\n",
    "import pandas as pd\n",
    "import glob\n",
    "# Rather than have a messy notebook with a load of functions we can store them in separate .py files and import them\n",
    "\n",
    "cudnn.benchmark = True\n",
    "plt.ion()   # interactive mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "writer = SummaryWriter(\"Experiments/TENSORBOARD\")    # This determines the tensorboard file name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DNADataset(object):\n",
    "    def __init__(self, root, transforms, labels, imDx = False):\n",
    "        self.root, self.transforms, self.labels = root, transforms, labels\n",
    "    \n",
    "        # load all image files, sorting them to ensure they are aligned\n",
    "        self.imgDir = glob.glob(root+\"*/*.tiff\")\n",
    "        Damagednuclei= [x for x in self.imgDir if 'Damaged_nuclei_' in x]\n",
    "        Undamagednuclei= [x for x in self.imgDir if \"No_damage_nuclei\" in x]\n",
    "        #np.random.shuffle(Undamagednuclei)\n",
    "        #Undamagednuclei=Undamagednuclei[:10000]\n",
    "        self.imgDir= Damagednuclei+Undamagednuclei\n",
    "        size80=[]\n",
    "        for x in self.imgDir:\n",
    "            img = Image.open(x) # Open image\n",
    "            w,h=img.size\n",
    "            if w<=80 and h<=80:\n",
    "                size80.append(x)\n",
    "        self.imgDir=size80              \n",
    "        \n",
    "        self.imgs = sorted(self.imgDir) # list of images\n",
    "\n",
    "        \n",
    "\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.imgs[idx]\n",
    "       \n",
    "        # Transform images into tensors\n",
    "        img = Image.open(img_path) # Open image\n",
    "        w,h=img.size\n",
    "        img = np.array(img) # Convert image into an array\n",
    "        img = np.float32(np.divide(img, 2**16)) # Ensure all values are floats\n",
    "        \n",
    "        result=np.zeros((80,80), dtype=np.float32)\n",
    "        x_center = (80 - w) // 2\n",
    "        y_center = (80 - h) // 2 # copy img image into center of result image\n",
    "        result[y_center:y_center+h, x_center:x_center+w] = img\n",
    "        img = result\n",
    "        \n",
    "        targetlab=\"\"\n",
    "        if img_path.find('No_damage_nuclei') != -1:\n",
    "            targetlab= 'Undamaged'\n",
    "        if img_path.find('Damaged_nuclei_') != -1:\n",
    "            targetlab= 'Damaged'  # Find labels corresponding to image\n",
    "        target = self.labels.index(targetlab) # Get the label and assign to a value\n",
    "        \n",
    "        # Convert label to tensor\n",
    "        #torch.to\n",
    "        \n",
    "        if self.transforms is not None:\n",
    "            img = self.transforms(img)\n",
    "#             #print('In the transforms')\n",
    "        imNo = idx\n",
    "        return img, target, imNo\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.imgs)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "root=\"/workspace/myFile/Output/17052023/\"\n",
    "p= glob.glob(root+\"*/*.tiff\")\n",
    "Damagednuclei= [x for x in p if 'Damaged_nuclei_' in x]\n",
    "Undamagednuclei= [x for x in p if \"No_damage_nuclei\" in x]\n",
    "#np.random.shuffle(Undamagednuclei)\n",
    "#Undamagednuclei=Undamagednuclei[:10000]\n",
    "#Undamagednuclei"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "imDr = \"/workspace/myFile/Output/17052023/\"  # Image patches directory\n",
    "\n",
    "labels = ['Damaged', 'Undamaged']  # Your labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For data augmentation\n",
    "def get_transform(train):\n",
    "    transforms = []\n",
    "\n",
    "    transforms.append(T.ToTensor())\n",
    "    #transforms.append(T.Normalize([0.0019368887995516483], [0.00672996630111016]))\n",
    "    #transforms.append(T.RandomHorizontalFlip(0.5))\n",
    "    \n",
    "    if train:\n",
    "        transforms.append(T.RandomHorizontalFlip(p=1))\n",
    "        transforms.append(T.RandomVerticalFlip(p=1))\n",
    "    \n",
    "    return T.Compose(transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, scheduler, train, test, num_epochs=25):\n",
    "    since = time.time()\n",
    "    # Create a temporary directory to save training checkpoints\n",
    "    with TemporaryDirectory() as tempdir:\n",
    "        best_model_params_path = os.path.join(tempdir, 'best_model_params.pt')\n",
    "\n",
    "        torch.save(model.state_dict(), best_model_params_path)\n",
    "        best_acc = 0.0\n",
    "        \n",
    "        for epoch in range(num_epochs):\n",
    "            print(f'Epoch {epoch}/{num_epochs - 1}')\n",
    "            print('-' * 10)\n",
    "            dataset_train = torch.utils.data.Subset(dataSetTrain, train[epoch])\n",
    "            dataset_test = torch.utils.data.Subset(dataSetTest, test[epoch])\n",
    "            data_loader_train = torch.utils.data.DataLoader(\n",
    "                dataset_train, batch_size=128, shuffle=True, num_workers=0)\n",
    "\n",
    "            data_loader_test = torch.utils.data.DataLoader(\n",
    "                dataset_test, batch_size=128, shuffle=False, num_workers=0)\n",
    "            # Each epoch has a training and validation phase\n",
    "            for phase in ['train', 'val']:\n",
    "                if phase == 'train':\n",
    "                    model.train()  # Set model to training mode\n",
    "                    dataloaders = data_loader_train\n",
    "                else:\n",
    "                    model.eval()   # Set model to evaluate mode\n",
    "                    dataloaders = data_loader_test\n",
    "\n",
    "                running_loss = 0.0\n",
    "                running_corrects = 0\n",
    "                damaged_len=0\n",
    "                damaged_corrects = 0\n",
    "                undamaged_len=0\n",
    "                undamaged_corrects = 0\n",
    "\n",
    "                # Iterate over data.\n",
    "                for inputs, labels, imNo in dataloaders:\n",
    "                    inputs = inputs.to(device)\n",
    "                    labels = labels.to(device)\n",
    "\n",
    "                    # zero the parameter gradients\n",
    "                    optimizer.zero_grad()\n",
    "\n",
    "                    # forward\n",
    "                    # track history if only in train\n",
    "                    with torch.set_grad_enabled(phase == 'train'):\n",
    "                        outputs = model(inputs)\n",
    "                        _, preds = torch.max(outputs, 1)\n",
    "                        loss = criterion(outputs, labels)\n",
    "                        # backward + optimize only if in training phase\n",
    "                        if phase == 'train':\n",
    "                            loss.backward()\n",
    "                            optimizer.step()\n",
    "\n",
    "                    # statistics\n",
    "                    running_loss += loss.item() * inputs.size(0)    # Loss\n",
    "                    nada=torch.tensor(np.zeros(len(labels))).to(device)\n",
    "                    uno=nada+1\n",
    "                    falseneg=preds+1\n",
    "                    falsepos=preds-1\n",
    "                    FPplusTN=torch.sum(labels==nada)\n",
    "                    TPplusFN=torch.sum(labels==uno)\n",
    "                    FN=torch.sum(labels==falseneg)\n",
    "                    FP=torch.sum(labels==falsepos)\n",
    "                    TN=FPplusTN-FP\n",
    "                    TP=TPplusFN-FN\n",
    "                    running_corrects += torch.sum(preds == labels.data) # Accuracy\n",
    "                    damaged_len+=TPplusFN\n",
    "                    damaged_corrects += TP\n",
    "                    undamaged_len+=FPplusTN\n",
    "                    undamaged_corrects += TN\n",
    "                damaged_acc = damaged_corrects / damaged_len\n",
    "                undamaged_acc = undamaged_corrects/undamaged_len\n",
    "                epoch_acc= (damaged_acc+undamaged_acc)/2\n",
    "                \n",
    "                if phase == 'train':\n",
    "                    scheduler.step()\n",
    "\n",
    "                epoch_loss = running_loss / dataset_sizes[phase]    # Loss metric per epoch\n",
    "                #epoch_acc = running_corrects.double() / dataset_sizes[phase]    # Accuracy metric per epoch\n",
    "\n",
    "                if phase == \"train\":    # This is the tensorboard code that writes accuracy and loss metrics\n",
    "                    writer.add_scalar(\"Train/Accuracy\", epoch_acc, epoch)\n",
    "                    writer.add_scalar(\"Train/Loss\", epoch_loss, epoch)\n",
    "                else:\n",
    "                    writer.add_scalar(\"Validation/Accuracy\", epoch_acc, epoch)\n",
    "                    writer.add_scalar(\"Validation/Loss\", epoch_loss, epoch)\n",
    "\n",
    "                print(f'{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n",
    "\n",
    "                # deep copy the model\n",
    "                if phase == 'val' and epoch_acc >= best_acc: \n",
    "                    # This compares validation accuracy to previous bests and adjusts model weights accordingly\n",
    "                    best_acc = epoch_acc\n",
    "                    torch.save(model.state_dict(), best_model_params_path)\n",
    "                    con_mat= torch.tensor([[damaged_corrects, damaged_len-damaged_corrects],[undamaged_len-undamaged_corrects,undamaged_corrects]])\n",
    "\n",
    "            print()\n",
    "\n",
    "        time_elapsed = time.time() - since  # Nice way to measure training time but info also stored (indirectly) by tensorboard\n",
    "        print(\n",
    "            f'Training complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')\n",
    "        print(f'Best val Acc: {best_acc:4f}')\n",
    "        #labels= labels.cpu().numpy()\n",
    "        #preds=preds.cpu().numpy()\n",
    "        model.load_state_dict(torch.load(best_model_params_path))\n",
    "    writer.close()\n",
    "    return model, con_mat   # We want to return the model because its the model, also confusion matrix for later analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is your RESNET\n",
    "# Initialize CNN with kaiming\n",
    "def init_cnn(m):\n",
    "    # Set the weights of the RESNET\n",
    "    if getattr(m, 'bias', None) is not None: nn.init.constant_(m.bias, 0)\n",
    "    if isinstance(m, (nn.Conv2d,nn.Linear)): nn.init.kaiming_normal_(m.weight)\n",
    "    for l in m.children(): init_cnn(l)\n",
    "\n",
    "\n",
    "# noop function for returning nothing\n",
    "def noop(x): return x\n",
    "# activation function(RELU)\n",
    "act_fn = nn.ReLU(inplace=True)\n",
    "\n",
    "# Flatten\n",
    "class Flatten(nn.Module):\n",
    "    def forward(self, x): return x.view(x.size(0), -1)\n",
    "\n",
    "# Make a convolution\n",
    "def conv(ni, nf, ks=3, stride=1, bias=False):\n",
    "    return nn.Conv2d(ni, nf, kernel_size=ks, stride=stride, padding=ks//2, bias=bias)\n",
    "\n",
    "# Create a convuolutional layer with convolution and batch norm\n",
    "def conv_layer(ni, nf, ks=3, stride=1, zero_bn=False, act=True):\n",
    "    bn = nn.BatchNorm2d(nf) # get a 2d batch norm from Pytorhc\n",
    "    nn.init.constant_(bn.weight, 0. if zero_bn else 1.)\n",
    "    layers = [conv(ni, nf, ks, stride=stride), bn]\n",
    "    if act: layers.append(act_fn) # add in the activation function if act is true\n",
    "    return nn.Sequential(*layers)\n",
    "\n",
    "\n",
    "# Resblock\n",
    "class ResBlock(nn.Module):\n",
    "    def __init__(self, expansion, ni, nh, stride = 1):\n",
    "        super().__init__()\n",
    "        # ni - number of inputs channels, nf - number of filters\n",
    "        # nh - number of filters in first conv\n",
    "        # expansion is 1 for resnet 18, 34 and 4 for larger networks\n",
    "        nf, ni = nh*expansion, ni*expansion\n",
    "        layers = [conv_layer(ni, nh, 3, stride = stride), # for resnet < 34 2 convs per resblock\n",
    "                 conv_layer(nh, nf, 3, zero_bn = True, act = False)\n",
    "                 ] if expansion == 1 else [ # for RESNET > 34 then 3 convs per block with bottleneck\n",
    "                            conv_layer(ni, nh, 1),\n",
    "                            conv_layer(nh, nh, 3, stride = stride),\n",
    "                            conv_layer(nh, nf, 1, zero_bn = True, act = False)\n",
    "        ]\n",
    "        self.convs = nn.Sequential(*layers) # Creates the conv layers\n",
    "        self.idconv = noop if ni==nf else conv_layer(ni, nf, 1, act = False) # id convolution ()\n",
    "        self.pool = noop if stride== 1 else nn.AvgPool2d(2, ceil_mode = True) # average pool on \n",
    "        \n",
    "    def forward(self, x): \n",
    "        # Forward function adds the convolution part to the id part \n",
    "        #return act_fn(self.convs(x)) + self.idconv(self.pool(x))\n",
    "        return act_fn(self.convs(x) + self.idconv(self.pool(x)))\n",
    "\n",
    "# XResnet\n",
    "class XResNet(nn.Sequential):\n",
    "    @classmethod\n",
    "    def create(cls, expansion, layers, c_in=3, c_out=1000):\n",
    "        nfs = [c_in, (c_in + 1)*8, 64, 64] # number of filters in stem layer (c_in is number of image channels)\n",
    "        stem = [conv_layer(nfs[i], nfs[i+1], stride=2 if i==0 else 1)\n",
    "            for i in range(3)]\n",
    "\n",
    "        nfs = [64//expansion,64,128,256,512]\n",
    "        res_layers = [cls._make_layer(expansion, nfs[i], nfs[i+1],\n",
    "                                      n_blocks=l, stride=1 if i==0 else 2)\n",
    "                  for i,l in enumerate(layers)]\n",
    "        res = cls(\n",
    "        *stem,\n",
    "        nn.MaxPool2d(kernel_size=3, stride = 2, padding = 1), # then a max pooling layer\n",
    "        *res_layers,\n",
    "        nn.AdaptiveAvgPool2d(1), Flatten(), \n",
    "        nn.Linear(nfs[-1]*expansion, c_out)\n",
    "        )\n",
    "        init_cnn(res)\n",
    "        return res\n",
    "        \n",
    "    @staticmethod\n",
    "    def _make_layer(expansion, ni, nf, n_blocks, stride): # returns a resblock\n",
    "        return nn.Sequential(\n",
    "        *[ResBlock(expansion, ni if i==0 else nf, nf, stride if i==0 else 1)\n",
    "         for i in range(n_blocks)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def xresnet18 (**kwargs): return XResNet.create(1, [2, 2,  2, 2], **kwargs)\n",
    "def xresnet34 (**kwargs): return XResNet.create(1, [3, 4,  6, 3], **kwargs)\n",
    "def xresnet50 (**kwargs): return XResNet.create(4, [3, 4,  6, 3], **kwargs)\n",
    "model = xresnet18(c_in = 1, c_out = 2)\n",
    "#model34 = xresnet34(c_in = 1, c_out = 2)\n",
    "#model50 = xresnet50(c_in = 1, c_out = 2)\n",
    "model = model.to(device)\n",
    "\n",
    "# Label smoothing cross entropy\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "def reduce_loss(loss, reduction='mean'):\n",
    "    return loss.mean() if reduction=='mean' else loss.sum() if reduction=='sum' else loss\n",
    "\n",
    "class LabelSmoothingCrossEntropy(nn.Module):\n",
    "    def __init__(self, ε:float=0.1, reduction='mean'):\n",
    "        super().__init__()\n",
    "        self.ε,self.reduction = ε,reduction\n",
    "    \n",
    "    def forward(self, output, target):\n",
    "        c = output.size()[-1]\n",
    "        log_preds = F.log_softmax(output, dim=-1)\n",
    "        loss = reduce_loss(-log_preds.sum(dim=-1), self.reduction)\n",
    "        nll = F.nll_loss(log_preds, target, reduction=self.reduction)\n",
    "        return lin_comb(loss/c, nll, self.ε)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions that shows the image, true class, predicted class and degree of prediction\n",
    "\n",
    "def images_to_probs(net, images):\n",
    "    '''\n",
    "    Generates predictions and corresponding probabilities from a trained\n",
    "    network and a list of images\n",
    "    '''\n",
    "    output = net(images)\n",
    "    # convert output probabilities to predicted class\n",
    "    _, preds_tensor = torch.max(output, 1)\n",
    "    preds = np.squeeze(preds_tensor.numpy())\n",
    "    return preds, [F.softmax(el, dim=0)[i].item() for i, el in zip(preds, output)]\n",
    "\n",
    "\n",
    "def plot_classes_preds(net, images, labels):\n",
    "    '''\n",
    "    Generates matplotlib Figure using a trained network, along with images\n",
    "    and labels from a batch, that shows the network's top prediction along\n",
    "    with its probability, alongside the actual label, coloring this\n",
    "    information based on whether the prediction was correct or not.\n",
    "    Uses the \"images_to_probs\" function.\n",
    "    '''\n",
    "    preds, probs = images_to_probs(net, images)\n",
    "    # plot the images in the batch, along with predicted and true labels\n",
    "    fig = plt.figure(figsize=(12, 48))\n",
    "    for idx in np.arange(4):\n",
    "        ax = fig.add_subplot(1, 4, idx+1, xticks=[], yticks=[])\n",
    "        matplotlib_imshow(images[idx], one_channel=True)\n",
    "        ax.set_title(\"{0}, {1:.1f}%\\n(label: {2})\".format(\n",
    "            labels[preds[idx]],\n",
    "            probs[idx] * 100.0,\n",
    "            labels[labels[idx]]),\n",
    "                    color=(\"green\" if preds[idx]==labels[idx].item() else \"red\"))\n",
    "    return fig\n",
    "\n",
    "def matplotlib_imshow(img, one_channel=True):\n",
    "    if one_channel:\n",
    "        img = img.mean(dim=0)\n",
    "    img = img / 2 + 0.5     # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    if one_channel:\n",
    "        plt.imshow(npimg, cmap=\"Greys\")\n",
    "    else:\n",
    "        plt.imshow(np.transpose(npimg, (1, 2, 0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def confusion_matrix_calc(data_loader_test, classes, model_ft):       \n",
    "        y_pred = []\n",
    "        y_true = []\n",
    "        for inputs, labels, imNo in data_loader_test:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "                output = model_ft(inputs) # Feed Network\n",
    "\n",
    "                output = (torch.max(torch.exp(output), 1)[1]).data.cpu().numpy()\n",
    "                y_pred.extend(output) # Save Prediction\n",
    "                \n",
    "                labels = labels.data.cpu().numpy()\n",
    "                y_true.extend(labels) # Save Truth\n",
    "\n",
    "        # constant for classes\n",
    "        # classes = ('Alive', 'Dead')\n",
    "\n",
    "        # Build confusion matrix\n",
    "        cf_matrix = confusion_matrix(y_true, y_pred)\n",
    "        return cf_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "k=5 #NUMBER OF K FOLDS\n",
    "epoch=range(30) #NUMBER OF EPOCHS\n",
    "\n",
    "torch.manual_seed(10)\n",
    "imIdx = torch.randperm(1).tolist()\n",
    "\n",
    "## Create dataset\n",
    "dataSetTrain = DNADataset(imDr, get_transform(train = True), labels, imDx=imIdx)\n",
    "dataSetTest = DNADataset(imDr, get_transform(train = False), labels, imDx=imIdx)\n",
    "\n",
    "data_loader_train=[]\n",
    "data_loader_test=[]\n",
    "\n",
    "# ## Create dataloaders\n",
    "# Get subset\n",
    "torch.manual_seed(10)\n",
    "indices = torch.randperm(len(dataSetTrain)).tolist()\n",
    "\n",
    "noTrain = int(len(dataSetTrain)*0.7)\n",
    "train=[]\n",
    "test=[]\n",
    "for epoch in epoch:\n",
    "    indices = torch.randperm(len(dataSetTrain)).tolist()\n",
    "    TotalSet=list(range(len(dataSetTrain)))\n",
    "    Kfifth = len(dataSetTrain)//k\n",
    "    split= epoch%k\n",
    "    train.append(TotalSet[(split+1)*Kfifth:]+TotalSet[:Kfifth*split])\n",
    "\n",
    "    indices = torch.randperm(len(dataSetTest)).tolist()\n",
    "    TotalSet=list(range(len(dataSetTrain)))\n",
    "    test.append(TotalSet[split*Kfifth:(split+1)*Kfifth])\n",
    "\n",
    "#dataset_train = torch.utils.data.Subset(dataSetTrain, indices[-noTrain:])\n",
    "\n",
    "#dataset_test = torch.utils.data.Subset(dataSetTest, indices[:-noTrain])\n",
    "#len(indices), len(indices[:-50]), len(indices[-50:]), 50/191, type(dataset_test)\n",
    "\n",
    "dataset_sizes = {'train': len(train[0]), 'val': len(test[0])}\n",
    "\n",
    "#dataset_train = torch.utils.data.Subset(dataSetTrain, train)\n",
    "#data_loader_train.append(dataset_train)\n",
    "#dataset_testo = torch.utils.data.Subset(dataSetTest, test)\n",
    "#data_loader_test.append(dataset_testo)\n",
    "# define training and validation data loaders\n",
    "\n",
    "\n",
    "# Collate function (gathers together the outputs)\n",
    "# def collate_fn(batch):\n",
    "#     return tuple(zip(*batch))\n",
    "\n",
    "#len(indices[-noTrain:]), dataset_sizes\n",
    "#dataset_test[0][1], dataset_test[3][1], dataset_test[-1][1], dataSetTrain.imgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_weights= [0.924865,0.075135] #1-(#inclass/ #intotal )\n",
    "class_weights = torch.Tensor(class_weights)\n",
    "class_weights=class_weights.to(device)\n",
    "criterion = nn.CrossEntropyLoss(weight = class_weights) \n",
    "\n",
    "# Observe that all parameters are being optimized\n",
    "optimizer_ft = optim.SGD(model.parameters(), lr=0.1, momentum=0.9) # standard ADAM optimiser\n",
    "\n",
    "# Decay LR by a factor of 0.1 every 7 epochs\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/29\n",
      "----------\n",
      "train Loss: 0.5480 Acc: 0.7503\n",
      "val Loss: 4.5232 Acc: 0.5000\n",
      "\n",
      "Epoch 1/29\n",
      "----------\n",
      "train Loss: 0.4538 Acc: 0.7927\n",
      "val Loss: 0.4206 Acc: 0.6272\n",
      "\n",
      "Epoch 2/29\n",
      "----------\n",
      "train Loss: 0.3692 Acc: 0.8483\n",
      "val Loss: 2.6980 Acc: 0.5310\n",
      "\n",
      "Epoch 3/29\n",
      "----------\n",
      "train Loss: 0.4098 Acc: 0.5923\n",
      "val Loss: 0.5674 Acc: 0.7093\n",
      "\n",
      "Epoch 4/29\n",
      "----------\n",
      "train Loss: 0.4041 Acc: 0.8211\n",
      "val Loss: 0.8672 Acc: 0.5017\n",
      "\n",
      "Epoch 5/29\n",
      "----------\n",
      "train Loss: 0.4158 Acc: 0.8156\n",
      "val Loss: 0.3415 Acc: 0.6450\n",
      "\n",
      "Epoch 6/29\n",
      "----------\n",
      "train Loss: 0.3879 Acc: 0.8289\n",
      "val Loss: 4.3162 Acc: 0.5001\n",
      "\n",
      "Epoch 7/29\n",
      "----------\n",
      "train Loss: 0.3116 Acc: 0.8748\n",
      "val Loss: 3.7218 Acc: 0.5533\n",
      "\n",
      "Epoch 8/29\n",
      "----------\n",
      "train Loss: 0.3553 Acc: 0.6795\n",
      "val Loss: 0.5305 Acc: 0.7331\n",
      "\n",
      "Epoch 9/29\n",
      "----------\n",
      "train Loss: 0.3473 Acc: 0.8508\n",
      "val Loss: 0.4164 Acc: 0.5518\n",
      "\n",
      "Epoch 10/29\n",
      "----------\n",
      "train Loss: 0.3705 Acc: 0.8381\n",
      "val Loss: 2.3520 Acc: 0.5403\n",
      "\n",
      "Epoch 11/29\n",
      "----------\n",
      "train Loss: 0.3412 Acc: 0.8529\n",
      "val Loss: 0.3485 Acc: 0.7074\n",
      "\n",
      "Epoch 12/29\n",
      "----------\n",
      "train Loss: 0.2932 Acc: 0.8840\n",
      "val Loss: 0.5042 Acc: 0.6486\n",
      "\n",
      "Epoch 13/29\n",
      "----------\n",
      "train Loss: 0.3366 Acc: 0.7087\n",
      "val Loss: 0.7649 Acc: 0.6232\n",
      "\n",
      "Epoch 14/29\n",
      "----------\n",
      "train Loss: 0.3461 Acc: 0.8516\n",
      "val Loss: 3.1245 Acc: 0.4971\n",
      "\n",
      "Epoch 15/29\n",
      "----------\n",
      "train Loss: 0.3538 Acc: 0.8454\n",
      "val Loss: 0.0440 Acc: 0.6382\n",
      "\n",
      "Epoch 16/29\n",
      "----------\n",
      "train Loss: 0.3268 Acc: 0.8606\n",
      "val Loss: 0.3898 Acc: 0.7270\n",
      "\n",
      "Epoch 17/29\n",
      "----------\n",
      "train Loss: 0.2822 Acc: 0.8890\n",
      "val Loss: 0.4700 Acc: 0.6823\n",
      "\n",
      "Epoch 18/29\n",
      "----------\n",
      "train Loss: 0.3161 Acc: 0.7434\n",
      "val Loss: 0.4731 Acc: 0.7561\n",
      "\n",
      "Epoch 19/29\n",
      "----------\n",
      "train Loss: 0.3314 Acc: 0.8596\n",
      "val Loss: 0.3914 Acc: 0.5539\n",
      "\n",
      "Epoch 20/29\n",
      "----------\n",
      "train Loss: 0.3460 Acc: 0.8508\n",
      "val Loss: 0.2482 Acc: 0.6586\n",
      "\n",
      "Epoch 21/29\n",
      "----------\n",
      "train Loss: 0.3239 Acc: 0.8612\n",
      "val Loss: 0.3571 Acc: 0.7212\n",
      "\n",
      "Epoch 22/29\n",
      "----------\n",
      "train Loss: 0.2871 Acc: 0.8876\n",
      "val Loss: 0.6202 Acc: 0.7038\n",
      "\n",
      "Epoch 23/29\n",
      "----------\n",
      "train Loss: 0.3516 Acc: 0.7764\n",
      "val Loss: 0.3970 Acc: 0.7840\n",
      "\n",
      "Epoch 24/29\n",
      "----------\n",
      "train Loss: 0.3441 Acc: 0.8528\n",
      "val Loss: 0.4491 Acc: 0.6314\n",
      "\n",
      "Epoch 25/29\n",
      "----------\n",
      "train Loss: 0.3439 Acc: 0.8523\n",
      "val Loss: 0.4489 Acc: 0.6778\n",
      "\n",
      "Epoch 26/29\n",
      "----------\n",
      "train Loss: 0.3205 Acc: 0.8634\n",
      "val Loss: 2.2859 Acc: 0.5308\n",
      "\n",
      "Epoch 27/29\n",
      "----------\n",
      "train Loss: 0.2826 Acc: 0.8881\n",
      "val Loss: 0.4922 Acc: 0.7029\n",
      "\n",
      "Epoch 28/29\n",
      "----------\n",
      "train Loss: 0.3935 Acc: 0.7834\n",
      "val Loss: 0.4390 Acc: 0.7525\n",
      "\n",
      "Epoch 29/29\n",
      "----------\n",
      "train Loss: 0.3260 Acc: 0.8648\n",
      "val Loss: 0.3704 Acc: 0.6248\n",
      "\n",
      "Training complete in 86m 53s\n",
      "Best val Acc: 0.784025\n"
     ]
    }
   ],
   "source": [
    "model_ft, con_mat = train_model(model, criterion, optimizer_ft, exp_lr_scheduler, \n",
    "                                    train,test,num_epochs=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cf_matrix = confusion_matrix_calc(data_loader_test, labels, model_ft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x504 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "con_mat=con_mat.cpu().numpy()\n",
    "df_cm_ratio = pd.DataFrame(con_mat / np.sum(con_mat, axis=1)[:, None], index=[i for i in labels],\n",
    "                     columns=[i for i in labels])\n",
    "plt.figure(figsize=(12, 7))\n",
    "sn.heatmap(df_cm_ratio, annot=True)\n",
    "# plt.save(\"Confusion_matrix_ratio.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x504 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_cm_raw = pd.DataFrame(con_mat, index=[i for i in labels],\n",
    "                     columns=[i for i in labels])\n",
    "plt.figure(figsize=(12, 7))\n",
    "sn.heatmap(df_cm_raw, annot=True)\n",
    "# plt.save(\"Confusion_matrix_raw.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[11948,  6783],\n",
       "       [  531,  7074]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "con_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_loader_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
