{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To note: Running this on different systems (i.e. local, SCW, server) will result in slight changes needing to the code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/scipy/__init__.py:138: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.4)\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion} is required for this version of \"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.pyplot._IonContext at 0x7f5d3c549850>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load libraries\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import sys\n",
    "import torchvision\n",
    "import torchvision.transforms as T\n",
    "import torchvision.models as models\n",
    "from PIL import Image\n",
    "from PIL import ImageEnhance\n",
    "import matplotlib.pyplot as plt\n",
    "import imagesize\n",
    "import subprocess\n",
    "sys.path\n",
    "from IPython.core.debugger import set_trace\n",
    "import scipy.ndimage\n",
    "import matplotlib.patches as patches\n",
    "# plt.rcParams['figure.figsize'] = [12,12]\n",
    "# sys.path.append('/workspace/myFile/Mask_RCNN_Tutorial/')\n",
    "from tqdm import tqdm\n",
    "from torch import nn as nn\n",
    "from torch import optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "import re\n",
    "import time\n",
    "import copy\n",
    "import pylab\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from tempfile import TemporaryDirectory\n",
    "import torch.backends.cudnn as cudnn\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "import seaborn as sn\n",
    "import pandas as pd\n",
    "import glob\n",
    "# Rather than have a messy notebook with a load of functions we can store them in separate .py files and import them\n",
    "\n",
    "cudnn.benchmark = True\n",
    "plt.ion()   # interactive mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "writer = SummaryWriter(\"Experiments/TENSORBOARD\")    # This determines the tensorboard file name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DNADataset(object):\n",
    "    def __init__(self, root, transforms, labels, imDx = False):\n",
    "        self.root, self.transforms, self.labels = root, transforms, labels\n",
    "    \n",
    "        # load all image files, sorting them to ensure they are aligned\n",
    "        self.imgDir = glob.glob(root+\"*/*.tiff\")\n",
    "        Damagednuclei= [x for x in self.imgDir if 'Damaged_nuclei_' in x]\n",
    "        Undamagednuclei= [x for x in self.imgDir if \"No_damage_nuclei\" in x]\n",
    "        #np.random.shuffle(Undamagednuclei)\n",
    "        #Undamagednuclei=Undamagednuclei[:10000]\n",
    "        self.imgDir= Damagednuclei+Undamagednuclei\n",
    "        size80=[]\n",
    "        for x in self.imgDir:\n",
    "            img = Image.open(x) # Open image\n",
    "            w,h=img.size\n",
    "            if w<=80 and h<=80:\n",
    "                size80.append(x)\n",
    "        self.imgDir=size80              \n",
    "        \n",
    "        self.imgs = sorted(self.imgDir) # list of images\n",
    "\n",
    "        \n",
    "\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.imgs[idx]\n",
    "       \n",
    "        # Transform images into tensors\n",
    "        img = Image.open(img_path) # Open image\n",
    "        w,h=img.size\n",
    "        img = np.array(img) # Convert image into an array\n",
    "        img = np.float32(np.divide(img, 2**16)) # Ensure all values are floats\n",
    "        \n",
    "        result=np.zeros((80,80), dtype=np.float32)\n",
    "        x_center = (80 - w) // 2\n",
    "        y_center = (80 - h) // 2 # copy img image into center of result image\n",
    "        result[y_center:y_center+h, x_center:x_center+w] = img\n",
    "        img = result\n",
    "        \n",
    "        targetlab=\"\"\n",
    "        if img_path.find('No_damage_nuclei') != -1:\n",
    "            targetlab= 'Undamaged'\n",
    "        if img_path.find('Damaged_nuclei_') != -1:\n",
    "            targetlab= 'Damaged'  # Find labels corresponding to image\n",
    "        target = self.labels.index(targetlab) # Get the label and assign to a value\n",
    "        \n",
    "        # Convert label to tensor\n",
    "        #torch.to\n",
    "        \n",
    "        if self.transforms is not None:\n",
    "            img = self.transforms(img)\n",
    "#             #print('In the transforms')\n",
    "        imNo = idx\n",
    "        return img, target, imNo\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.imgs)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "imDr = \"/workspace/myFile/Output/17052023/\"  # Image patches directory\n",
    "\n",
    "labels = ['Damaged', 'Undamaged']  # Your labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For data augmentation\n",
    "def get_transform(train):\n",
    "    transforms = []\n",
    "\n",
    "    transforms.append(T.ToTensor())\n",
    "    #transforms.append(T.Normalize([0.0019368887995516483], [0.00672996630111016]))\n",
    "    #transforms.append(T.RandomHorizontalFlip(0.5))\n",
    "    \n",
    "    if train:\n",
    "        transforms.append(T.RandomHorizontalFlip(p=1))\n",
    "        transforms.append(T.RandomVerticalFlip(p=1))\n",
    "    \n",
    "    return T.Compose(transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, scheduler, train, test, num_epochs=25):\n",
    "    since = time.time()\n",
    "    # Create a temporary directory to save training checkpoints\n",
    "    with TemporaryDirectory() as tempdir:\n",
    "        best_model_params_path = os.path.join(tempdir, 'best_model_params.pt')\n",
    "\n",
    "        torch.save(model.state_dict(), best_model_params_path)\n",
    "        best_acc = 0.0\n",
    "        \n",
    "        for epoch in range(num_epochs):\n",
    "            print(f'Epoch {epoch}/{num_epochs - 1}')\n",
    "            print('-' * 10)\n",
    "            dataset_train = torch.utils.data.Subset(dataSetTrain, train[epoch])\n",
    "            dataset_test = torch.utils.data.Subset(dataSetTest, test[epoch])\n",
    "            data_loader_train = torch.utils.data.DataLoader(\n",
    "                dataset_train, batch_size=128, shuffle=True, num_workers=0)\n",
    "\n",
    "            data_loader_test = torch.utils.data.DataLoader(\n",
    "                dataset_test, batch_size=128, shuffle=False, num_workers=0)\n",
    "            # Each epoch has a training and validation phase\n",
    "            for phase in ['val']:\n",
    "                if phase == 'train':\n",
    "                    model.train()  # Set model to training mode\n",
    "                    dataloaders = data_loader_train\n",
    "                else:\n",
    "                    model.eval()   # Set model to evaluate mode\n",
    "                    dataloaders = data_loader_test\n",
    "\n",
    "                running_loss = 0.0\n",
    "                running_corrects = 0\n",
    "                damaged_len=0\n",
    "                damaged_corrects = 0\n",
    "                undamaged_len=0\n",
    "                undamaged_corrects = 0\n",
    "\n",
    "                # Iterate over data.\n",
    "                for inputs, labels, imNo in dataloaders:\n",
    "                    inputs = inputs.to(device)\n",
    "                    labels = labels.to(device)\n",
    "\n",
    "                    # zero the parameter gradients\n",
    "                    optimizer.zero_grad()\n",
    "\n",
    "                    # forward\n",
    "                    # track history if only in train\n",
    "                    with torch.set_grad_enabled(phase == 'train'):\n",
    "                        outputs = model(inputs)\n",
    "                        _, preds = torch.max(outputs, 1)\n",
    "                        loss = criterion(outputs, labels)\n",
    "                        # backward + optimize only if in training phase\n",
    "                        if phase == 'train':\n",
    "                            loss.backward()\n",
    "                            optimizer.step()\n",
    "\n",
    "                    # statistics\n",
    "                    running_loss += loss.item() * inputs.size(0)    # Loss\n",
    "                    nada=torch.tensor(np.zeros(len(labels))).to(device)\n",
    "                    uno=nada+1\n",
    "                    falseneg=preds+1\n",
    "                    falsepos=preds-1\n",
    "                    FPplusTN=torch.sum(labels==nada)\n",
    "                    TPplusFN=torch.sum(labels==uno)\n",
    "                    FN=torch.sum(labels==falseneg)\n",
    "                    FP=torch.sum(labels==falsepos)\n",
    "                    TN=FPplusTN-FP\n",
    "                    TP=TPplusFN-FN\n",
    "                    running_corrects += torch.sum(preds == labels.data) # Accuracy\n",
    "                    damaged_len+=TPplusFN\n",
    "                    damaged_corrects += TP\n",
    "                    undamaged_len+=FPplusTN\n",
    "                    undamaged_corrects += TN\n",
    "                damaged_acc = damaged_corrects / damaged_len\n",
    "                undamaged_acc = undamaged_corrects/undamaged_len\n",
    "                epoch_acc= (damaged_acc+undamaged_acc)/2\n",
    "                proper_acc=(damaged_corrects+undamaged_corrects)/(damaged_len+undamaged_len)\n",
    "                if phase == 'train':\n",
    "                    scheduler.step()\n",
    "\n",
    "                epoch_loss = running_loss / dataset_sizes[phase]    # Loss metric per epoch\n",
    "                #epoch_acc = running_corrects.double() / dataset_sizes[phase]    # Accuracy metric per epoch\n",
    "\n",
    "                if phase == \"train\":    # This is the tensorboard code that writes accuracy and loss metrics\n",
    "                    writer.add_scalar(\"Train/Accuracy\", epoch_acc, epoch)\n",
    "                    writer.add_scalar(\"Train/Loss\", epoch_loss, epoch)\n",
    "                else:\n",
    "                    writer.add_scalar(\"Validation/Accuracy\", epoch_acc, epoch)\n",
    "                    writer.add_scalar(\"Validation/Loss\", epoch_loss, epoch)\n",
    "\n",
    "                print(f'{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n",
    "                print(\"proper accuracy=\")\n",
    "                print(proper_acc)\n",
    "                print(\"damaged accuracy=\")\n",
    "                print(damaged_acc)\n",
    "                print(\"undamaged accuracy=\")\n",
    "                print(undamaged_acc)\n",
    "                con_matter= torch.tensor([[damaged_corrects, damaged_len-damaged_corrects],[undamaged_len-undamaged_corrects,undamaged_corrects]])\n",
    "                con_matter=con_matter.cpu().numpy()\n",
    "                print(con_matter)\n",
    "                # deep copy the model\n",
    "                if phase == 'val' and epoch_acc >= best_acc: \n",
    "                    # This compares validation accuracy to previous bests and adjusts model weights accordingly\n",
    "                    best_acc = epoch_acc\n",
    "                    torch.save(model.state_dict(), best_model_params_path)\n",
    "                    con_mat= torch.tensor([[damaged_corrects, damaged_len-damaged_corrects],[undamaged_len-undamaged_corrects,undamaged_corrects]])\n",
    "\n",
    "            print()\n",
    "\n",
    "        time_elapsed = time.time() - since  # Nice way to measure training time but info also stored (indirectly) by tensorboard\n",
    "        print(\n",
    "            f'Training complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')\n",
    "        print(f'Best val Acc: {best_acc:4f}')\n",
    "        #labels= labels.cpu().numpy()\n",
    "        #preds=preds.cpu().numpy()\n",
    "        model.load_state_dict(torch.load(best_model_params_path))\n",
    "    writer.close()\n",
    "    return model, con_mat   # We want to return the model because its the model, also confusion matrix for later analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is your RESNET\n",
    "# Initialize CNN with kaiming\n",
    "def init_cnn(m):\n",
    "    # Set the weights of the RESNET\n",
    "    if getattr(m, 'bias', None) is not None: nn.init.constant_(m.bias, 0)\n",
    "    if isinstance(m, (nn.Conv2d,nn.Linear)): nn.init.kaiming_normal_(m.weight)\n",
    "    for l in m.children(): init_cnn(l)\n",
    "\n",
    "\n",
    "# noop function for returning nothing\n",
    "def noop(x): return x\n",
    "# activation function(RELU)\n",
    "act_fn = nn.ReLU(inplace=True)\n",
    "\n",
    "# Flatten\n",
    "class Flatten(nn.Module):\n",
    "    def forward(self, x): return x.view(x.size(0), -1)\n",
    "\n",
    "# Make a convolution\n",
    "def conv(ni, nf, ks=3, stride=1, bias=False):\n",
    "    return nn.Conv2d(ni, nf, kernel_size=ks, stride=stride, padding=ks//2, bias=bias)\n",
    "\n",
    "# Create a convuolutional layer with convolution and batch norm\n",
    "def conv_layer(ni, nf, ks=3, stride=1, zero_bn=False, act=True):\n",
    "    bn = nn.BatchNorm2d(nf) # get a 2d batch norm from Pytorhc\n",
    "    nn.init.constant_(bn.weight, 0. if zero_bn else 1.)\n",
    "    layers = [conv(ni, nf, ks, stride=stride), bn]\n",
    "    if act: layers.append(act_fn) # add in the activation function if act is true\n",
    "    return nn.Sequential(*layers)\n",
    "\n",
    "\n",
    "# Resblock\n",
    "class ResBlock(nn.Module):\n",
    "    def __init__(self, expansion, ni, nh, stride = 1):\n",
    "        super().__init__()\n",
    "        # ni - number of inputs channels, nf - number of filters\n",
    "        # nh - number of filters in first conv\n",
    "        # expansion is 1 for resnet 18, 34 and 4 for larger networks\n",
    "        nf, ni = nh*expansion, ni*expansion\n",
    "        layers = [conv_layer(ni, nh, 3, stride = stride), # for resnet < 34 2 convs per resblock\n",
    "                 conv_layer(nh, nf, 3, zero_bn = True, act = False)\n",
    "                 ] if expansion == 1 else [ # for RESNET > 34 then 3 convs per block with bottleneck\n",
    "                            conv_layer(ni, nh, 1),\n",
    "                            conv_layer(nh, nh, 3, stride = stride),\n",
    "                            conv_layer(nh, nf, 1, zero_bn = True, act = False)\n",
    "        ]\n",
    "        self.convs = nn.Sequential(*layers) # Creates the conv layers\n",
    "        self.idconv = noop if ni==nf else conv_layer(ni, nf, 1, act = False) # id convolution ()\n",
    "        self.pool = noop if stride== 1 else nn.AvgPool2d(2, ceil_mode = True) # average pool on \n",
    "        \n",
    "    def forward(self, x): \n",
    "        # Forward function adds the convolution part to the id part \n",
    "        #return act_fn(self.convs(x)) + self.idconv(self.pool(x))\n",
    "        return act_fn(self.convs(x) + self.idconv(self.pool(x)))\n",
    "\n",
    "# XResnet\n",
    "class XResNet(nn.Sequential):\n",
    "    @classmethod\n",
    "    def create(cls, expansion, layers, c_in=3, c_out=1000):\n",
    "        nfs = [c_in, (c_in + 1)*8, 64, 64] # number of filters in stem layer (c_in is number of image channels)\n",
    "        stem = [conv_layer(nfs[i], nfs[i+1], stride=2 if i==0 else 1)\n",
    "            for i in range(3)]\n",
    "\n",
    "        nfs = [64//expansion,64,128,256,512]\n",
    "        res_layers = [cls._make_layer(expansion, nfs[i], nfs[i+1],\n",
    "                                      n_blocks=l, stride=1 if i==0 else 2)\n",
    "                  for i,l in enumerate(layers)]\n",
    "        res = cls(\n",
    "        *stem,\n",
    "        nn.MaxPool2d(kernel_size=3, stride = 2, padding = 1), # then a max pooling layer\n",
    "        *res_layers,\n",
    "        nn.AdaptiveAvgPool2d(1), Flatten(), \n",
    "        nn.Linear(nfs[-1]*expansion, c_out)\n",
    "        )\n",
    "        init_cnn(res)\n",
    "        return res\n",
    "        \n",
    "    @staticmethod\n",
    "    def _make_layer(expansion, ni, nf, n_blocks, stride): # returns a resblock\n",
    "        return nn.Sequential(\n",
    "        *[ResBlock(expansion, ni if i==0 else nf, nf, stride if i==0 else 1)\n",
    "         for i in range(n_blocks)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def xresnet18 (**kwargs): return XResNet.create(1, [2, 2,  2, 2], **kwargs)\n",
    "def xresnet34 (**kwargs): return XResNet.create(1, [3, 4,  6, 3], **kwargs)\n",
    "def xresnet50 (**kwargs): return XResNet.create(4, [3, 4,  6, 3], **kwargs)\n",
    "model = xresnet18(c_in = 1, c_out = 2)\n",
    "#model34 = xresnet34(c_in = 1, c_out = 2)\n",
    "#model50 = xresnet50(c_in = 1, c_out = 2)\n",
    "model.load_state_dict(torch.load(\"/workspace/myFile/Output/17052023/200againbest_model_params.pt\"))\n",
    "model = model.to(device)\n",
    "\n",
    "# Label smoothing cross entropy\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "def reduce_loss(loss, reduction='mean'):\n",
    "    return loss.mean() if reduction=='mean' else loss.sum() if reduction=='sum' else loss\n",
    "\n",
    "class LabelSmoothingCrossEntropy(nn.Module):\n",
    "    def __init__(self, ε:float=0.1, reduction='mean'):\n",
    "        super().__init__()\n",
    "        self.ε,self.reduction = ε,reduction\n",
    "    \n",
    "    def forward(self, output, target):\n",
    "        c = output.size()[-1]\n",
    "        log_preds = F.log_softmax(output, dim=-1)\n",
    "        loss = reduce_loss(-log_preds.sum(dim=-1), self.reduction)\n",
    "        nll = F.nll_loss(log_preds, target, reduction=self.reduction)\n",
    "        return lin_comb(loss/c, nll, self.ε)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions that shows the image, true class, predicted class and degree of prediction\n",
    "\n",
    "def images_to_probs(net, images):\n",
    "    '''\n",
    "    Generates predictions and corresponding probabilities from a trained\n",
    "    network and a list of images\n",
    "    '''\n",
    "    output = net(images)\n",
    "    # convert output probabilities to predicted class\n",
    "    _, preds_tensor = torch.max(output, 1)\n",
    "    preds = np.squeeze(preds_tensor.numpy())\n",
    "    return preds, [F.softmax(el, dim=0)[i].item() for i, el in zip(preds, output)]\n",
    "\n",
    "\n",
    "def plot_classes_preds(net, images, labels):\n",
    "    '''\n",
    "    Generates matplotlib Figure using a trained network, along with images\n",
    "    and labels from a batch, that shows the network's top prediction along\n",
    "    with its probability, alongside the actual label, coloring this\n",
    "    information based on whether the prediction was correct or not.\n",
    "    Uses the \"images_to_probs\" function.\n",
    "    '''\n",
    "    preds, probs = images_to_probs(net, images)\n",
    "    # plot the images in the batch, along with predicted and true labels\n",
    "    fig = plt.figure(figsize=(12, 48))\n",
    "    for idx in np.arange(4):\n",
    "        ax = fig.add_subplot(1, 4, idx+1, xticks=[], yticks=[])\n",
    "        matplotlib_imshow(images[idx], one_channel=True)\n",
    "        ax.set_title(\"{0}, {1:.1f}%\\n(label: {2})\".format(\n",
    "            labels[preds[idx]],\n",
    "            probs[idx] * 100.0,\n",
    "            labels[labels[idx]]),\n",
    "                    color=(\"green\" if preds[idx]==labels[idx].item() else \"red\"))\n",
    "    return fig\n",
    "\n",
    "def matplotlib_imshow(img, one_channel=True):\n",
    "    if one_channel:\n",
    "        img = img.mean(dim=0)\n",
    "    img = img / 2 + 0.5     # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    if one_channel:\n",
    "        plt.imshow(npimg, cmap=\"Greys\")\n",
    "    else:\n",
    "        plt.imshow(np.transpose(npimg, (1, 2, 0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def confusion_matrix_calc(data_loader_test, classes, model_ft):       \n",
    "        y_pred = []\n",
    "        y_true = []\n",
    "        for inputs, labels, imNo in data_loader_test:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "                output = model_ft(inputs) # Feed Network\n",
    "\n",
    "                output = (torch.max(torch.exp(output), 1)[1]).data.cpu().numpy()\n",
    "                y_pred.extend(output) # Save Prediction\n",
    "                \n",
    "                labels = labels.data.cpu().numpy()\n",
    "                y_true.extend(labels) # Save Truth\n",
    "\n",
    "        # constant for classes\n",
    "        # classes = ('Alive', 'Dead')\n",
    "\n",
    "        # Build confusion matrix\n",
    "        cf_matrix = confusion_matrix(y_true, y_pred)\n",
    "        return cf_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': 105347, 'val': 1}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k=5 #NUMBER OF K FOLDS\n",
    "epoch=5 #NUMBER OF EPOCHS\n",
    "\n",
    "torch.manual_seed(10)\n",
    "imIdx = torch.randperm(1).tolist()\n",
    "\n",
    "## Create dataset\n",
    "dataSetTrain = DNADataset(imDr, get_transform(train = True), labels, imDx=imIdx)\n",
    "dataSetTest = DNADataset(imDr, get_transform(train = False), labels, imDx=imIdx)\n",
    "\n",
    "data_loader_train=[]\n",
    "data_loader_test=[]\n",
    "\n",
    "# ## Create dataloaders\n",
    "# Get subset\n",
    "torch.manual_seed(10)\n",
    "indices = torch.randperm(len(dataSetTrain)).tolist()\n",
    "\n",
    "noTrain = int(len(dataSetTrain)*0.7)\n",
    "train=[]\n",
    "test=[]\n",
    "indices = torch.randperm(len(dataSetTrain)).tolist()\n",
    "TotalSet=list(range(len(dataSetTrain)))\n",
    "Kfifth = len(dataSetTrain)//k\n",
    "split= epoch%k\n",
    "train.append(TotalSet[(split+1)*Kfifth:]+TotalSet[:Kfifth*split])\n",
    "\n",
    "indices = torch.randperm(len(dataSetTest)).tolist()\n",
    "TotalSet=list(range(len(dataSetTrain)))\n",
    "test.append(TotalSet)\n",
    "\n",
    "#dataset_train = torch.utils.data.Subset(dataSetTrain, indices[-noTrain:])\n",
    "\n",
    "#dataset_test = torch.utils.data.Subset(dataSetTest, indices[:-noTrain])\n",
    "#len(indices), len(indices[:-50]), len(indices[-50:]), 50/191, type(dataset_test)\n",
    "\n",
    "dataset_sizes = {'train': len(train[0]), 'val': len(test)}\n",
    "dataset_sizes\n",
    "#dataset_train = torch.utils.data.Subset(dataSetTrain, train)\n",
    "#data_loader_train.append(dataset_train)\n",
    "#dataset_testo = torch.utils.data.Subset(dataSetTest, test)\n",
    "#data_loader_test.append(dataset_testo)\n",
    "# define training and validation data loaders\n",
    "\n",
    "\n",
    "# Collate function (gathers together the outputs)\n",
    "# def collate_fn(batch):\n",
    "#     return tuple(zip(*batch))\n",
    "\n",
    "#len(indices[-noTrain:]), dataset_sizes\n",
    "#dataset_test[0][1], dataset_test[3][1], dataset_test[-1][1], dataSetTrain.imgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_weights= [0.924865,0.075135] #1-(#inclass/ #intotal )\n",
    "class_weights = torch.Tensor(class_weights)\n",
    "class_weights=class_weights.to(device)\n",
    "criterion = nn.CrossEntropyLoss(weight = class_weights) \n",
    "\n",
    "# Observe that all parameters are being optimized\n",
    "optimizer_ft = optim.Adam(model.parameters(), weight_decay=1e-2) # standard ADAM optimiser\n",
    "\n",
    "# Decay LR by a factor of 0.1 every 7 epochs\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/0\n",
      "----------\n",
      "val Loss: 16354.8940 Acc: 0.9455\n",
      "proper accuracy=\n",
      "tensor(0.9174, device='cuda:0')\n",
      "damaged accuracy=\n",
      "tensor(0.9124, device='cuda:0')\n",
      "undamaged accuracy=\n",
      "tensor(0.9785, device='cuda:0')\n",
      "[[111125  10664]\n",
      " [   213   9681]]\n",
      "\n",
      "Training complete in 2m 21s\n",
      "Best val Acc: 0.945455\n"
     ]
    }
   ],
   "source": [
    "model_ft, con_mat = train_model(model, criterion, optimizer_ft, exp_lr_scheduler, \n",
    "                                    train,test,num_epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cf_matrix = confusion_matrix_calc(data_loader_test, labels, model_ft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x504 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "con_mat=con_mat.cpu().numpy()\n",
    "plotlabels=['Undamaged','Damaged']\n",
    "df_cm_ratio = pd.DataFrame(con_mat / np.sum(con_mat, axis=1)[:, None], index=[i for i in plotlabels],\n",
    "                     columns=[i for i in plotlabels])\n",
    "plt.figure(figsize=(12, 7))\n",
    "sn.heatmap(df_cm_ratio, annot=True)\n",
    "# plt.save(\"Confusion_matrix_ratio.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x504 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_cm_raw = pd.DataFrame(con_mat, index=[i for i in plotlabels],\n",
    "                     columns=[i for i in plotlabels])\n",
    "plt.figure(figsize=(12, 7))\n",
    "sn.heatmap(df_cm_raw, annot=True)\n",
    "# plt.save(\"Confusion_matrix_raw.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[111125,  10664],\n",
       "       [   213,   9681]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "con_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_loader_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotlabels=['Undamaged','Damaged']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
