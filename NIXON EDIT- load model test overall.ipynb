{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To note: Running this on different systems (i.e. local, SCW, server) will result in slight changes needing to the code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/scipy/__init__.py:138: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.4)\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion} is required for this version of \"\n"
     ]
    }
   ],
   "source": [
    "# Load libraries\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import sys\n",
    "import torchvision\n",
    "import torchvision.transforms as T\n",
    "import torchvision.models as models\n",
    "from PIL import Image\n",
    "from PIL import ImageEnhance\n",
    "import matplotlib.pyplot as plt\n",
    "import imagesize\n",
    "import subprocess\n",
    "sys.path\n",
    "from IPython.core.debugger import set_trace\n",
    "import scipy.ndimage\n",
    "import matplotlib.patches as patches\n",
    "# plt.rcParams['figure.figsize'] = [12,12]\n",
    "# sys.path.append('/workspace/myFile/Mask_RCNN_Tutorial/')\n",
    "from tqdm import tqdm\n",
    "from torch import nn as nn\n",
    "from torch import optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "import re\n",
    "import time\n",
    "import copy\n",
    "import pylab\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from tempfile import TemporaryDirectory\n",
    "import torch.backends.cudnn as cudnn\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "import seaborn as sn\n",
    "import pandas as pd\n",
    "import glob\n",
    "# Rather than have a messy notebook with a load of functions we can store them in separate .py files and import them\n",
    "\n",
    "cudnn.benchmark = True\n",
    "plt.ion()   # interactive mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "writer = SummaryWriter(\"Experiments/TENSORBOARD\")    # This determines the tensorboard file name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DNADataset(object):\n",
    "    def __init__(self, root, transforms, labels, imDx = False):\n",
    "        self.root, self.transforms, self.labels = root, transforms, labels\n",
    "        self.imgDir=[]\n",
    "        # load all image files, sorting them to ensure they are aligned\n",
    "        for drug in [\"A\",\"B\",\"C\",\"D\",\"E\",\"F\"]:\n",
    "            self.imgDir = self.imgDir+glob.glob(root+drug+\"10*/*.tiff\")\n",
    "            self.imgDir = self.imgDir +glob.glob(root+drug+\"11*/*.tiff\")\n",
    "            self.imgDir =self.imgDir+ glob.glob(root+drug+\"12*/*.tiff\")\n",
    "        Damagednuclei= [x for x in self.imgDir if 'Damaged_nuclei_' in x]\n",
    "        Undamagednuclei= [x for x in self.imgDir if \"No_damage_nuclei\" in x]\n",
    "        #np.random.shuffle(Undamagednuclei)\n",
    "        #Undamagednuclei=Undamagednuclei[:10000]\n",
    "        self.imgDir= Damagednuclei+Undamagednuclei\n",
    "        size80=[]\n",
    "        for x in self.imgDir:\n",
    "            img = Image.open(x) # Open image\n",
    "            w,h=img.size\n",
    "            if w<=80 and h<=80:\n",
    "                size80.append(x)\n",
    "        self.imgDir=size80              \n",
    "        \n",
    "        self.imgs = sorted(self.imgDir) # list of images\n",
    "\n",
    "        \n",
    "\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.imgs[idx]\n",
    "       \n",
    "        # Transform images into tensors\n",
    "        img = Image.open(img_path) # Open image\n",
    "        w,h=img.size\n",
    "        img = np.array(img) # Convert image into an array\n",
    "        img = np.float32(np.divide(img, 2**16)) # Ensure all values are floats\n",
    "        \n",
    "        result=np.zeros((80,80), dtype=np.float32)\n",
    "        x_center = (80 - w) // 2\n",
    "        y_center = (80 - h) // 2 # copy img image into center of result image\n",
    "        result[y_center:y_center+h, x_center:x_center+w] = img\n",
    "        img = result\n",
    "        \n",
    "        targetlab=\"\"\n",
    "        if img_path.find('No_damage_nuclei') != -1:\n",
    "            targetlab= 'Undamaged'\n",
    "        if img_path.find('Damaged_nuclei_') != -1:\n",
    "            targetlab= 'Damaged'  # Find labels corresponding to image\n",
    "        target = self.labels.index(targetlab) # Get the label and assign to a value\n",
    "        \n",
    "        # Convert label to tensor\n",
    "        #torch.to\n",
    "        \n",
    "        if self.transforms is not None:\n",
    "            img = self.transforms(img)\n",
    "#             #print('In the transforms')\n",
    "        imNo = idx\n",
    "        return img, target, imNo\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.imgs)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "imDr = \"/workspace/myFile/Output/17052023/\"  # Image patches directory\n",
    "\n",
    "labels = ['Damaged', 'Undamaged']  # Your labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For data augmentation\n",
    "def get_transform(train):\n",
    "    transforms = []\n",
    "\n",
    "    transforms.append(T.ToTensor())\n",
    "    #transforms.append(T.Normalize([0.0019368887995516483], [0.00672996630111016]))\n",
    "    #transforms.append(T.RandomHorizontalFlip(0.5))\n",
    "    \n",
    "    if train:\n",
    "        transforms.append(T.RandomHorizontalFlip(p=1))\n",
    "        transforms.append(T.RandomVerticalFlip(p=1))\n",
    "    \n",
    "    return T.Compose(transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, scheduler, train, test, num_epochs=25):\n",
    "    since = time.time()\n",
    "    # Create a temporary directory to save training checkpoints\n",
    "    with TemporaryDirectory() as tempdir:\n",
    "        best_model_params_path = os.path.join(tempdir, 'best_model_params.pt')\n",
    "\n",
    "        torch.save(model.state_dict(), best_model_params_path)\n",
    "        best_acc = 0.0\n",
    "        \n",
    "        for epoch in range(num_epochs):\n",
    "            print(f'Epoch {epoch}/{num_epochs - 1}')\n",
    "            print('-' * 10)\n",
    "            dataset_train = torch.utils.data.Subset(dataSetTrain, train[epoch])\n",
    "            dataset_test = torch.utils.data.Subset(dataSetTest, test[epoch])\n",
    "            data_loader_train = torch.utils.data.DataLoader(\n",
    "                dataset_train, batch_size=128, shuffle=True, num_workers=0)\n",
    "\n",
    "            data_loader_test = torch.utils.data.DataLoader(\n",
    "                dataset_test, batch_size=128, shuffle=False, num_workers=0)\n",
    "            # Each epoch has a training and validation phase\n",
    "            for phase in ['val']:\n",
    "                if phase == 'train':\n",
    "                    model.train()  # Set model to training mode\n",
    "                    dataloaders = data_loader_train\n",
    "                else:\n",
    "                    model.eval()   # Set model to evaluate mode\n",
    "                    dataloaders = data_loader_test\n",
    "\n",
    "                running_loss = 0.0\n",
    "                running_corrects = 0\n",
    "                damaged_len=0\n",
    "                damaged_corrects = 0\n",
    "                undamaged_len=0\n",
    "                undamaged_corrects = 0\n",
    "\n",
    "                # Iterate over data.\n",
    "                for inputs, labels, imNo in dataloaders:\n",
    "                    inputs = inputs.to(device)\n",
    "                    labels = labels.to(device)\n",
    "\n",
    "                    # zero the parameter gradients\n",
    "                    optimizer.zero_grad()\n",
    "\n",
    "                    # forward\n",
    "                    # track history if only in train\n",
    "                    with torch.set_grad_enabled(phase == 'train'):\n",
    "                        outputs = model(inputs)\n",
    "                        _, preds = torch.max(outputs, 1)\n",
    "                        loss = criterion(outputs, labels)\n",
    "                        # backward + optimize only if in training phase\n",
    "                        if phase == 'train':\n",
    "                            loss.backward()\n",
    "                            optimizer.step()\n",
    "\n",
    "                    # statistics\n",
    "                    running_loss += loss.item() * inputs.size(0)    # Loss\n",
    "                    nada=torch.tensor(np.zeros(len(labels))).to(device)\n",
    "                    uno=nada+1\n",
    "                    falseneg=preds+1\n",
    "                    falsepos=preds-1\n",
    "                    FPplusTN=torch.sum(labels==nada)\n",
    "                    TPplusFN=torch.sum(labels==uno)\n",
    "                    FN=torch.sum(labels==falseneg)\n",
    "                    FP=torch.sum(labels==falsepos)\n",
    "                    TN=FPplusTN-FP\n",
    "                    TP=TPplusFN-FN\n",
    "                    running_corrects += torch.sum(preds == labels.data) # Accuracy\n",
    "                    damaged_len+=TPplusFN\n",
    "                    damaged_corrects += TP\n",
    "                    undamaged_len+=FPplusTN\n",
    "                    undamaged_corrects += TN\n",
    "                damaged_acc = damaged_corrects / damaged_len\n",
    "                undamaged_acc = undamaged_corrects/undamaged_len\n",
    "                epoch_acc= (damaged_acc+undamaged_acc)/2\n",
    "                proper_acc=(damaged_corrects+undamaged_corrects)/(damaged_len+undamaged_len)\n",
    "                if phase == 'train':\n",
    "                    scheduler.step()\n",
    "\n",
    "                epoch_loss = running_loss / dataset_sizes[phase]    # Loss metric per epoch\n",
    "                #epoch_acc = running_corrects.double() / dataset_sizes[phase]    # Accuracy metric per epoch\n",
    "\n",
    "                if phase == \"train\":    # This is the tensorboard code that writes accuracy and loss metrics\n",
    "                    writer.add_scalar(\"Train/Accuracy\", epoch_acc, epoch)\n",
    "                    writer.add_scalar(\"Train/Loss\", epoch_loss, epoch)\n",
    "                else:\n",
    "                    writer.add_scalar(\"Validation/Accuracy\", epoch_acc, epoch)\n",
    "                    writer.add_scalar(\"Validation/Loss\", epoch_loss, epoch)\n",
    "\n",
    "                print(f'{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n",
    "                print(\"proper accuracy=\")\n",
    "                print(proper_acc)\n",
    "                print(\"damaged accuracy=\")\n",
    "                print(damaged_acc)\n",
    "                print(\"undamaged accuracy=\")\n",
    "                print(undamaged_acc)\n",
    "                con_matter= torch.tensor([[damaged_corrects, damaged_len-damaged_corrects],[undamaged_len-undamaged_corrects,undamaged_corrects]])\n",
    "                con_matter=con_matter.cpu().numpy()\n",
    "                print(con_matter)\n",
    "                # deep copy the model\n",
    "                if phase == 'val' and epoch_acc >= best_acc: \n",
    "                    # This compares validation accuracy to previous bests and adjusts model weights accordingly\n",
    "                    best_acc = epoch_acc\n",
    "                    torch.save(model.state_dict(), best_model_params_path)\n",
    "                    con_mat= torch.tensor([[damaged_corrects, damaged_len-damaged_corrects],[undamaged_len-undamaged_corrects,undamaged_corrects]])\n",
    "\n",
    "            print()\n",
    "\n",
    "        time_elapsed = time.time() - since  # Nice way to measure training time but info also stored (indirectly) by tensorboard\n",
    "        print(\n",
    "            f'Training complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')\n",
    "        print(f'Best val Acc: {best_acc:4f}')\n",
    "        #labels= labels.cpu().numpy()\n",
    "        #preds=preds.cpu().numpy()\n",
    "        model.load_state_dict(torch.load(best_model_params_path))\n",
    "    writer.close()\n",
    "    return model, con_mat   # We want to return the model because its the model, also confusion matrix for later analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is your RESNET\n",
    "# Initialize CNN with kaiming\n",
    "def init_cnn(m):\n",
    "    # Set the weights of the RESNET\n",
    "    if getattr(m, 'bias', None) is not None: nn.init.constant_(m.bias, 0)\n",
    "    if isinstance(m, (nn.Conv2d,nn.Linear)): nn.init.kaiming_normal_(m.weight)\n",
    "    for l in m.children(): init_cnn(l)\n",
    "\n",
    "\n",
    "# noop function for returning nothing\n",
    "def noop(x): return x\n",
    "# activation function(RELU)\n",
    "act_fn = nn.ReLU(inplace=True)\n",
    "\n",
    "# Flatten\n",
    "class Flatten(nn.Module):\n",
    "    def forward(self, x): return x.view(x.size(0), -1)\n",
    "\n",
    "# Make a convolution\n",
    "def conv(ni, nf, ks=3, stride=1, bias=False):\n",
    "    return nn.Conv2d(ni, nf, kernel_size=ks, stride=stride, padding=ks//2, bias=bias)\n",
    "\n",
    "# Create a convuolutional layer with convolution and batch norm\n",
    "def conv_layer(ni, nf, ks=3, stride=1, zero_bn=False, act=True):\n",
    "    bn = nn.BatchNorm2d(nf) # get a 2d batch norm from Pytorhc\n",
    "    nn.init.constant_(bn.weight, 0. if zero_bn else 1.)\n",
    "    layers = [conv(ni, nf, ks, stride=stride), bn]\n",
    "    if act: layers.append(act_fn) # add in the activation function if act is true\n",
    "    return nn.Sequential(*layers)\n",
    "\n",
    "\n",
    "# Resblock\n",
    "class ResBlock(nn.Module):\n",
    "    def __init__(self, expansion, ni, nh, stride = 1):\n",
    "        super().__init__()\n",
    "        # ni - number of inputs channels, nf - number of filters\n",
    "        # nh - number of filters in first conv\n",
    "        # expansion is 1 for resnet 18, 34 and 4 for larger networks\n",
    "        nf, ni = nh*expansion, ni*expansion\n",
    "        layers = [conv_layer(ni, nh, 3, stride = stride), # for resnet < 34 2 convs per resblock\n",
    "                 conv_layer(nh, nf, 3, zero_bn = True, act = False)\n",
    "                 ] if expansion == 1 else [ # for RESNET > 34 then 3 convs per block with bottleneck\n",
    "                            conv_layer(ni, nh, 1),\n",
    "                            conv_layer(nh, nh, 3, stride = stride),\n",
    "                            conv_layer(nh, nf, 1, zero_bn = True, act = False)\n",
    "        ]\n",
    "        self.convs = nn.Sequential(*layers) # Creates the conv layers\n",
    "        self.idconv = noop if ni==nf else conv_layer(ni, nf, 1, act = False) # id convolution ()\n",
    "        self.pool = noop if stride== 1 else nn.AvgPool2d(2, ceil_mode = True) # average pool on \n",
    "        \n",
    "    def forward(self, x): \n",
    "        # Forward function adds the convolution part to the id part \n",
    "        #return act_fn(self.convs(x)) + self.idconv(self.pool(x))\n",
    "        return act_fn(self.convs(x) + self.idconv(self.pool(x)))\n",
    "\n",
    "# XResnet\n",
    "class XResNet(nn.Sequential):\n",
    "    @classmethod\n",
    "    def create(cls, expansion, layers, c_in=3, c_out=1000):\n",
    "        nfs = [c_in, (c_in + 1)*8, 64, 64] # number of filters in stem layer (c_in is number of image channels)\n",
    "        stem = [conv_layer(nfs[i], nfs[i+1], stride=2 if i==0 else 1)\n",
    "            for i in range(3)]\n",
    "\n",
    "        nfs = [64//expansion,64,128,256,512]\n",
    "        res_layers = [cls._make_layer(expansion, nfs[i], nfs[i+1],\n",
    "                                      n_blocks=l, stride=1 if i==0 else 2)\n",
    "                  for i,l in enumerate(layers)]\n",
    "        res = cls(\n",
    "        *stem,\n",
    "        nn.MaxPool2d(kernel_size=3, stride = 2, padding = 1), # then a max pooling layer\n",
    "        *res_layers,\n",
    "        nn.AdaptiveAvgPool2d(1), Flatten(), \n",
    "        nn.Linear(nfs[-1]*expansion, c_out)\n",
    "        )\n",
    "        init_cnn(res)\n",
    "        return res\n",
    "        \n",
    "    @staticmethod\n",
    "    def _make_layer(expansion, ni, nf, n_blocks, stride): # returns a resblock\n",
    "        return nn.Sequential(\n",
    "        *[ResBlock(expansion, ni if i==0 else nf, nf, stride if i==0 else 1)\n",
    "         for i in range(n_blocks)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def xresnet18 (**kwargs): return XResNet.create(1, [2, 2,  2, 2], **kwargs)\n",
    "def xresnet34 (**kwargs): return XResNet.create(1, [3, 4,  6, 3], **kwargs)\n",
    "def xresnet50 (**kwargs): return XResNet.create(4, [3, 4,  6, 3], **kwargs)\n",
    "model = xresnet18(c_in = 1, c_out = 2)\n",
    "#model34 = xresnet34(c_in = 1, c_out = 2)\n",
    "#model50 = xresnet50(c_in = 1, c_out = 2)\n",
    "model.load_state_dict(torch.load(\"/workspace/myFile/Output/17052023/best_model_params.pt\"))\n",
    "model = model.to(device)\n",
    "\n",
    "# Label smoothing cross entropy\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "def reduce_loss(loss, reduction='mean'):\n",
    "    return loss.mean() if reduction=='mean' else loss.sum() if reduction=='sum' else loss\n",
    "\n",
    "class LabelSmoothingCrossEntropy(nn.Module):\n",
    "    def __init__(self, ε:float=0.1, reduction='mean'):\n",
    "        super().__init__()\n",
    "        self.ε,self.reduction = ε,reduction\n",
    "    \n",
    "    def forward(self, output, target):\n",
    "        c = output.size()[-1]\n",
    "        log_preds = F.log_softmax(output, dim=-1)\n",
    "        loss = reduce_loss(-log_preds.sum(dim=-1), self.reduction)\n",
    "        nll = F.nll_loss(log_preds, target, reduction=self.reduction)\n",
    "        return lin_comb(loss/c, nll, self.ε)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions that shows the image, true class, predicted class and degree of prediction\n",
    "\n",
    "def images_to_probs(net, images):\n",
    "    '''\n",
    "    Generates predictions and corresponding probabilities from a trained\n",
    "    network and a list of images\n",
    "    '''\n",
    "    output = net(images)\n",
    "    # convert output probabilities to predicted class\n",
    "    _, preds_tensor = torch.max(output, 1)\n",
    "    preds = np.squeeze(preds_tensor.numpy())\n",
    "    return preds, [F.softmax(el, dim=0)[i].item() for i, el in zip(preds, output)]\n",
    "\n",
    "\n",
    "def plot_classes_preds(net, images, labels):\n",
    "    '''\n",
    "    Generates matplotlib Figure using a trained network, along with images\n",
    "    and labels from a batch, that shows the network's top prediction along\n",
    "    with its probability, alongside the actual label, coloring this\n",
    "    information based on whether the prediction was correct or not.\n",
    "    Uses the \"images_to_probs\" function.\n",
    "    '''\n",
    "    preds, probs = images_to_probs(net, images)\n",
    "    # plot the images in the batch, along with predicted and true labels\n",
    "    fig = plt.figure(figsize=(12, 48))\n",
    "    for idx in np.arange(4):\n",
    "        ax = fig.add_subplot(1, 4, idx+1, xticks=[], yticks=[])\n",
    "        matplotlib_imshow(images[idx], one_channel=True)\n",
    "        ax.set_title(\"{0}, {1:.1f}%\\n(label: {2})\".format(\n",
    "            labels[preds[idx]],\n",
    "            probs[idx] * 100.0,\n",
    "            labels[labels[idx]]),\n",
    "                    color=(\"green\" if preds[idx]==labels[idx].item() else \"red\"))\n",
    "    return fig\n",
    "\n",
    "def matplotlib_imshow(img, one_channel=True):\n",
    "    if one_channel:\n",
    "        img = img.mean(dim=0)\n",
    "    img = img / 2 + 0.5     # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    if one_channel:\n",
    "        plt.imshow(npimg, cmap=\"Greys\")\n",
    "    else:\n",
    "        plt.imshow(np.transpose(npimg, (1, 2, 0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def confusion_matrix_calc(data_loader_test, classes, model_ft):       \n",
    "        y_pred = []\n",
    "        y_true = []\n",
    "        for inputs, labels, imNo in data_loader_test:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "                output = model_ft(inputs) # Feed Network\n",
    "\n",
    "                output = (torch.max(torch.exp(output), 1)[1]).data.cpu().numpy()\n",
    "                y_pred.extend(output) # Save Prediction\n",
    "                \n",
    "                labels = labels.data.cpu().numpy()\n",
    "                y_true.extend(labels) # Save Truth\n",
    "\n",
    "        # constant for classes\n",
    "        # classes = ('Alive', 'Dead')\n",
    "\n",
    "        # Build confusion matrix\n",
    "        cf_matrix = confusion_matrix(y_true, y_pred)\n",
    "        return cf_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "k=5 #NUMBER OF K FOLDS\n",
    "epoch=5 #NUMBER OF EPOCHS\n",
    "\n",
    "torch.manual_seed(10)\n",
    "imIdx = torch.randperm(1).tolist()\n",
    "\n",
    "## Create dataset\n",
    "dataSetTrain = DNADataset(imDr, get_transform(train = True), labels, imDx=imIdx)\n",
    "dataSetTest = DNADataset(imDr, get_transform(train = False), labels, imDx=imIdx)\n",
    "\n",
    "data_loader_train=[]\n",
    "data_loader_test=[]\n",
    "\n",
    "# ## Create dataloaders\n",
    "# Get subset\n",
    "torch.manual_seed(10)\n",
    "indices = torch.randperm(len(dataSetTrain)).tolist()\n",
    "\n",
    "noTrain = int(len(dataSetTrain)*0.7)\n",
    "train=[]\n",
    "test=[]\n",
    "indices = torch.randperm(len(dataSetTrain)).tolist()\n",
    "TotalSet=list(range(len(dataSetTrain)))\n",
    "Kfifth = len(dataSetTrain)//k\n",
    "split= epoch%k\n",
    "train.append(TotalSet[(split+1)*Kfifth:]+TotalSet[:Kfifth*split])\n",
    "\n",
    "indices = torch.randperm(len(dataSetTest)).tolist()\n",
    "TotalSet=list(range(len(dataSetTrain)))\n",
    "test.append(TotalSet)\n",
    "\n",
    "#dataset_train = torch.utils.data.Subset(dataSetTrain, indices[-noTrain:])\n",
    "\n",
    "#dataset_test = torch.utils.data.Subset(dataSetTest, indices[:-noTrain])\n",
    "#len(indices), len(indices[:-50]), len(indices[-50:]), 50/191, type(dataset_test)\n",
    "\n",
    "dataset_sizes = {'train': len(train[0]), 'val': len(test)}\n",
    "\n",
    "#dataset_train = torch.utils.data.Subset(dataSetTrain, train)\n",
    "#data_loader_train.append(dataset_train)\n",
    "#dataset_testo = torch.utils.data.Subset(dataSetTest, test)\n",
    "#data_loader_test.append(dataset_testo)\n",
    "# define training and validation data loaders\n",
    "\n",
    "\n",
    "# Collate function (gathers together the outputs)\n",
    "# def collate_fn(batch):\n",
    "#     return tuple(zip(*batch))\n",
    "\n",
    "#len(indices[-noTrain:]), dataset_sizes\n",
    "#dataset_test[0][1], dataset_test[3][1], dataset_test[-1][1], dataSetTrain.imgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_weights= [0.924865,0.075135] #1-(#inclass/ #intotal )\n",
    "class_weights = torch.Tensor(class_weights)\n",
    "class_weights=class_weights.to(device)\n",
    "criterion = nn.CrossEntropyLoss(weight = class_weights) \n",
    "\n",
    "# Observe that all parameters are being optimized\n",
    "optimizer_ft = optim.Adam(model.parameters(), weight_decay=1e-2) # standard ADAM optimiser\n",
    "\n",
    "# Decay LR by a factor of 0.1 every 7 epochs\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/0\n",
      "----------\n",
      "val Loss: 12553.0280 Acc: 0.9235\n",
      "proper accuracy=\n",
      "tensor(0.8922, device='cuda:0')\n",
      "damaged accuracy=\n",
      "tensor(0.8858, device='cuda:0')\n",
      "undamaged accuracy=\n",
      "tensor(0.9612, device='cuda:0')\n",
      "[[57200  7375]\n",
      " [  233  5777]]\n",
      "\n",
      "Training complete in 1m 50s\n",
      "Best val Acc: 0.923512\n"
     ]
    }
   ],
   "source": [
    "model_ft, con_mat = train_model(model, criterion, optimizer_ft, exp_lr_scheduler, \n",
    "                                    train,test,num_epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cf_matrix = confusion_matrix_calc(data_loader_test, labels, model_ft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x504 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "con_mat=con_mat.cpu().numpy()\n",
    "plotlabels=['Undamaged','Damaged']\n",
    "df_cm_ratio = pd.DataFrame(con_mat / np.sum(con_mat, axis=1)[:, None], index=[i for i in plotlabels],\n",
    "                     columns=[i for i in plotlabels])\n",
    "plt.figure(figsize=(12, 7))\n",
    "sn.heatmap(df_cm_ratio, annot=True)\n",
    "# plt.save(\"Confusion_matrix_ratio.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x504 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_cm_raw = pd.DataFrame(con_mat, index=[i for i in plotlabels],\n",
    "                     columns=[i for i in plotlabels])\n",
    "plt.figure(figsize=(12, 7))\n",
    "sn.heatmap(df_cm_raw, annot=True)\n",
    "# plt.save(\"Confusion_matrix_raw.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[57200,  7375],\n",
       "       [  233,  5777]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "con_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_loader_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotlabels=['Undamaged','Damaged']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
