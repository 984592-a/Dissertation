{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To note: Running this on different systems (i.e. local, SCW, server) will result in slight changes needing to the code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/scipy/__init__.py:138: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.4)\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion} is required for this version of \"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.pyplot._IonContext at 0x7fd9a3ac3ac0>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load libraries\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import sys\n",
    "import torchvision\n",
    "import torchvision.transforms as T\n",
    "import torchvision.models as models\n",
    "from PIL import Image\n",
    "from PIL import ImageEnhance\n",
    "import matplotlib.pyplot as plt\n",
    "import imagesize\n",
    "import subprocess\n",
    "sys.path\n",
    "from IPython.core.debugger import set_trace\n",
    "import scipy.ndimage\n",
    "import matplotlib.patches as patches\n",
    "# plt.rcParams['figure.figsize'] = [12,12]\n",
    "# sys.path.append('/workspace/myFile/Mask_RCNN_Tutorial/')\n",
    "from tqdm import tqdm\n",
    "from torch import nn as nn\n",
    "from torch import optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "import re\n",
    "import time\n",
    "import copy\n",
    "import pylab\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from tempfile import TemporaryDirectory\n",
    "import torch.backends.cudnn as cudnn\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "import seaborn as sn\n",
    "import pandas as pd\n",
    "import glob\n",
    "# Rather than have a messy notebook with a load of functions we can store them in separate .py files and import them\n",
    "\n",
    "cudnn.benchmark = True\n",
    "plt.ion()   # interactive mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "writer = SummaryWriter(\"Experiments/TENSORBOARD\")    # This determines the tensorboard file name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DNADataset(object):\n",
    "    def __init__(self, root, transforms, labels, imDx = False):\n",
    "        self.root, self.transforms, self.labels = root, transforms, labels\n",
    "    \n",
    "        # load all image files, sorting them to ensure they are aligned\n",
    "        self.imgDir = glob.glob(root+\"*/*.tiff\")\n",
    "        Damagednuclei= [x for x in self.imgDir if 'Damaged_nuclei_' in x]\n",
    "        Undamagednuclei= [x for x in self.imgDir if \"No_damage_nuclei\" in x]\n",
    "        #np.random.shuffle(Undamagednuclei)\n",
    "        #Undamagednuclei=Undamagednuclei[:10000]\n",
    "        self.imgDir= Damagednuclei+Undamagednuclei\n",
    "        size80=[]\n",
    "        for x in self.imgDir:\n",
    "            img = Image.open(x) # Open image\n",
    "            w,h=img.size\n",
    "            if w<=80 and h<=80:\n",
    "                size80.append(x)\n",
    "        self.imgDir=size80              \n",
    "        \n",
    "        self.imgs = sorted(self.imgDir) # list of images\n",
    "\n",
    "        \n",
    "\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.imgs[idx]\n",
    "       \n",
    "        # Transform images into tensors\n",
    "        img = Image.open(img_path) # Open image\n",
    "        w,h=img.size\n",
    "        img = np.array(img) # Convert image into an array\n",
    "        img = np.float32(np.divide(img, 2**16)) # Ensure all values are floats\n",
    "        \n",
    "        result=np.zeros((80,80), dtype=np.float32)\n",
    "        x_center = (80 - w) // 2\n",
    "        y_center = (80 - h) // 2 # copy img image into center of result image\n",
    "        result[y_center:y_center+h, x_center:x_center+w] = img\n",
    "        img = result\n",
    "        \n",
    "        targetlab=\"\"\n",
    "        if img_path.find('No_damage_nuclei') != -1:\n",
    "            targetlab= 'Undamaged'\n",
    "        if img_path.find('Damaged_nuclei_') != -1:\n",
    "            targetlab= 'Damaged'  # Find labels corresponding to image\n",
    "        target = self.labels.index(targetlab) # Get the label and assign to a value\n",
    "        \n",
    "        # Convert label to tensor\n",
    "        #torch.to\n",
    "        \n",
    "        if self.transforms is not None:\n",
    "            img = self.transforms(img)\n",
    "#             #print('In the transforms')\n",
    "        imNo = idx\n",
    "        return img, target, imNo\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.imgs)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "root=\"/workspace/myFile/Output/17052023/\"\n",
    "p= glob.glob(root+\"*/*.tiff\")\n",
    "Damagednuclei= [x for x in p if 'Damaged_nuclei_' in x]\n",
    "Undamagednuclei= [x for x in p if \"No_damage_nuclei\" in x]\n",
    "#np.random.shuffle(Undamagednuclei)\n",
    "#Undamagednuclei=Undamagednuclei[:10000]\n",
    "#Undamagednuclei"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "imDr = \"/workspace/myFile/Output/17052023/\"  # Image patches directory\n",
    "\n",
    "labels = ['Damaged', 'Undamaged']  # Your labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For data augmentation\n",
    "def get_transform(train):\n",
    "    transforms = []\n",
    "\n",
    "    transforms.append(T.ToTensor())\n",
    "    #transforms.append(T.Normalize([0.0019368887995516483], [0.00672996630111016]))\n",
    "    #transforms.append(T.RandomHorizontalFlip(0.5))\n",
    "    \n",
    "    if train:\n",
    "        transforms.append(T.RandomHorizontalFlip(p=1))\n",
    "        transforms.append(T.RandomVerticalFlip(p=1))\n",
    "    \n",
    "    return T.Compose(transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, scheduler, dataloaderTrain, dataloaderTest, num_epochs=25):\n",
    "    since = time.time()\n",
    "    # Create a temporary directory to save training checkpoints\n",
    "    with TemporaryDirectory() as tempdir:\n",
    "        best_model_params_path = os.path.join(tempdir, 'best_model_params.pt')\n",
    "\n",
    "        torch.save(model.state_dict(), best_model_params_path)\n",
    "        best_acc = 0.0\n",
    "        \n",
    "        for epoch in range(num_epochs):\n",
    "            print(f'Epoch {epoch}/{num_epochs - 1}')\n",
    "            print('-' * 10)\n",
    "\n",
    "            # Each epoch has a training and validation phase\n",
    "            for phase in ['train', 'val']:\n",
    "                if phase == 'train':\n",
    "                    model.train()  # Set model to training mode\n",
    "                    dataloaders = dataloaderTrain\n",
    "                else:\n",
    "                    model.eval()   # Set model to evaluate mode\n",
    "                    dataloaders = dataloaderTest\n",
    "\n",
    "                running_loss = 0.0\n",
    "                running_corrects = 0\n",
    "                damaged_len=0\n",
    "                damaged_corrects = 0\n",
    "                undamaged_len=0\n",
    "                undamaged_corrects = 0\n",
    "\n",
    "                # Iterate over data.\n",
    "                for inputs, labels, imNo in dataloaders:\n",
    "                    inputs = inputs.to(device)\n",
    "                    labels = labels.to(device)\n",
    "\n",
    "                    # zero the parameter gradients\n",
    "                    optimizer.zero_grad()\n",
    "\n",
    "                    # forward\n",
    "                    # track history if only in train\n",
    "                    with torch.set_grad_enabled(phase == 'train'):\n",
    "                        outputs = model(inputs)\n",
    "                        _, preds = torch.max(outputs, 1)\n",
    "                        loss = criterion(outputs, labels)\n",
    "                        # backward + optimize only if in training phase\n",
    "                        if phase == 'train':\n",
    "                            loss.backward()\n",
    "                            optimizer.step()\n",
    "\n",
    "                    # statistics\n",
    "                    running_loss += loss.item() * inputs.size(0)    # Loss\n",
    "                    nada=torch.tensor(np.zeros(len(labels))).to(device)\n",
    "                    uno=nada+1\n",
    "                    falseneg=preds+1\n",
    "                    falsepos=preds-1\n",
    "                    FPplusTN=torch.sum(labels==nada)\n",
    "                    TPplusFN=torch.sum(labels==uno)\n",
    "                    FN=torch.sum(labels==falseneg)\n",
    "                    FP=torch.sum(labels==falsepos)\n",
    "                    TN=FPplusTN-FP\n",
    "                    TP=TPplusFN-FN\n",
    "                    running_corrects += torch.sum(preds == labels.data) # Accuracy\n",
    "                    damaged_len+=TPplusFN\n",
    "                    damaged_corrects += TP\n",
    "                    undamaged_len+=FPplusTN\n",
    "                    undamaged_corrects += TN\n",
    "                damaged_acc = damaged_corrects / damaged_len\n",
    "                undamaged_acc = undamaged_corrects/undamaged_len\n",
    "                epoch_acc= (damaged_acc+undamaged_acc)/2\n",
    "                \n",
    "                if phase == 'train':\n",
    "                    scheduler.step()\n",
    "\n",
    "                epoch_loss = running_loss / dataset_sizes[phase]    # Loss metric per epoch\n",
    "                #epoch_acc = running_corrects.double() / dataset_sizes[phase]    # Accuracy metric per epoch\n",
    "\n",
    "                if phase == \"train\":    # This is the tensorboard code that writes accuracy and loss metrics\n",
    "                    writer.add_scalar(\"Train/Accuracy\", epoch_acc, epoch)\n",
    "                    writer.add_scalar(\"Train/Loss\", epoch_loss, epoch)\n",
    "                else:\n",
    "                    writer.add_scalar(\"Validation/Accuracy\", epoch_acc, epoch)\n",
    "                    writer.add_scalar(\"Validation/Loss\", epoch_loss, epoch)\n",
    "\n",
    "                print(f'{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n",
    "\n",
    "                # deep copy the model\n",
    "                if phase == 'val' and epoch_acc >= best_acc: \n",
    "                    # This compares validation accuracy to previous bests and adjusts model weights accordingly\n",
    "                    best_acc = epoch_acc\n",
    "                    torch.save(model.state_dict(), best_model_params_path)\n",
    "\n",
    "            print()\n",
    "\n",
    "        time_elapsed = time.time() - since  # Nice way to measure training time but info also stored (indirectly) by tensorboard\n",
    "        print(\n",
    "            f'Training complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')\n",
    "        print(f'Best val Acc: {best_acc:4f}')\n",
    "        labels= labels.cpu().numpy()\n",
    "        preds=preds.cpu().numpy()\n",
    "        con_mat = confusion_matrix(labels, preds)   # Confusion matrix compares true class with predicted class\n",
    "        # load best model weights\n",
    "        model.load_state_dict(torch.load(best_model_params_path))\n",
    "    writer.close()\n",
    "    return model, con_mat   # We want to return the model because its the model, also confusion matrix for later analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is your RESNET\n",
    "# Initialize CNN with kaiming\n",
    "def init_cnn(m):\n",
    "    # Set the weights of the RESNET\n",
    "    if getattr(m, 'bias', None) is not None: nn.init.constant_(m.bias, 0)\n",
    "    if isinstance(m, (nn.Conv2d,nn.Linear)): nn.init.kaiming_normal_(m.weight)\n",
    "    for l in m.children(): init_cnn(l)\n",
    "\n",
    "\n",
    "# noop function for returning nothing\n",
    "def noop(x): return x\n",
    "# activation function(RELU)\n",
    "act_fn = nn.ReLU(inplace=True)\n",
    "\n",
    "# Flatten\n",
    "class Flatten(nn.Module):\n",
    "    def forward(self, x): return x.view(x.size(0), -1)\n",
    "\n",
    "# Make a convolution\n",
    "def conv(ni, nf, ks=3, stride=1, bias=False):\n",
    "    return nn.Conv2d(ni, nf, kernel_size=ks, stride=stride, padding=ks//2, bias=bias)\n",
    "\n",
    "# Create a convuolutional layer with convolution and batch norm\n",
    "def conv_layer(ni, nf, ks=3, stride=1, zero_bn=False, act=True):\n",
    "    bn = nn.BatchNorm2d(nf) # get a 2d batch norm from Pytorhc\n",
    "    nn.init.constant_(bn.weight, 0. if zero_bn else 1.)\n",
    "    layers = [conv(ni, nf, ks, stride=stride), bn]\n",
    "    if act: layers.append(act_fn) # add in the activation function if act is true\n",
    "    return nn.Sequential(*layers)\n",
    "\n",
    "\n",
    "# Resblock\n",
    "class ResBlock(nn.Module):\n",
    "    def __init__(self, expansion, ni, nh, stride = 1):\n",
    "        super().__init__()\n",
    "        # ni - number of inputs channels, nf - number of filters\n",
    "        # nh - number of filters in first conv\n",
    "        # expansion is 1 for resnet 18, 34 and 4 for larger networks\n",
    "        nf, ni = nh*expansion, ni*expansion\n",
    "        layers = [conv_layer(ni, nh, 3, stride = stride), # for resnet < 34 2 convs per resblock\n",
    "                 conv_layer(nh, nf, 3, zero_bn = True, act = False)\n",
    "                 ] if expansion == 1 else [ # for RESNET > 34 then 3 convs per block with bottleneck\n",
    "                            conv_layer(ni, nh, 1),\n",
    "                            conv_layer(nh, nh, 3, stride = stride),\n",
    "                            conv_layer(nh, nf, 1, zero_bn = True, act = False)\n",
    "        ]\n",
    "        self.convs = nn.Sequential(*layers) # Creates the conv layers\n",
    "        self.idconv = noop if ni==nf else conv_layer(ni, nf, 1, act = False) # id convolution ()\n",
    "        self.pool = noop if stride== 1 else nn.AvgPool2d(2, ceil_mode = True) # average pool on \n",
    "        \n",
    "    def forward(self, x): \n",
    "        # Forward function adds the convolution part to the id part \n",
    "        #return act_fn(self.convs(x)) + self.idconv(self.pool(x))\n",
    "        return act_fn(self.convs(x) + self.idconv(self.pool(x)))\n",
    "\n",
    "# XResnet\n",
    "class XResNet(nn.Sequential):\n",
    "    @classmethod\n",
    "    def create(cls, expansion, layers, c_in=3, c_out=1000):\n",
    "        nfs = [c_in, (c_in + 1)*8, 64, 64] # number of filters in stem layer (c_in is number of image channels)\n",
    "        stem = [conv_layer(nfs[i], nfs[i+1], stride=2 if i==0 else 1)\n",
    "            for i in range(3)]\n",
    "\n",
    "        nfs = [64//expansion,64,128,256,512]\n",
    "        res_layers = [cls._make_layer(expansion, nfs[i], nfs[i+1],\n",
    "                                      n_blocks=l, stride=1 if i==0 else 2)\n",
    "                  for i,l in enumerate(layers)]\n",
    "        res = cls(\n",
    "        *stem,\n",
    "        nn.MaxPool2d(kernel_size=3, stride = 2, padding = 1), # then a max pooling layer\n",
    "        *res_layers,\n",
    "        nn.AdaptiveAvgPool2d(1), Flatten(), \n",
    "        nn.Linear(nfs[-1]*expansion, c_out)\n",
    "        )\n",
    "        init_cnn(res)\n",
    "        return res\n",
    "        \n",
    "    @staticmethod\n",
    "    def _make_layer(expansion, ni, nf, n_blocks, stride): # returns a resblock\n",
    "        return nn.Sequential(\n",
    "        *[ResBlock(expansion, ni if i==0 else nf, nf, stride if i==0 else 1)\n",
    "         for i in range(n_blocks)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def xresnet18 (**kwargs): return XResNet.create(1, [2, 2,  2, 2], **kwargs)\n",
    "def xresnet34 (**kwargs): return XResNet.create(1, [3, 4,  6, 3], **kwargs)\n",
    "def xresnet50 (**kwargs): return XResNet.create(4, [3, 4,  6, 3], **kwargs)\n",
    "model18 = xresnet18(c_in = 1, c_out = 2)\n",
    "model34 = xresnet34(c_in = 1, c_out = 2)\n",
    "model50 = xresnet50(c_in = 1, c_out = 2)\n",
    "\n",
    "\n",
    "# Label smoothing cross entropy\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "def reduce_loss(loss, reduction='mean'):\n",
    "    return loss.mean() if reduction=='mean' else loss.sum() if reduction=='sum' else loss\n",
    "\n",
    "class LabelSmoothingCrossEntropy(nn.Module):\n",
    "    def __init__(self, ε:float=0.1, reduction='mean'):\n",
    "        super().__init__()\n",
    "        self.ε,self.reduction = ε,reduction\n",
    "    \n",
    "    def forward(self, output, target):\n",
    "        c = output.size()[-1]\n",
    "        log_preds = F.log_softmax(output, dim=-1)\n",
    "        loss = reduce_loss(-log_preds.sum(dim=-1), self.reduction)\n",
    "        nll = F.nll_loss(log_preds, target, reduction=self.reduction)\n",
    "        return lin_comb(loss/c, nll, self.ε)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions that shows the image, true class, predicted class and degree of prediction\n",
    "\n",
    "def images_to_probs(net, images):\n",
    "    '''\n",
    "    Generates predictions and corresponding probabilities from a trained\n",
    "    network and a list of images\n",
    "    '''\n",
    "    output = net(images)\n",
    "    # convert output probabilities to predicted class\n",
    "    _, preds_tensor = torch.max(output, 1)\n",
    "    preds = np.squeeze(preds_tensor.numpy())\n",
    "    return preds, [F.softmax(el, dim=0)[i].item() for i, el in zip(preds, output)]\n",
    "\n",
    "\n",
    "def plot_classes_preds(net, images, labels):\n",
    "    '''\n",
    "    Generates matplotlib Figure using a trained network, along with images\n",
    "    and labels from a batch, that shows the network's top prediction along\n",
    "    with its probability, alongside the actual label, coloring this\n",
    "    information based on whether the prediction was correct or not.\n",
    "    Uses the \"images_to_probs\" function.\n",
    "    '''\n",
    "    preds, probs = images_to_probs(net, images)\n",
    "    # plot the images in the batch, along with predicted and true labels\n",
    "    fig = plt.figure(figsize=(12, 48))\n",
    "    for idx in np.arange(4):\n",
    "        ax = fig.add_subplot(1, 4, idx+1, xticks=[], yticks=[])\n",
    "        matplotlib_imshow(images[idx], one_channel=True)\n",
    "        ax.set_title(\"{0}, {1:.1f}%\\n(label: {2})\".format(\n",
    "            labels[preds[idx]],\n",
    "            probs[idx] * 100.0,\n",
    "            labels[labels[idx]]),\n",
    "                    color=(\"green\" if preds[idx]==labels[idx].item() else \"red\"))\n",
    "    return fig\n",
    "\n",
    "def matplotlib_imshow(img, one_channel=True):\n",
    "    if one_channel:\n",
    "        img = img.mean(dim=0)\n",
    "    img = img / 2 + 0.5     # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    if one_channel:\n",
    "        plt.imshow(npimg, cmap=\"Greys\")\n",
    "    else:\n",
    "        plt.imshow(np.transpose(npimg, (1, 2, 0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def confusion_matrix_calc(data_loader_test, classes, model_ft):       \n",
    "        y_pred = []\n",
    "        y_true = []\n",
    "        for inputs, labels, imNo in data_loader_test:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "                output = model_ft(inputs) # Feed Network\n",
    "\n",
    "                output = (torch.max(torch.exp(output), 1)[1]).data.cpu().numpy()\n",
    "                y_pred.extend(output) # Save Prediction\n",
    "                \n",
    "                labels = labels.data.cpu().numpy()\n",
    "                y_true.extend(labels) # Save Truth\n",
    "\n",
    "        # constant for classes\n",
    "        # classes = ('Alive', 'Dead')\n",
    "\n",
    "        # Build confusion matrix\n",
    "        cf_matrix = confusion_matrix(y_true, y_pred)\n",
    "        return cf_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(92178, {'train': 92178, 'val': 39505})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(10)\n",
    "imIdx = torch.randperm(1).tolist()\n",
    "\n",
    "## Create dataset\n",
    "dataSetTrain = DNADataset(imDr, get_transform(train = True), labels, imDx=imIdx)\n",
    "dataSetTest = DNADataset(imDr, get_transform(train = False), labels, imDx=imIdx)\n",
    "\n",
    "# ## Create dataloaders\n",
    "# Get subset\n",
    "torch.manual_seed(10)\n",
    "indices = torch.randperm(len(dataSetTrain)).tolist()\n",
    "\n",
    "noTrain = int(len(dataSetTrain)*0.7)\n",
    "\n",
    "dataset_train = torch.utils.data.Subset(dataSetTrain, indices[-noTrain:])\n",
    "\n",
    "dataset_test = torch.utils.data.Subset(dataSetTest, indices[:-noTrain])\n",
    "#len(indices), len(indices[:-50]), len(indices[-50:]), 50/191, type(dataset_test)\n",
    "\n",
    "dataset_sizes = {'train': len(dataset_train), 'val': len(dataset_test)}\n",
    "\n",
    "# define training and validation data loaders\n",
    "data_loader_train = torch.utils.data.DataLoader(\n",
    "    dataset_train, batch_size=128, shuffle=True, num_workers=0)\n",
    "\n",
    "data_loader_test = torch.utils.data.DataLoader(\n",
    "    dataset_test, batch_size=128, shuffle=False, num_workers=0)\n",
    "\n",
    "# Collate function (gathers together the outputs)\n",
    "# def collate_fn(batch):\n",
    "#     return tuple(zip(*batch))\n",
    "\n",
    "len(indices[-noTrain:]), dataset_sizes\n",
    "#dataset_test[0][1], dataset_test[3][1], dataset_test[-1][1], dataSetTrain.imgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/9\n",
      "----------\n",
      "train Loss: 0.5654 Acc: 0.7357\n",
      "val Loss: 1.1468 Acc: 0.6342\n",
      "\n",
      "Epoch 1/9\n",
      "----------\n",
      "train Loss: 0.4644 Acc: 0.7963\n",
      "val Loss: 0.4481 Acc: 0.7847\n",
      "\n",
      "Epoch 2/9\n",
      "----------\n",
      "train Loss: 0.4284 Acc: 0.8112\n",
      "val Loss: 0.7469 Acc: 0.5735\n",
      "\n",
      "Epoch 3/9\n",
      "----------\n",
      "train Loss: 0.4115 Acc: 0.8212\n",
      "val Loss: 0.5785 Acc: 0.6809\n",
      "\n",
      "Epoch 4/9\n",
      "----------\n",
      "train Loss: 0.4011 Acc: 0.8235\n",
      "val Loss: 1.2026 Acc: 0.5008\n",
      "\n",
      "Epoch 5/9\n",
      "----------\n",
      "train Loss: 0.3924 Acc: 0.8293\n",
      "val Loss: 2.5713 Acc: 0.4999\n",
      "\n",
      "Epoch 6/9\n",
      "----------\n",
      "train Loss: 0.3844 Acc: 0.8332\n",
      "val Loss: 0.4265 Acc: 0.8020\n",
      "\n",
      "Epoch 7/9\n",
      "----------\n",
      "train Loss: 0.3513 Acc: 0.8512\n",
      "val Loss: 0.3710 Acc: 0.8395\n",
      "\n",
      "Epoch 8/9\n",
      "----------\n",
      "train Loss: 0.3387 Acc: 0.8550\n",
      "val Loss: 0.3674 Acc: 0.8402\n",
      "\n",
      "Epoch 9/9\n",
      "----------\n",
      "train Loss: 0.3359 Acc: 0.8585\n",
      "val Loss: 0.3703 Acc: 0.8402\n",
      "\n",
      "Training complete in 28m 50s\n",
      "Best val Acc: 0.840235\n",
      "[[ 2486   506]\n",
      " [ 5492 31021]]\n",
      "Epoch 0/9\n",
      "----------\n",
      "train Loss: 0.5618 Acc: 0.7390\n",
      "val Loss: 0.8330 Acc: 0.6026\n",
      "\n",
      "Epoch 1/9\n",
      "----------\n",
      "train Loss: 0.4607 Acc: 0.7940\n",
      "val Loss: 0.5609 Acc: 0.7112\n",
      "\n",
      "Epoch 2/9\n",
      "----------\n",
      "train Loss: 0.4252 Acc: 0.8105\n",
      "val Loss: 0.4959 Acc: 0.7766\n",
      "\n",
      "Epoch 3/9\n",
      "----------\n",
      "train Loss: 0.4091 Acc: 0.8196\n",
      "val Loss: 0.4774 Acc: 0.7742\n",
      "\n",
      "Epoch 4/9\n",
      "----------\n",
      "train Loss: 0.3957 Acc: 0.8254\n",
      "val Loss: 0.5078 Acc: 0.7449\n",
      "\n",
      "Epoch 5/9\n",
      "----------\n",
      "train Loss: 0.3825 Acc: 0.8348\n",
      "val Loss: 0.5543 Acc: 0.7631\n",
      "\n",
      "Epoch 6/9\n",
      "----------\n",
      "train Loss: 0.3735 Acc: 0.8371\n",
      "val Loss: 1.1779 Acc: 0.5896\n",
      "\n",
      "Epoch 7/9\n",
      "----------\n",
      "train Loss: 0.3355 Acc: 0.8594\n",
      "val Loss: 0.4512 Acc: 0.8014\n",
      "\n",
      "Epoch 8/9\n",
      "----------\n",
      "train Loss: 0.3256 Acc: 0.8647\n",
      "val Loss: 0.3667 Acc: 0.8412\n",
      "\n",
      "Epoch 9/9\n",
      "----------\n",
      "train Loss: 0.3200 Acc: 0.8662\n",
      "val Loss: 0.3689 Acc: 0.8408\n",
      "\n",
      "Training complete in 31m 16s\n",
      "Best val Acc: 0.841151\n",
      "[[ 2564   428]\n",
      " [ 6377 30136]]\n",
      "Epoch 0/9\n",
      "----------\n",
      "train Loss: 0.7880 Acc: 0.7109\n",
      "val Loss: 0.5935 Acc: 0.7285\n",
      "\n",
      "Epoch 1/9\n",
      "----------\n",
      "train Loss: 0.5005 Acc: 0.7923\n",
      "val Loss: 0.7892 Acc: 0.6065\n",
      "\n",
      "Epoch 2/9\n",
      "----------\n",
      "train Loss: 0.4369 Acc: 0.8106\n",
      "val Loss: 6.3008 Acc: 0.5000\n",
      "\n",
      "Epoch 3/9\n",
      "----------\n",
      "train Loss: 0.4181 Acc: 0.8178\n",
      "val Loss: 0.8898 Acc: 0.6067\n",
      "\n",
      "Epoch 4/9\n",
      "----------\n",
      "train Loss: 0.4044 Acc: 0.8245\n",
      "val Loss: 0.5728 Acc: 0.7231\n",
      "\n",
      "Epoch 5/9\n",
      "----------\n",
      "train Loss: 0.3931 Acc: 0.8302\n",
      "val Loss: 0.6554 Acc: 0.6825\n",
      "\n",
      "Epoch 6/9\n",
      "----------\n",
      "train Loss: 0.3840 Acc: 0.8345\n",
      "val Loss: 0.4194 Acc: 0.8118\n",
      "\n",
      "Epoch 7/9\n",
      "----------\n",
      "train Loss: 0.3496 Acc: 0.8515\n",
      "val Loss: 0.3726 Acc: 0.8396\n",
      "\n",
      "Epoch 8/9\n",
      "----------\n",
      "train Loss: 0.3454 Acc: 0.8562\n",
      "val Loss: 0.3740 Acc: 0.8398\n",
      "\n",
      "Epoch 9/9\n",
      "----------\n",
      "train Loss: 0.3391 Acc: 0.8566\n",
      "val Loss: 0.3756 Acc: 0.8373\n",
      "\n",
      "Training complete in 36m 12s\n",
      "Best val Acc: 0.839827\n",
      "[[ 2492   500]\n",
      " [ 5595 30918]]\n",
      "Epoch 0/9\n",
      "----------\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "only batches of spatial targets supported (3D tensors) but got targets of size: : [128]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_764/53579104.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     21\u001b[0m                 \u001b[0moptimizer_ft\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSGD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmomentum\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mMomentum\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m                 \u001b[0mexp_lr_scheduler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlr_scheduler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mStepLR\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer_ft\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgamma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mGAMMA\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m                 model_ft, con_mat = train_model(model, criterion, optimizer_ft, exp_lr_scheduler,\n\u001b[0m\u001b[1;32m     24\u001b[0m                    data_loader_train,data_loader_test,num_epochs=10)\n\u001b[1;32m     25\u001b[0m                 \u001b[0mcf_matrix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfusion_matrix_calc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_loader_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_ft\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_764/3239080070.py\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, criterion, optimizer, scheduler, dataloaderTrain, dataloaderTest, num_epochs)\u001b[0m\n\u001b[1;32m     41\u001b[0m                         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m                         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m                         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m                         \u001b[0;31m# backward + optimize only if in training phase\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m                         \u001b[0;32mif\u001b[0m \u001b[0mphase\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'train'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/nn/modules/loss.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m   1148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1149\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1150\u001b[0;31m         return F.cross_entropy(input, target, weight=self.weight,\n\u001b[0m\u001b[1;32m   1151\u001b[0m                                \u001b[0mignore_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mignore_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1152\u001b[0m                                label_smoothing=self.label_smoothing)\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mcross_entropy\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction, label_smoothing)\u001b[0m\n\u001b[1;32m   2847\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msize_average\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mreduce\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2848\u001b[0m         \u001b[0mreduction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_get_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize_average\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2849\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcross_entropy_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_enum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_smoothing\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2850\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2851\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: only batches of spatial targets supported (3D tensors) but got targets of size: : [128]"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x504 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x504 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x504 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "class_weights= [0.924865,0.075135] #1-(#inclass/ #intotal )\n",
    "class_weights = torch.Tensor(class_weights)\n",
    "class_weights=class_weights.to(device)\n",
    "criterion = nn.CrossEntropyLoss(weight = class_weights) \n",
    "\n",
    "# Observe that all parameters are being optimized\n",
    "learning_rate=[0.1]#,0.2,0.5]\n",
    "Momentum=[0.1,0.5]#,0.9,0.99]\n",
    "GAMMA=[0.05,0.1]#, 0.5, 0.8]\n",
    "#Batch_size= [16,32]#,64,128]\n",
    "model=[model18,model34,model50]\n",
    "\n",
    "#ADD IN A THING SO IT SAVES THE TENSORBOARD TO DIFFERENT BITS\n",
    "\n",
    "for learning_rate in learning_rate:\n",
    "    for GAMMA in GAMMA:\n",
    "        for Momentum in Momentum:\n",
    "            for model in model:\n",
    "                model = model.to(device)\n",
    "                # Decay LR by a factor of gamma every 7 epochs\n",
    "                optimizer_ft = optim.SGD(model.parameters(), lr=learning_rate, momentum=Momentum)\n",
    "                exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=GAMMA)\n",
    "                model_ft, con_mat = train_model(model, criterion, optimizer_ft, exp_lr_scheduler,\n",
    "                   data_loader_train,data_loader_test,num_epochs=10)\n",
    "                cf_matrix = confusion_matrix_calc(data_loader_test, labels, model_ft)\n",
    "                print(cf_matrix)\n",
    "                df_cm_ratio = pd.DataFrame(cf_matrix / np.sum(cf_matrix, axis=1)[:, None], index=[i for i in labels],\n",
    "                     columns=[i for i in labels])\n",
    "                plt.figure(figsize=(12, 7))\n",
    "                sn.heatmap(df_cm_ratio, annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#model_ft, con_mat = train_model(model, criterion, optimizer_ft, exp_lr_scheduler, \n",
    "                                    #data_loader_train,data_loader_test,num_epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cf_matrix = confusion_matrix_calc(data_loader_test, labels, model_ft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cm_ratio = pd.DataFrame(cf_matrix / np.sum(cf_matrix, axis=1)[:, None], index=[i for i in labels],\n",
    "                     columns=[i for i in labels])\n",
    "plt.figure(figsize=(12, 7))\n",
    "sn.heatmap(df_cm_ratio, annot=True)\n",
    "# plt.save(\"Confusion_matrix_ratio.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_cm_raw = pd.DataFrame(cf_matrix, index=[i for i in labels],\n",
    "                     columns=[i for i in labels])\n",
    "plt.figure(figsize=(12, 7))\n",
    "sn.heatmap(df_cm_raw, annot=True)\n",
    "# plt.save(\"Confusion_matrix_raw.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cf_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
