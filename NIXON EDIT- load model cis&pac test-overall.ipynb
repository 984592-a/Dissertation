{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To note: Running this on different systems (i.e. local, SCW, server) will result in slight changes needing to the code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/scipy/__init__.py:138: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.4)\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion} is required for this version of \"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.pyplot._IonContext at 0x7fa674e22820>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load libraries\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import sys\n",
    "import torchvision\n",
    "import torchvision.transforms as T\n",
    "import torchvision.models as models\n",
    "from PIL import Image\n",
    "from PIL import ImageEnhance\n",
    "import matplotlib.pyplot as plt\n",
    "import imagesize\n",
    "import subprocess\n",
    "sys.path\n",
    "from IPython.core.debugger import set_trace\n",
    "import scipy.ndimage\n",
    "import matplotlib.patches as patches\n",
    "# plt.rcParams['figure.figsize'] = [12,12]\n",
    "# sys.path.append('/workspace/myFile/Mask_RCNN_Tutorial/')\n",
    "from tqdm import tqdm\n",
    "from torch import nn as nn\n",
    "from torch import optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "import re\n",
    "import time\n",
    "import copy\n",
    "import pylab\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from tempfile import TemporaryDirectory\n",
    "import torch.backends.cudnn as cudnn\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "import seaborn as sn\n",
    "import pandas as pd\n",
    "import glob\n",
    "# Rather than have a messy notebook with a load of functions we can store them in separate .py files and import them\n",
    "\n",
    "cudnn.benchmark = True\n",
    "plt.ion()   # interactive mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "writer = SummaryWriter(\"Experiments/TENSORBOARD\")    # This determines the tensorboard file name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DNADataset(object):\n",
    "    def __init__(self, root, transforms, labels, imDx = False):\n",
    "        self.root, self.transforms, self.labels = root, transforms, labels\n",
    "    \n",
    "        # load all image files, sorting them to ensure they are aligned\n",
    "        self.imgDir = glob.glob(root+\"*/*.tiff\")\n",
    "        Damagednuclei= [x for x in self.imgDir if 'Damaged_nuclei_' in x]\n",
    "        Undamagednuclei= [x for x in self.imgDir if \"No_damage_nuclei\" in x]\n",
    "        #np.random.shuffle(Undamagednuclei)\n",
    "        #Undamagednuclei=Undamagednuclei[:10000]\n",
    "        self.imgDir= Damagednuclei+Undamagednuclei\n",
    "        size80=[]\n",
    "        for x in self.imgDir:\n",
    "            img = Image.open(x) # Open image\n",
    "            w,h=img.size\n",
    "            if w<=80 and h<=80:\n",
    "                size80.append(x)\n",
    "        self.imgDir=size80              \n",
    "        \n",
    "        self.imgs = sorted(self.imgDir) # list of images\n",
    "\n",
    "        \n",
    "\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.imgs[idx]\n",
    "       \n",
    "        # Transform images into tensors\n",
    "        img = Image.open(img_path) # Open image\n",
    "        w,h=img.size\n",
    "        img = np.array(img) # Convert image into an array\n",
    "        img = np.float32(np.divide(img, 2**16)) # Ensure all values are floats\n",
    "        \n",
    "        result=np.zeros((80,80), dtype=np.float32)\n",
    "        x_center = (80 - w) // 2\n",
    "        y_center = (80 - h) // 2 # copy img image into center of result image\n",
    "        result[y_center:y_center+h, x_center:x_center+w] = img\n",
    "        img = result\n",
    "        \n",
    "        targetlab=\"\"\n",
    "        if img_path.find('No_damage_nuclei') != -1:\n",
    "            targetlab= 'Undamaged'\n",
    "        if img_path.find('Damaged_nuclei_') != -1:\n",
    "            targetlab= 'Damaged'  # Find labels corresponding to image\n",
    "        target = self.labels.index(targetlab) # Get the label and assign to a value\n",
    "        \n",
    "        # Convert label to tensor\n",
    "        #torch.to\n",
    "        \n",
    "        if self.transforms is not None:\n",
    "            img = self.transforms(img)\n",
    "#             #print('In the transforms')\n",
    "        imNo = idx\n",
    "        return img, target, imNo\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.imgs)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "imDr = \"/workspace/myFile/Output/17052023/\"  # Image patches directory\n",
    "\n",
    "labels = ['Damaged', 'Undamaged']  # Your labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For data augmentation\n",
    "def get_transform(train):\n",
    "    transforms = []\n",
    "\n",
    "    transforms.append(T.ToTensor())\n",
    "    #transforms.append(T.Normalize([0.0019368887995516483], [0.00672996630111016]))\n",
    "    #transforms.append(T.RandomHorizontalFlip(0.5))\n",
    "    \n",
    "    if train:\n",
    "        transforms.append(T.RandomHorizontalFlip(p=1))\n",
    "        transforms.append(T.RandomVerticalFlip(p=1))\n",
    "    \n",
    "    return T.Compose(transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, scheduler, train, test, num_epochs=25):\n",
    "    since = time.time()\n",
    "    # Create a temporary directory to save training checkpoints\n",
    "    with TemporaryDirectory() as tempdir:\n",
    "        best_model_params_path = os.path.join(tempdir, 'best_model_params.pt')\n",
    "\n",
    "        torch.save(model.state_dict(), best_model_params_path)\n",
    "        best_acc = 0.0\n",
    "        \n",
    "        for epoch in range(num_epochs):\n",
    "            print(f'Epoch {epoch}/{num_epochs - 1}')\n",
    "            print('-' * 10)\n",
    "            dataset_train = torch.utils.data.Subset(dataSetTrain, train[epoch])\n",
    "            dataset_test = torch.utils.data.Subset(dataSetTest, test[epoch])\n",
    "            data_loader_train = torch.utils.data.DataLoader(\n",
    "                dataset_train, batch_size=128, shuffle=True, num_workers=0)\n",
    "\n",
    "            data_loader_test = torch.utils.data.DataLoader(\n",
    "                dataset_test, batch_size=128, shuffle=False, num_workers=0)\n",
    "            # Each epoch has a training and validation phase\n",
    "            for phase in ['val']:\n",
    "                if phase == 'train':\n",
    "                    model.train()  # Set model to training mode\n",
    "                    dataloaders = data_loader_train\n",
    "                else:\n",
    "                    model.eval()   # Set model to evaluate mode\n",
    "                    dataloaders = data_loader_test\n",
    "\n",
    "                running_loss = 0.0\n",
    "                running_corrects = 0\n",
    "                damaged_len=0\n",
    "                damaged_corrects = 0\n",
    "                undamaged_len=0\n",
    "                undamaged_corrects = 0\n",
    "\n",
    "                # Iterate over data.\n",
    "                for inputs, labels, imNo in dataloaders:\n",
    "                    inputs = inputs.to(device)\n",
    "                    labels = labels.to(device)\n",
    "\n",
    "                    # zero the parameter gradients\n",
    "                    optimizer.zero_grad()\n",
    "\n",
    "                    # forward\n",
    "                    # track history if only in train\n",
    "                    with torch.set_grad_enabled(phase == 'train'):\n",
    "                        outputs = model(inputs)\n",
    "                        _, preds = torch.max(outputs, 1)\n",
    "                        loss = criterion(outputs, labels)\n",
    "                        # backward + optimize only if in training phase\n",
    "                        if phase == 'train':\n",
    "                            loss.backward()\n",
    "                            optimizer.step()\n",
    "\n",
    "                    # statistics\n",
    "                    running_loss += loss.item() * inputs.size(0)    # Loss\n",
    "                    nada=torch.tensor(np.zeros(len(labels))).to(device)\n",
    "                    uno=nada+1\n",
    "                    falseneg=preds+1\n",
    "                    falsepos=preds-1\n",
    "                    FPplusTN=torch.sum(labels==nada)\n",
    "                    TPplusFN=torch.sum(labels==uno)\n",
    "                    FN=torch.sum(labels==falseneg)\n",
    "                    FP=torch.sum(labels==falsepos)\n",
    "                    TN=FPplusTN-FP\n",
    "                    TP=TPplusFN-FN\n",
    "                    running_corrects += torch.sum(preds == labels.data) # Accuracy\n",
    "                    damaged_len+=TPplusFN\n",
    "                    damaged_corrects += TP\n",
    "                    undamaged_len+=FPplusTN\n",
    "                    undamaged_corrects += TN\n",
    "                damaged_acc = damaged_corrects / damaged_len\n",
    "                undamaged_acc = undamaged_corrects/undamaged_len\n",
    "                epoch_acc= (damaged_acc+undamaged_acc)/2\n",
    "                proper_acc=(damaged_corrects+undamaged_corrects)/(damaged_len+undamaged_len)\n",
    "                if phase == 'train':\n",
    "                    scheduler.step()\n",
    "\n",
    "                epoch_loss = running_loss / dataset_sizes[phase]    # Loss metric per epoch\n",
    "                #epoch_acc = running_corrects.double() / dataset_sizes[phase]    # Accuracy metric per epoch\n",
    "\n",
    "                if phase == \"train\":    # This is the tensorboard code that writes accuracy and loss metrics\n",
    "                    writer.add_scalar(\"Train/Accuracy\", epoch_acc, epoch)\n",
    "                    writer.add_scalar(\"Train/Loss\", epoch_loss, epoch)\n",
    "                else:\n",
    "                    writer.add_scalar(\"Validation/Accuracy\", epoch_acc, epoch)\n",
    "                    writer.add_scalar(\"Validation/Loss\", epoch_loss, epoch)\n",
    "\n",
    "                print(f'{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n",
    "                print(\"proper accuracy=\")\n",
    "                print(proper_acc)\n",
    "                print(\"undamaged accuracy=\")\n",
    "                print(damaged_acc)\n",
    "                print(\"damaged accuracy=\")\n",
    "                print(undamaged_acc)\n",
    "                con_matter= torch.tensor([[damaged_corrects, damaged_len-damaged_corrects],[undamaged_len-undamaged_corrects,undamaged_corrects]])\n",
    "                con_matter=con_matter.cpu().numpy()\n",
    "                print(con_matter)\n",
    "                # deep copy the model\n",
    "                if phase == 'val' and epoch_acc >= best_acc: \n",
    "                    # This compares validation accuracy to previous bests and adjusts model weights accordingly\n",
    "                    best_acc = epoch_acc\n",
    "                    torch.save(model.state_dict(), best_model_params_path)\n",
    "                    con_mat= torch.tensor([[damaged_corrects, damaged_len-damaged_corrects],[undamaged_len-undamaged_corrects,undamaged_corrects]])\n",
    "\n",
    "            print()\n",
    "\n",
    "        time_elapsed = time.time() - since  # Nice way to measure training time but info also stored (indirectly) by tensorboard\n",
    "        print(\n",
    "            f'Training complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')\n",
    "        print(f'Best val Acc: {best_acc:4f}')\n",
    "        #labels= labels.cpu().numpy()\n",
    "        #preds=preds.cpu().numpy()\n",
    "        model.load_state_dict(torch.load(best_model_params_path))\n",
    "    writer.close()\n",
    "    return model, con_mat   # We want to return the model because its the model, also confusion matrix for later analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "6914# This is your RESNET\n",
    "# Initialize CNN with kaiming\n",
    "def init_cnn(m):\n",
    "    # Set the weights of the RESNET\n",
    "    if getattr(m, 'bias', None) is not None: nn.init.constant_(m.bias, 0)\n",
    "    if isinstance(m, (nn.Conv2d,nn.Linear)): nn.init.kaiming_normal_(m.weight)\n",
    "    for l in m.children(): init_cnn(l)\n",
    "\n",
    "\n",
    "# noop function for returning nothing\n",
    "def noop(x): return x\n",
    "# activation function(RELU)\n",
    "act_fn = nn.ReLU(inplace=True)\n",
    "\n",
    "# Flatten\n",
    "class Flatten(nn.Module):\n",
    "    def forward(self, x): return x.view(x.size(0), -1)\n",
    "\n",
    "# Make a convolution\n",
    "def conv(ni, nf, ks=3, stride=1, bias=False):\n",
    "    return nn.Conv2d(ni, nf, kernel_size=ks, stride=stride, padding=ks//2, bias=bias)\n",
    "\n",
    "# Create a convuolutional layer with convolution and batch norm\n",
    "def conv_layer(ni, nf, ks=3, stride=1, zero_bn=False, act=True):\n",
    "    bn = nn.BatchNorm2d(nf) # get a 2d batch norm from Pytorhc\n",
    "    nn.init.constant_(bn.weight, 0. if zero_bn else 1.)\n",
    "    layers = [conv(ni, nf, ks, stride=stride), bn]\n",
    "    if act: layers.append(act_fn) # add in the activation function if act is true\n",
    "    return nn.Sequential(*layers)\n",
    "\n",
    "\n",
    "# Resblock\n",
    "class ResBlock(nn.Module):\n",
    "    def __init__(self, expansion, ni, nh, stride = 1):\n",
    "        super().__init__()\n",
    "        # ni - number of inputs channels, nf - number of filters\n",
    "        # nh - number of filters in first conv\n",
    "        # expansion is 1 for resnet 18, 34 and 4 for larger networks\n",
    "        nf, ni = nh*expansion, ni*expansion\n",
    "        layers = [conv_layer(ni, nh, 3, stride = stride), # for resnet < 34 2 convs per resblock\n",
    "                 conv_layer(nh, nf, 3, zero_bn = True, act = False)\n",
    "                 ] if expansion == 1 else [ # for RESNET > 34 then 3 convs per block with bottleneck\n",
    "                            conv_layer(ni, nh, 1),\n",
    "                            conv_layer(nh, nh, 3, stride = stride),\n",
    "                            conv_layer(nh, nf, 1, zero_bn = True, act = False)\n",
    "        ]\n",
    "        self.convs = nn.Sequential(*layers) # Creates the conv layers\n",
    "        self.idconv = noop if ni==nf else conv_layer(ni, nf, 1, act = False) # id convolution ()\n",
    "        self.pool = noop if stride== 1 else nn.AvgPool2d(2, ceil_mode = True) # average pool on \n",
    "        \n",
    "    def forward(self, x): \n",
    "        # Forward function adds the convolution part to the id part \n",
    "        #return act_fn(self.convs(x)) + self.idconv(self.pool(x))\n",
    "        return act_fn(self.convs(x) + self.idconv(self.pool(x)))\n",
    "\n",
    "# XResnet\n",
    "class XResNet(nn.Sequential):\n",
    "    @classmethod\n",
    "    def create(cls, expansion, layers, c_in=3, c_out=1000):\n",
    "        nfs = [c_in, (c_in + 1)*8, 64, 64] # number of filters in stem layer (c_in is number of image channels)\n",
    "        stem = [conv_layer(nfs[i], nfs[i+1], stride=2 if i==0 else 1)\n",
    "            for i in range(3)]\n",
    "\n",
    "        nfs = [64//expansion,64,128,256,512]\n",
    "        res_layers = [cls._make_layer(expansion, nfs[i], nfs[i+1],\n",
    "                                      n_blocks=l, stride=1 if i==0 else 2)\n",
    "                  for i,l in enumerate(layers)]\n",
    "        res = cls(\n",
    "        *stem,\n",
    "        nn.MaxPool2d(kernel_size=3, stride = 2, padding = 1), # then a max pooling layer\n",
    "        *res_layers,\n",
    "        nn.AdaptiveAvgPool2d(1), Flatten(), \n",
    "        nn.Linear(nfs[-1]*expansion, c_out)\n",
    "        )\n",
    "        init_cnn(res)\n",
    "        return res\n",
    "        \n",
    "    @staticmethod\n",
    "    def _make_layer(expansion, ni, nf, n_blocks, stride): # returns a resblock\n",
    "        return nn.Sequential(\n",
    "        *[ResBlock(expansion, ni if i==0 else nf, nf, stride if i==0 else 1)\n",
    "         for i in range(n_blocks)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def xresnet18 (**kwargs): return XResNet.create(1, [2, 2,  2, 2], **kwargs)\n",
    "def xresnet34 (**kwargs): return XResNet.create(1, [3, 4,  6, 3], **kwargs)\n",
    "def xresnet50 (**kwargs): return XResNet.create(4, [3, 4,  6, 3], **kwargs)\n",
    "model = xresnet18(c_in = 1, c_out = 2)\n",
    "#model34 = xresnet34(c_in = 1, c_out = 2)\n",
    "#model50 = xresnet50(c_in = 1, c_out = 2)\n",
    "model.load_state_dict(torch.load(\"/workspace/myFile/Output/17052023/cis_and_pac_best_model_params.pt\"))\n",
    "model = model.to(device)\n",
    "\n",
    "# Label smoothing cross entropy\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "def reduce_loss(loss, reduction='mean'):\n",
    "    return loss.mean() if reduction=='mean' else loss.sum() if reduction=='sum' else loss\n",
    "\n",
    "class LabelSmoothingCrossEntropy(nn.Module):\n",
    "    def __init__(self, ε:float=0.1, reduction='mean'):\n",
    "        super().__init__()\n",
    "        self.ε,self.reduction = ε,reduction\n",
    "    \n",
    "    def forward(self, output, target):\n",
    "        c = output.size()[-1]\n",
    "        log_preds = F.log_softmax(output, dim=-1)\n",
    "        loss = reduce_loss(-log_preds.sum(dim=-1), self.reduction)\n",
    "        nll = F.nll_loss(log_preds, target, reduction=self.reduction)\n",
    "        return lin_comb(loss/c, nll, self.ε)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions that shows the image, true class, predicted class and degree of prediction\n",
    "\n",
    "def images_to_probs(net, images):\n",
    "    '''\n",
    "    Generates predictions and corresponding probabilities from a trained\n",
    "    network and a list of images\n",
    "    '''\n",
    "    output = net(images)\n",
    "    # convert output probabilities to predicted class\n",
    "    _, preds_tensor = torch.max(output, 1)\n",
    "    preds = np.squeeze(preds_tensor.numpy())\n",
    "    return preds, [F.softmax(el, dim=0)[i].item() for i, el in zip(preds, output)]\n",
    "\n",
    "\n",
    "def plot_classes_preds(net, images, labels):\n",
    "    '''\n",
    "    Generates matplotlib Figure using a trained network, along with images\n",
    "    and labels from a batch, that shows the network's top prediction along\n",
    "    with its probability, alongside the actual label, coloring this\n",
    "    information based on whether the prediction was correct or not.\n",
    "    Uses the \"images_to_probs\" function.\n",
    "    '''\n",
    "    preds, probs = images_to_probs(net, images)\n",
    "    # plot the images in the batch, along with predicted and true labels\n",
    "    fig = plt.figure(figsize=(12, 48))\n",
    "    for idx in np.arange(4):\n",
    "        ax = fig.add_subplot(1, 4, idx+1, xticks=[], yticks=[])\n",
    "        matplotlib_imshow(images[idx], one_channel=True)\n",
    "        ax.set_title(\"{0}, {1:.1f}%\\n(label: {2})\".format(\n",
    "            labels[preds[idx]],\n",
    "            probs[idx] * 100.0,\n",
    "            labels[labels[idx]]),\n",
    "                    color=(\"green\" if preds[idx]==labels[idx].item() else \"red\"))\n",
    "    return fig\n",
    "\n",
    "def matplotlib_imshow(img, one_channel=True):\n",
    "    if one_channel:\n",
    "        img = img.mean(dim=0)\n",
    "    img = img / 2 + 0.5     # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    if one_channel:\n",
    "        plt.imshow(npimg, cmap=\"Greys\")\n",
    "    else:\n",
    "        plt.imshow(np.transpose(npimg, (1, 2, 0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def confusion_matrix_calc(data_loader_test, classes, model_ft):       \n",
    "        y_pred = []\n",
    "        y_true = []\n",
    "        for inputs, labels, imNo in data_loader_test:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "                output = model_ft(inputs) # Feed Network\n",
    "\n",
    "                output = (torch.max(torch.exp(output), 1)[1]).data.cpu().numpy()\n",
    "                y_pred.extend(output) # Save Prediction\n",
    "                \n",
    "                labels = labels.data.cpu().numpy()\n",
    "                y_true.extend(labels) # Save Truth\n",
    "\n",
    "        # constant for classes\n",
    "        # classes = ('Alive', 'Dead')\n",
    "\n",
    "        # Build confusion matrix\n",
    "        cf_matrix = confusion_matrix(y_true, y_pred)\n",
    "        return cf_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "k=5 #NUMBER OF K FOLDS\n",
    "epoch=5 #NUMBER OF EPOCHS\n",
    "\n",
    "torch.manual_seed(10)\n",
    "imIdx = torch.randperm(1).tolist()\n",
    "\n",
    "## Create dataset\n",
    "dataSetTrain = DNADataset(imDr, get_transform(train = True), labels, imDx=imIdx)\n",
    "dataSetTest = DNADataset(imDr, get_transform(train = False), labels, imDx=imIdx)\n",
    "\n",
    "data_loader_train=[]\n",
    "data_loader_test=[]\n",
    "\n",
    "# ## Create dataloaders\n",
    "# Get subset\n",
    "torch.manual_seed(10)\n",
    "indices = torch.randperm(len(dataSetTrain)).tolist()\n",
    "\n",
    "noTrain = int(len(dataSetTrain)*0.7)\n",
    "train=[]\n",
    "test=[]\n",
    "indices = torch.randperm(len(dataSetTrain)).tolist()\n",
    "TotalSet=list(range(len(dataSetTrain)))\n",
    "Kfifth = len(dataSetTrain)//k\n",
    "split= epoch%k\n",
    "train.append(TotalSet[(split+1)*Kfifth:]+TotalSet[:Kfifth*split])\n",
    "\n",
    "indices = torch.randperm(len(dataSetTest)).tolist()\n",
    "TotalSet=list(range(len(dataSetTrain)))\n",
    "test.append(TotalSet)\n",
    "\n",
    "#dataset_train = torch.utils.data.Subset(dataSetTrain, indices[-noTrain:])\n",
    "\n",
    "#dataset_test = torch.utils.data.Subset(dataSetTest, indices[:-noTrain])\n",
    "#len(indices), len(indices[:-50]), len(indices[-50:]), 50/191, type(dataset_test)\n",
    "\n",
    "dataset_sizes = {'train': len(train[0]), 'val': len(test)}\n",
    "\n",
    "#dataset_train = torch.utils.data.Subset(dataSetTrain, train)\n",
    "#data_loader_train.append(dataset_train)\n",
    "#dataset_testo = torch.utils.data.Subset(dataSetTest, test)\n",
    "#data_loader_test.append(dataset_testo)\n",
    "# define training and validation data loaders\n",
    "\n",
    "\n",
    "# Collate function (gathers together the outputs)\n",
    "# def collate_fn(batch):\n",
    "#     return tuple(zip(*batch))\n",
    "\n",
    "#len(indices[-noTrain:]), dataset_sizes\n",
    "#dataset_test[0][1], dataset_test[3][1], dataset_test[-1][1], dataSetTrain.imgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_weights= [0.924865,0.075135] #1-(#inclass/ #intotal )\n",
    "class_weights = torch.Tensor(class_weights)\n",
    "class_weights=class_weights.to(device)\n",
    "criterion = nn.CrossEntropyLoss(weight = class_weights) \n",
    "\n",
    "# Observe that all parameters are being optimized\n",
    "optimizer_ft = optim.Adam(model.parameters(), weight_decay=1e-2) # standard ADAM optimiser\n",
    "\n",
    "# Decay LR by a factor of 0.1 every 7 epochs\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/0\n",
      "----------\n",
      "val Loss: 58927.3868 Acc: 0.7959\n",
      "proper accuracy=\n",
      "tensor(0.8847, device='cuda:0')\n",
      "damaged accuracy=\n",
      "tensor(0.9004, device='cuda:0')\n",
      "undamaged accuracy=\n",
      "tensor(0.6914, device='cuda:0')\n",
      "[[109659  12130]\n",
      " [  3053   6841]]\n",
      "\n",
      "Training complete in 2m 21s\n",
      "Best val Acc: 0.795915\n"
     ]
    }
   ],
   "source": [
    "model_ft, con_mat = train_model(model, criterion, optimizer_ft, exp_lr_scheduler, \n",
    "                                    train,test,num_epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cf_matrix = confusion_matrix_calc(data_loader_test, labels, model_ft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x504 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "con_mat=con_mat.cpu().numpy()\n",
    "plotlabels=['Undamaged','Damaged']\n",
    "df_cm_ratio = pd.DataFrame(con_mat / np.sum(con_mat, axis=1)[:, None], index=[i for i in plotlabels],\n",
    "                     columns=[i for i in plotlabels])\n",
    "plt.figure(figsize=(12, 7))\n",
    "sn.heatmap(df_cm_ratio, annot=True)\n",
    "# plt.save(\"Confusion_matrix_ratio.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x504 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_cm_raw = pd.DataFrame(con_mat, index=[i for i in plotlabels],\n",
    "                     columns=[i for i in plotlabels])\n",
    "plt.figure(figsize=(12, 7))\n",
    "sn.heatmap(df_cm_raw, annot=True)\n",
    "# plt.save(\"Confusion_matrix_raw.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[109659,  12130],\n",
       "       [  3053,   6841]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "con_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_loader_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotlabels=['Undamaged','Damaged']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
