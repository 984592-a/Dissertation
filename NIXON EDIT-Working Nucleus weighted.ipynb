{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To note: Running this on different systems (i.e. local, SCW, server) will result in slight changes needing to the code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/scipy/__init__.py:138: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.4)\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion} is required for this version of \"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.pyplot._IonContext at 0x7f481d39b850>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load libraries\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import sys\n",
    "import torchvision\n",
    "import torchvision.transforms as T\n",
    "import torchvision.models as models\n",
    "from PIL import Image\n",
    "from PIL import ImageEnhance\n",
    "import matplotlib.pyplot as plt\n",
    "import imagesize\n",
    "import subprocess\n",
    "sys.path\n",
    "from IPython.core.debugger import set_trace\n",
    "import scipy.ndimage\n",
    "import matplotlib.patches as patches\n",
    "# plt.rcParams['figure.figsize'] = [12,12]\n",
    "# sys.path.append('/workspace/myFile/Mask_RCNN_Tutorial/')\n",
    "from tqdm import tqdm\n",
    "from torch import nn as nn\n",
    "from torch import optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "import re\n",
    "import time\n",
    "import copy\n",
    "import pylab\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from tempfile import TemporaryDirectory\n",
    "import torch.backends.cudnn as cudnn\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "import seaborn as sn\n",
    "import pandas as pd\n",
    "import glob\n",
    "# Rather than have a messy notebook with a load of functions we can store them in separate .py files and import them\n",
    "\n",
    "cudnn.benchmark = True\n",
    "plt.ion()   # interactive mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "writer = SummaryWriter(\"Experiments/TENSORBOARD\")    # This determines the tensorboard file name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DNADataset(object):\n",
    "    def __init__(self, root, transforms, labels, imDx = False):\n",
    "        self.root, self.transforms, self.labels = root, transforms, labels\n",
    "    \n",
    "        # load all image files, sorting them to ensure they are aligned\n",
    "        self.imgDir = glob.glob(root+\"*/*.tiff\")\n",
    "        Damagednuclei= [x for x in self.imgDir if 'Damaged_nuclei_' in x]\n",
    "        Undamagednuclei= [x for x in self.imgDir if \"No_damage_nuclei\" in x]\n",
    "        np.random.shuffle(Undamagednuclei)\n",
    "        Undamagednuclei=Undamagednuclei[:10000]\n",
    "        self.imgDir= Damagednuclei+Undamagednuclei\n",
    "        size80=[]\n",
    "        for x in self.imgDir:\n",
    "            img = Image.open(x) # Open image\n",
    "            w,h=img.size\n",
    "            if w<=80 and h<=80:\n",
    "                size80.append(x)\n",
    "        self.imgDir=size80              \n",
    "        \n",
    "        self.imgs = sorted(self.imgDir) # list of images\n",
    "\n",
    "        \n",
    "\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.imgs[idx]\n",
    "       \n",
    "        # Transform images into tensors\n",
    "        img = Image.open(img_path) # Open image\n",
    "        w,h=img.size\n",
    "        img = np.array(img) # Convert image into an array\n",
    "        img = np.float32(np.divide(img, 2**16)) # Ensure all values are floats\n",
    "        \n",
    "        result=np.zeros((80,80), dtype=np.float32)\n",
    "        x_center = (80 - w) // 2\n",
    "        y_center = (80 - h) // 2 # copy img image into center of result image\n",
    "        result[y_center:y_center+h, x_center:x_center+w] = img\n",
    "        img = result\n",
    "        \n",
    "        targetlab=\"\"\n",
    "        if img_path.find('No_damage_nuclei') != -1:\n",
    "            targetlab= 'Undamaged'\n",
    "        if img_path.find('Damaged_nuclei_') != -1:\n",
    "            targetlab= 'Damaged'  # Find labels corresponding to image\n",
    "        target = self.labels.index(targetlab) # Get the label and assign to a value\n",
    "        \n",
    "        # Convert label to tensor\n",
    "        #torch.to\n",
    "        \n",
    "        if self.transforms is not None:\n",
    "            img = self.transforms(img)\n",
    "#             #print('In the transforms')\n",
    "        imNo = idx\n",
    "        return img, target, imNo\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.imgs)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "root=\"/workspace/myFile/Output/17052023/\"\n",
    "p= glob.glob(root+\"*/*.tiff\")\n",
    "Damagednuclei= [x for x in p if 'Damaged_nuclei_' in x]\n",
    "Undamagednuclei= [x for x in p if \"No_damage_nuclei\" in x]\n",
    "#np.random.shuffle(Undamagednuclei)\n",
    "#Undamagednuclei=Undamagednuclei[:10000]\n",
    "#Undamagednuclei"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "imDr = \"/workspace/myFile/Output/17052023/\"  # Image patches directory\n",
    "\n",
    "labels = ['Damaged', 'Undamaged']  # Your labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For data augmentation\n",
    "def get_transform(train):\n",
    "    transforms = []\n",
    "\n",
    "    transforms.append(T.ToTensor())\n",
    "    transforms.append(T.Normalize([0.0019368887995516483], [0.00672996630111016]))\n",
    "    #transforms.append(T.RandomHorizontalFlip(0.5))\n",
    "    \n",
    "    if train:\n",
    "        transforms.append(T.RandomHorizontalFlip())\n",
    "        transforms.append(T.RandomVerticalFlip())\n",
    "    \n",
    "    return T.Compose(transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, scheduler, dataloaderTrain, dataloaderTest, num_epochs=25):\n",
    "    since = time.time()\n",
    "    # Create a temporary directory to save training checkpoints\n",
    "    with TemporaryDirectory() as tempdir:\n",
    "        best_model_params_path = os.path.join(tempdir, 'best_model_params.pt')\n",
    "\n",
    "        torch.save(model.state_dict(), best_model_params_path)\n",
    "        best_acc = 0.0\n",
    "\n",
    "        for epoch in range(num_epochs):\n",
    "            print(f'Epoch {epoch}/{num_epochs - 1}')\n",
    "            print('-' * 10)\n",
    "\n",
    "            # Each epoch has a training and validation phase\n",
    "            for phase in ['train', 'val']:\n",
    "                if phase == 'train':\n",
    "                    model.train()  # Set model to training mode\n",
    "                    dataloaders = dataloaderTrain\n",
    "                else:\n",
    "                    model.eval()   # Set model to evaluate mode\n",
    "                    dataloaders = dataloaderTest\n",
    "\n",
    "                running_loss = 0.0\n",
    "                running_corrects = 0\n",
    "\n",
    "                # Iterate over data.\n",
    "                for inputs, labels, imNo in dataloaders:\n",
    "                    inputs = inputs.to(device)\n",
    "                    labels = labels.to(device)\n",
    "\n",
    "                    # zero the parameter gradients\n",
    "                    optimizer.zero_grad()\n",
    "\n",
    "                    # forward\n",
    "                    # track history if only in train\n",
    "                    with torch.set_grad_enabled(phase == 'train'):\n",
    "                        outputs = model(inputs)\n",
    "                        _, preds = torch.max(outputs, 1)\n",
    "                        loss = criterion(outputs, labels)\n",
    "                        # backward + optimize only if in training phase\n",
    "                        if phase == 'train':\n",
    "                            loss.backward()\n",
    "                            optimizer.step()\n",
    "\n",
    "                    # statistics\n",
    "                    running_loss += loss.item() * inputs.size(0)    # Loss\n",
    "                    running_corrects += torch.sum(preds == labels.data) # Accuracy\n",
    "\n",
    "                if phase == 'train':\n",
    "                    scheduler.step()\n",
    "\n",
    "                epoch_loss = running_loss / dataset_sizes[phase]    # Loss metric per epoch\n",
    "                epoch_acc = running_corrects.double() / dataset_sizes[phase]    # Accuracy metric per epoch\n",
    "\n",
    "                if phase == \"train\":    # This is the tensorboard code that writes accuracy and loss metrics\n",
    "                    writer.add_scalar(\"Train/Accuracy\", epoch_acc, epoch)\n",
    "                    writer.add_scalar(\"Train/Loss\", epoch_loss, epoch)\n",
    "                else:\n",
    "                    writer.add_scalar(\"Validation/Accuracy\", epoch_acc, epoch)\n",
    "                    writer.add_scalar(\"Validation/Loss\", epoch_loss, epoch)\n",
    "\n",
    "                print(f'{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n",
    "\n",
    "                # deep copy the model\n",
    "                if phase == 'val' and epoch_acc > best_acc: \n",
    "                    # This compares validation accuracy to previous bests and adjusts model weights accordingly\n",
    "                    best_acc = epoch_acc\n",
    "                    torch.save(model.state_dict(), best_model_params_path)\n",
    "\n",
    "            print()\n",
    "\n",
    "        time_elapsed = time.time() - since  # Nice way to measure training time but info also stored (indirectly) by tensorboard\n",
    "        print(\n",
    "            f'Training complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')\n",
    "        print(f'Best val Acc: {best_acc:4f}')\n",
    "        labels= labels.cpu().numpy()\n",
    "        preds=preds.cpu().numpy()\n",
    "        con_mat = confusion_matrix(labels, preds)   # Confusion matrix compares true class with predicted class\n",
    "        # load best model weights\n",
    "        model.load_state_dict(torch.load(best_model_params_path))\n",
    "    writer.close()\n",
    "    return model, con_mat   # We want to return the model because its the model, also confusion matrix for later analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is your RESNET\n",
    "# Initialize CNN with kaiming\n",
    "def init_cnn(m):\n",
    "    # Set the weights of the RESNET\n",
    "    if getattr(m, 'bias', None) is not None: nn.init.constant_(m.bias, 0)\n",
    "    if isinstance(m, (nn.Conv2d,nn.Linear)): nn.init.kaiming_normal_(m.weight)\n",
    "    for l in m.children(): init_cnn(l)\n",
    "\n",
    "\n",
    "# noop function for returning nothing\n",
    "def noop(x): return x\n",
    "# activation function(RELU)\n",
    "act_fn = nn.ReLU(inplace=True)\n",
    "\n",
    "# Flatten\n",
    "class Flatten(nn.Module):\n",
    "    def forward(self, x): return x.view(x.size(0), -1)\n",
    "\n",
    "# Make a convolution\n",
    "def conv(ni, nf, ks=3, stride=1, bias=False):\n",
    "    return nn.Conv2d(ni, nf, kernel_size=ks, stride=stride, padding=ks//2, bias=bias)\n",
    "\n",
    "# Create a convuolutional layer with convolution and batch norm\n",
    "def conv_layer(ni, nf, ks=3, stride=1, zero_bn=False, act=True):\n",
    "    bn = nn.BatchNorm2d(nf) # get a 2d batch norm from Pytorhc\n",
    "    nn.init.constant_(bn.weight, 0. if zero_bn else 1.)\n",
    "    layers = [conv(ni, nf, ks, stride=stride), bn]\n",
    "    if act: layers.append(act_fn) # add in the activation function if act is true\n",
    "    return nn.Sequential(*layers)\n",
    "\n",
    "\n",
    "# Resblock\n",
    "class ResBlock(nn.Module):\n",
    "    def __init__(self, expansion, ni, nh, stride = 1):\n",
    "        super().__init__()\n",
    "        # ni - number of inputs channels, nf - number of filters\n",
    "        # nh - number of filters in first conv\n",
    "        # expansion is 1 for resnet 18, 34 and 4 for larger networks\n",
    "        nf, ni = nh*expansion, ni*expansion\n",
    "        layers = [conv_layer(ni, nh, 3, stride = stride), # for resnet < 34 2 convs per resblock\n",
    "                 conv_layer(nh, nf, 3, zero_bn = True, act = False)\n",
    "                 ] if expansion == 1 else [ # for RESNET > 34 then 3 convs per block with bottleneck\n",
    "                            conv_layer(ni, nh, 1),\n",
    "                            conv_layer(nh, nh, 3, stride = stride),\n",
    "                            conv_layer(nh, nf, 1, zero_bn = True, act = False)\n",
    "        ]\n",
    "        self.convs = nn.Sequential(*layers) # Creates the conv layers\n",
    "        self.idconv = noop if ni==nf else conv_layer(ni, nf, 1, act = False) # id convolution ()\n",
    "        self.pool = noop if stride== 1 else nn.AvgPool2d(2, ceil_mode = True) # average pool on \n",
    "        \n",
    "    def forward(self, x): \n",
    "        # Forward function adds the convolution part to the id part \n",
    "        #return act_fn(self.convs(x)) + self.idconv(self.pool(x))\n",
    "        return act_fn(self.convs(x) + self.idconv(self.pool(x)))\n",
    "\n",
    "# XResnet\n",
    "class XResNet(nn.Sequential):\n",
    "    @classmethod\n",
    "    def create(cls, expansion, layers, c_in=3, c_out=1000):\n",
    "        nfs = [c_in, (c_in + 1)*8, 64, 64] # number of filters in stem layer (c_in is number of image channels)\n",
    "        stem = [conv_layer(nfs[i], nfs[i+1], stride=2 if i==0 else 1)\n",
    "            for i in range(3)]\n",
    "\n",
    "        nfs = [64//expansion,64,128,256,512]\n",
    "        res_layers = [cls._make_layer(expansion, nfs[i], nfs[i+1],\n",
    "                                      n_blocks=l, stride=1 if i==0 else 2)\n",
    "                  for i,l in enumerate(layers)]\n",
    "        res = cls(\n",
    "        *stem,\n",
    "        nn.MaxPool2d(kernel_size=3, stride = 2, padding = 1), # then a max pooling layer\n",
    "        *res_layers,\n",
    "        nn.AdaptiveAvgPool2d(1), Flatten(), \n",
    "        nn.Linear(nfs[-1]*expansion, c_out)\n",
    "        )\n",
    "        init_cnn(res)\n",
    "        return res\n",
    "        \n",
    "    @staticmethod\n",
    "    def _make_layer(expansion, ni, nf, n_blocks, stride): # returns a resblock\n",
    "        return nn.Sequential(\n",
    "        *[ResBlock(expansion, ni if i==0 else nf, nf, stride if i==0 else 1)\n",
    "         for i in range(n_blocks)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def xresnet18 (**kwargs): return XResNet.create(1, [2, 2,  2, 2], **kwargs)\n",
    "def xresnet34 (**kwargs): return XResNet.create(1, [3, 4,  6, 3], **kwargs)\n",
    "def xresnet50 (**kwargs): return XResNet.create(4, [3, 4,  6, 3], **kwargs)\n",
    "model = xresnet18(c_in = 1, c_out = 2)\n",
    "#model = xresnet34(c_in = 1, c_out = 2)\n",
    "#model = xresnet50(c_in = 1, c_out = 2)\n",
    "model = model.to(device)\n",
    "\n",
    "# Label smoothing cross entropy\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "def reduce_loss(loss, reduction='mean'):\n",
    "    return loss.mean() if reduction=='mean' else loss.sum() if reduction=='sum' else loss\n",
    "\n",
    "class LabelSmoothingCrossEntropy(nn.Module):\n",
    "    def __init__(self, ε:float=0.1, reduction='mean'):\n",
    "        super().__init__()\n",
    "        self.ε,self.reduction = ε,reduction\n",
    "    \n",
    "    def forward(self, output, target):\n",
    "        c = output.size()[-1]\n",
    "        log_preds = F.log_softmax(output, dim=-1)\n",
    "        loss = reduce_loss(-log_preds.sum(dim=-1), self.reduction)\n",
    "        nll = F.nll_loss(log_preds, target, reduction=self.reduction)\n",
    "        return lin_comb(loss/c, nll, self.ε)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions that shows the image, true class, predicted class and degree of prediction\n",
    "\n",
    "def images_to_probs(net, images):\n",
    "    '''\n",
    "    Generates predictions and corresponding probabilities from a trained\n",
    "    network and a list of images\n",
    "    '''\n",
    "    output = net(images)\n",
    "    # convert output probabilities to predicted class\n",
    "    _, preds_tensor = torch.max(output, 1)\n",
    "    preds = np.squeeze(preds_tensor.numpy())\n",
    "    return preds, [F.softmax(el, dim=0)[i].item() for i, el in zip(preds, output)]\n",
    "\n",
    "\n",
    "def plot_classes_preds(net, images, labels):\n",
    "    '''\n",
    "    Generates matplotlib Figure using a trained network, along with images\n",
    "    and labels from a batch, that shows the network's top prediction along\n",
    "    with its probability, alongside the actual label, coloring this\n",
    "    information based on whether the prediction was correct or not.\n",
    "    Uses the \"images_to_probs\" function.\n",
    "    '''\n",
    "    preds, probs = images_to_probs(net, images)\n",
    "    # plot the images in the batch, along with predicted and true labels\n",
    "    fig = plt.figure(figsize=(12, 48))\n",
    "    for idx in np.arange(4):\n",
    "        ax = fig.add_subplot(1, 4, idx+1, xticks=[], yticks=[])\n",
    "        matplotlib_imshow(images[idx], one_channel=True)\n",
    "        ax.set_title(\"{0}, {1:.1f}%\\n(label: {2})\".format(\n",
    "            labels[preds[idx]],\n",
    "            probs[idx] * 100.0,\n",
    "            labels[labels[idx]]),\n",
    "                    color=(\"green\" if preds[idx]==labels[idx].item() else \"red\"))\n",
    "    return fig\n",
    "\n",
    "def matplotlib_imshow(img, one_channel=True):\n",
    "    if one_channel:\n",
    "        img = img.mean(dim=0)\n",
    "    img = img / 2 + 0.5     # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    if one_channel:\n",
    "        plt.imshow(npimg, cmap=\"Greys\")\n",
    "    else:\n",
    "        plt.imshow(np.transpose(npimg, (1, 2, 0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def confusion_matrix_calc(data_loader_test, classes, model_ft):       \n",
    "        y_pred = []\n",
    "        y_true = []\n",
    "        for inputs, labels, imNo in data_loader_test:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "                output = model_ft(inputs) # Feed Network\n",
    "\n",
    "                output = (torch.max(torch.exp(output), 1)[1]).data.cpu().numpy()\n",
    "                y_pred.extend(output) # Save Prediction\n",
    "                \n",
    "                labels = labels.data.cpu().numpy()\n",
    "                y_true.extend(labels) # Save Truth\n",
    "\n",
    "        # constant for classes\n",
    "        # classes = ('Alive', 'Dead')\n",
    "\n",
    "        # Build confusion matrix\n",
    "        cf_matrix = confusion_matrix(y_true, y_pred)\n",
    "        return cf_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13908, {'train': 13908, 'val': 5961})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(10)\n",
    "imIdx = torch.randperm(101106).tolist()\n",
    "\n",
    "## Create dataset\n",
    "dataSetTrain = DNADataset(imDr, get_transform(train = True), labels, imDx=imIdx)\n",
    "dataSetTest = DNADataset(imDr, get_transform(train = False), labels, imDx=imIdx)\n",
    "\n",
    "# ## Create dataloaders\n",
    "# Get subset\n",
    "torch.manual_seed(10)\n",
    "indices = torch.randperm(len(dataSetTrain)).tolist()\n",
    "\n",
    "noTrain = int(len(dataSetTrain)*0.7)\n",
    "\n",
    "dataset_train = torch.utils.data.Subset(dataSetTrain, indices[-noTrain:])\n",
    "dataset_test = torch.utils.data.Subset(dataSetTest, indices[:-noTrain])\n",
    "#len(indices), len(indices[:-50]), len(indices[-50:]), 50/191, type(dataset_test)\n",
    "\n",
    "dataset_sizes = {'train': len(dataset_train), 'val': len(dataset_test)}\n",
    "\n",
    "# define training and validation data loaders\n",
    "data_loader_train = torch.utils.data.DataLoader(\n",
    "    dataset_train, batch_size=20, shuffle=True, num_workers=0)\n",
    "\n",
    "data_loader_test = torch.utils.data.DataLoader(\n",
    "    dataset_test, batch_size=1, shuffle=False, num_workers=0)\n",
    "\n",
    "\n",
    "# Collate function (gathers together the outputs)\n",
    "# def collate_fn(batch):\n",
    "#     return tuple(zip(*batch))\n",
    "\n",
    "len(indices[-noTrain:]), dataset_sizes\n",
    "#dataset_test[0][1], dataset_test[3][1], dataset_test[-1][1], dataSetTrain.imgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_weights= [0.92486,0.075135] #1-(#inclass/ #intotal )\n",
    "class_weights = torch.Tensor(class_weights)\n",
    "class_weights=class_weights.to(device)\n",
    "criterion = nn.CrossEntropyLoss(weight = class_weights)\n",
    "\n",
    "# Observe that all parameters are being optimized\n",
    "optimizer_ft = optim.Adam(model.parameters(), weight_decay=1e-2) # standard ADAM optimiser\n",
    "\n",
    "# Decay LR by a factor of 0.1 every 7 epochs\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/4\n",
      "----------\n",
      "train Loss: 0.2541 Acc: 0.5035\n",
      "val Loss: 1.6559 Acc: 0.4914\n",
      "\n",
      "Epoch 1/4\n",
      "----------\n",
      "train Loss: 0.2429 Acc: 0.4994\n",
      "val Loss: 0.7855 Acc: 0.4915\n",
      "\n",
      "Epoch 2/4\n",
      "----------\n",
      "train Loss: 0.2369 Acc: 0.4992\n",
      "val Loss: 0.6614 Acc: 0.4915\n",
      "\n",
      "Epoch 3/4\n",
      "----------\n",
      "train Loss: 0.2305 Acc: 0.4992\n",
      "val Loss: 0.7734 Acc: 0.4915\n",
      "\n",
      "Epoch 4/4\n",
      "----------\n",
      "train Loss: 0.2306 Acc: 0.4992\n",
      "val Loss: 0.8893 Acc: 0.4915\n",
      "\n",
      "Training complete in 6m 8s\n",
      "Best val Acc: 0.491528\n"
     ]
    }
   ],
   "source": [
    "model_ft, con_mat = train_model(model, criterion, optimizer_ft, exp_lr_scheduler,\n",
    "                       data_loader_train,data_loader_test,num_epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "cf_matrix = confusion_matrix_calc(data_loader_test, labels, model_ft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x504 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_cm_ratio = pd.DataFrame(cf_matrix / np.sum(cf_matrix, axis=1)[:, None], index=[i for i in labels],\n",
    "                     columns=[i for i in labels])\n",
    "plt.figure(figsize=(12, 7))\n",
    "sn.heatmap(df_cm_ratio, annot=True)\n",
    "# plt.save(\"Confusion_matrix_ratio.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAosAAAGcCAYAAACx0eqpAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAAozUlEQVR4nO3deZhcZZX48e9JE9YIBAhbEiBssii7gIPMsCjbqKAiggiR0QkiKKKOijKyjygjDCgGoyDooMi4sYhCRETxJ5IgyC6EECBNFsImi5B0+vz+qBuohFSncunqqs79fnju03XfulX3VD/p5vQ5931vZCaSJEnS4gxpdwCSJEnqXCaLkiRJashkUZIkSQ2ZLEqSJKkhk0VJkiQ1ZLIoSZKkhpZr9QnmTpvs2jySmrLy5ge2OwRJg0TP3O5odwzz5kzttxxn6Fob9/l5ImJF4PfACtTyt59k5skRMQa4HFgTuA04IjPnRsQKwPeBHYEngQ9k5rTivU4EPgLMBz6Zmdf1dW4ri5IkSZ3vZWCvzNwW2A7YLyJ2Bb4KnJuZmwJPU0sCKb4+XYyfWxxHRGwFHApsDewHfCsiuvo6scmiJElSGb3z+29bgqx5vtgdWmwJ7AX8pBi/FDioeHxgsU/x/N4REcX45Zn5cmY+DEwBdu7r3CaLkiRJZWRv/21NiIiuiLgDmA1MBB4CnsnMnuKQ6cDI4vFI4DGA4vlnqbWqXxlfzGsWy2RRkiSpzSJiXERMrtvGLXpMZs7PzO2AUdSqgVsMRGwtn+AiSZK0TOptriLYjMycAExo8thnIuJG4K3A6hGxXFE9HAV0F4d1A6OB6RGxHLAatYkuC8YXqH/NYllZlCRJKiGzt9+2JYmIERGxevF4JeAdwH3AjcDBxWFjgSuLx1cV+xTP/zYzsxg/NCJWKGZSbwbc2te5rSxKkiR1vvWAS4uZy0OAKzLzmoi4F7g8Is4AbgcuKo6/CPhBREwBnqI2A5rMvCcirgDuBXqAYzOzzxk2UUsyW8d1FiU1y3UWJTWrE9ZZnDv9rn7LcZYf9ea2f55GrCxKkiSV0eQs5sHOaxYlSZLUkJVFSZKkMppYTHtZYLIoSZJUhm1oSZIkVZ2VRUmSpDL6cVHuTmayKEmSVEIzi2kvC2xDS5IkqSEri5IkSWXYhpYkSVJDtqElSZJUdVYWJUmSynBRbkmSJDVkG1qSJElVZ2VRkiSpDGdDS5IkqSHb0JIkSao6K4uSJEll2IaWJElSI5nVWDrHNrQkSZIasrIoSZJURkUmuJgsSpIkleE1i5IkSWqoIpVFr1mUJElSQ1YWJUmSyuitxmxok0VJkqQybENLkiSp6qwsSpIkleFsaEmSJDVkG1qSJElVZ2VRkiSpDNvQkiRJaqgiyaJtaEmSJDVkZVGSJKmETBflliRJUiO2oSVJklR1VhYlSZLKqMg6iyaLkiRJZdiGliRJUtVZWZQkSSrDNrQkSZIasg0tSZKkqrOyKEmSVIZtaEmSJDVkG1qSJElVZ2VRkiSpjIpUFk0WJUmSyqjINYu2oSVJktSQlUVJkqQybENLkiSpIdvQkiRJqjori5IkSWXYhpYkSVJDtqElSZJUdSaLkiRJZfT29t+2BBExOiJujIh7I+KeiDi+GD8lIroj4o5iO6DuNSdGxJSI+FtE7Fs3vl8xNiUivrCkc9uGliRJKmNgr1nsAT6TmX+JiDcAt0XExOK5czPzv+sPjoitgEOBrYH1gd9ExObF0xcA7wCmA5Mi4qrMvLfRiU0WJUmSOlxmzgBmFI+fi4j7gJF9vORA4PLMfBl4OCKmADsXz03JzKkAEXF5cWzDZNE2tCRJUhmZ/bcthYjYCNge+HMxdFxE3BkRF0fE8GJsJPBY3cumF2ONxhsyWZQkSSqjH69ZjIhxETG5bhu3uFNGxDDgp8CnMvPvwHhgE2A7apXHr/f3x7QNLUmS1GaZOQGY0NcxETGUWqJ4WWb+rHjdrLrnvwNcU+x2A6PrXj6qGKOP8cWysihJklTGwM6GDuAi4L7MPKdufL26w94D3F08vgo4NCJWiIgxwGbArcAkYLOIGBMRy1ObBHNVX+e2sihJklTGwC7KvRtwBHBXRNxRjH0ROCwitgMSmAYcDZCZ90TEFdQmrvQAx2bmfICIOA64DugCLs7Me/o6scmiJElSh8vMm4FYzFPX9vGaM4EzFzN+bV+vW5TJoiRJUhneG1qSJEkNLeWSN4NVn8liRHyDWg98sTLzk/0ekSRJkjrGkmZDTwZuA1YEdgAeLLbtgOVbGpkkSVInG8DZ0O3UZ2UxMy8FiIhjgLdlZk+xfyHwh9aHJ0mS1KE6PMnrL82uszgcWLVuf1gxJkmSpGVYsxNczgJuj4gbqU3b/mfglFYFJUmS1PEGdp3FtmkqWczM70XEr4BdiqHPZ+bM1oUlSZLU2bK3GrOhm2pDF7eYeTuwbWZeCSwfETu3NDJJkiS1XbPXLH4LeCtwWLH/HHBBSyKSJEkaDJwNvZBdMnOHiLgdIDOfLm4+LUmSVE0VuWax2crivIjooligOyJGANX4DkmSJFVYs5XF84GfA2tHxJnAwcBJLYtKkiSp01Vkgkuzs6Evi4jbgL2pLZ1zUGbe19LIJEmSOlmHX2vYX5pKFiNiDWA28KO6saGZOa9VgUmSJHW0iiSLzV6z+BfgCeABaveGfgKYFhF/iYgdWxWcJEmS2qvZZHEicEBmrpWZawL7A9cAH6e2rI4kSVK1ZPbf1sGaTRZ3zczrFuxk5vXAWzPzFmCFlkQmSZLUyVxncSEzIuLzwOXF/geAWcVyOp39CfW6zZz9JF88ezxPPvMsQXDwAXvxoffst9Axzz73Al8+ZwKPzZjFCkOHctpnxrHZRqNf13nnzp3HF88ez70PTmP1VYdx9hc/wch1R3DX/Q9x6nnfBWp/jH38iPey925veV3nktR59t1nD8455zS6hgzh4u/9iK+d7b0gpHZotrL4QWAU8Iti26AY6wIOaUVg6hxdXUP47LjDufI7Z3PZeady+dUTeeiR6Qsd893Lr2SLTTbgZxeexZn/cQxfHf+Dpt+/e+YTHPUfZ7xm/GfX/Y5Vh63CtZecwxHv3Z9zL6rNr9p0o1Fc/s0z+Mn4r3DhmZ/jtPMupmf+/Nf3ISV1lCFDhnD+eWfyznd9iDdvuycf+MBBbLnlZu0OS1pYb/bf1sGaXTpnDvCJBk9P6b9w1IlGrDmcEWsOB2CVlVdizOj1mTXnaTbZcNQrxzz0aDcfOeRdAGy8wfp0z3qCOU8/y1rDV+PqG27mh7+4jnk9Pbx5i0056bij6Opa8t8pN/7pNo750PsAeMfuO/NfF1xCZrLSiq9e+fDyvHm1xZwkLVN2fsv2PPTQNB5++FEArrjiSt79rn25774H2xyZVMc7uLwqIkZExNkRcW1E/HbB1urg1Hm6Zz7B/Q89wjZbbLLQ+BvHbMBv/jgJgLvuf4gZs+Ywa85TTH20m+tuuoXvn3syPxn/FbqGDOGXv/1jU+eaPedp1h2xBgDLdXUxbJWVeebvzwNw5/1TOOjfP8d7j/4CX/7kv7FcV1c/fkpJ7bb+yHV5bPrjr+xP757B+uuv28aIpOpq9prFy4AfA+8EPgaMpbZ8jirkxX+8xAmn/w+f/9gRDFtl5YWe+8gH3sVZ43/AwcecyGZjRrPFphvRNSS45fZ7uPfBhznsE/8JwMtz57HG6qsCcPyp59I9czbzenqYMftJDj7mRAAOP2g/3rPvv/QZyzZbbMovvvM1pj7azZfOvpC3vWVbVlje25VLkgZQh7eP+0uzyeKamXlRRByfmTcBN0XEpEYHR8Q4YBzABWeeyEc/+N5+CFXtNK+nhxNO/x/+da/dePvbXjuZZNgqK3PGZ48GIDPZb+ynGLXu2tx299949zt251P/duhrXnPeyScAtWrlSV//Nt87e+E7SK691nBmPvEU645Yk57583n+hRdZfdVhCx2z8QYjWXmlFZkybTpbb75xf31cSW32ePdMRo9a/5X9USPX4/HHZ7YxIum1ssNnMfeXZie4LLhTy4yI+NeI2B5Yo9HBmTkhM3fKzJ1MFAe/zOTkc77DxqNHMvZ9Byz2mL8//wLz5vUA8NNf3ciOb9qCYauszK7bbc3EP9zKk888C8Czf3+ex2c1V5TeY9cduGri7wGY+Idb2XnbrYkIps+c/cqElsdnPcHDjz3O+uuMeL0fU1IHmTT5DjbddAwbbTSaoUOHcsghB3L1Nde3OyypkpqtLJ4REasBnwG+AawKnNCyqNRRbr/nAa6+4WY2GzP6lVbxJ4/6ADNnzwHgkHe+namPPs5J/30hEcEmG47k1BPGAbDJhqP4xNj3c/SJZ9GbyXJdXXzpuA83ldy9d789OPFr4zngw59mtTeswte+WJtjdfvdf+OiH1/Ncst1MWTIEL70iaMYvtobWvTpJbXD/PnzOf5TJ3HtL39I15AhXHLpj7n33gfaHZa0sIq0oSNbvGr43GmTq/GdlPS6rbz5ge0OQdIg0TO3u+1rYbxwxof6LcdZ5aT/bfvnaaSpymJEjKG2dM5G9a/JzHe3JixJkiR1gmbb0L8ALgKuxju2SJIkVaYN3Wyy+FJmnt/SSCRJkgaTisyGbjZZPC8iTgauB15eMJiZf2lJVJIkSeoIzSaLbwaOAPbi1TZ0FvuSJEnVYxt6Ie8HNs7Mua0MRpIkadDw3tALuRtYvYVxSJIkqQM1W1lcHbi/uMVf/TWLLp0jSZKqyTb0Qk5uaRSSJEmDTFXuDd1UspiZN7U6EEmSJHWepq5ZjIhdI2JSRDwfEXMjYn5E/L3VwUmSJHWs3uy/rYM124b+JnAo8H/ATsCRwOatCkqSJKnjdXiS11+anQ1NZk4BujJzfmZ+D9ivdWFJkiSpEzRbWXwxIpYH7oiIrwEzWIpEU5IkaZnjOosLOaI49jjgBWA08L5WBSVJktTxvGbxVZn5SESMKB6f2tqQJEmS1Cn6rCxGzSkRMQf4G/BARDwREV8emPAkSZI6U/Zmv22dbElt6BOA3YC3ZOYamTkc2AXYLSJOaHl0kiRJnaoibeglJYtHAIdl5sMLBjJzKvAhasvnSJIkaRm2pGsWh2bmnEUHM/OJiBjaopgkSZI6n7f7A2BuyeckSZKWbR3ePu4vS0oWt21wW78AVmxBPJIkSeogfSaLmdk1UIFIkiQNKlYWJUmS1EhmNZJFb9knSZKkhqwsSpIklWEbWpIkSQ1VJFm0DS1JktThImJ0RNwYEfdGxD0RcXwxvkZETIyIB4uvw4vxiIjzI2JKRNwZETvUvdfY4vgHI2Lsks5tsihJklTCAN8bugf4TGZuBewKHBsRWwFfAG7IzM2AG4p9gP2BzYptHDAeasklcDK12zfvDJy8IMFsxGRRkiSpjAG8N3RmzsjMvxSPnwPuA0YCBwKXFoddChxUPD4Q+H7W3AKsHhHrAfsCEzPzqcx8GpgI7NfXuU0WJUmSBpGI2AjYHvgzsE5mziiemgmsUzweCTxW97LpxVij8YZMFiVJksro7b8tIsZFxOS6bdziThkRw4CfAp/KzIXuspe1hR/7fdaNs6ElSZJKaPJaw+beK3MCMKGvYyJiKLVE8bLM/FkxPCsi1svMGUWbeXYx3g2Mrnv5qGKsG9hjkfHf9XVeK4uSJEkdLiICuAi4LzPPqXvqKmDBjOaxwJV140cWs6J3BZ4t2tXXAftExPBiYss+xVhDVhYlSZLKGNh1FncDjgDuiog7irEvAmcBV0TER4BHgEOK564FDgCmAC8CRwFk5lMRcTowqTjutMx8qq8TmyxKkiSV0Ttwp8rMm4Fo8PTeizk+gWMbvNfFwMXNnts2tCRJkhqysihJklRCf05w6WQmi5IkSWUMYBu6nWxDS5IkqSEri5IkSSXYhpYkSVJjFWlDmyxKkiSVkBVJFr1mUZIkSQ1ZWZQkSSqjIpVFk0VJkqQSbENLkiSp8qwsSpIklVGRyqLJoiRJUgm2oSVJklR5VhYlSZJKqEpl0WRRkiSphKoki7ahJUmS1JCVRUmSpDIy2h3BgDBZlCRJKsE2tCRJkirPyqIkSVIJ2WsbWpIkSQ3YhpYkSVLlWVmUJEkqIZ0NLUmSpEZsQ0uSJKnyrCxKkiSV4GxoSZIkNZTZ7ggGhm1oSZIkNWRlUZIkqQTb0JIkSWqoKsmibWhJkiQ1ZGVRkiSphKpMcDFZlCRJKsE2tCRJkirPyqIkSVIJ3htakiRJDXlvaEmSJFWelUVJkqQSem1DS5IkqZGqXLNoG1qSJEkNWVmUJEkqoSrrLJosSpIklVCVO7jYhpYkSVJDVhYlSZJKsA0tSZKkhqqydI5taEmSJDVkZVGSJKmEqqyzaLIoSZJUgrOhJUmSVHlWFiVJkkqoygQXk0VJkqQSqnLNom1oSZIkNWRlUZIkqQQnuEiSJKmh3ox+25oRERdHxOyIuLtu7JSI6I6IO4rtgLrnToyIKRHxt4jYt258v2JsSkR8YUnnNVmUJEkaHC4B9lvM+LmZuV2xXQsQEVsBhwJbF6/5VkR0RUQXcAGwP7AVcFhxbEMtb0PHsDVafQpJkqQBN9ATXDLz9xGxUZOHHwhcnpkvAw9HxBRg5+K5KZk5FSAiLi+OvbfRG1lZlCRJKqE/29ARMS4iJtdt45YilOMi4s6iTT28GBsJPFZ3zPRirNF4QyaLkiRJbZaZEzJzp7ptQpMvHQ9sAmwHzAC+3t+xORtakiSphE6YDJ2ZsxY8jojvANcUu93A6LpDRxVj9DG+WFYWJUmSShjo2dCLExHr1e2+B1gwU/oq4NCIWCEixgCbAbcCk4DNImJMRCxPbRLMVX2dw8qiJElSCQM9wSUifgTsAawVEdOBk4E9ImI7aoXOacDRtdjynoi4gtrElR7g2MycX7zPccB1QBdwcWbe0+d5s8UrSs6bM7UTqrSSBoGV1t+93SFIGiR65na3/V57f1z34H7LcXab+ZO2f55GrCxKkiSV0NvuAAaIyaIkSVIJSccWA/uVE1wkSZLUkJVFSZKkEnorMivDZFGSJKmEXtvQkiRJqjori5IkSSVUZYKLyaIkSVIJVVk6xza0JEmSGrKyKEmSVIJtaEmSJDVkG1qSJEmVZ2VRkiSphKpUFk0WJUmSSqjKNYu2oSVJktSQlUVJkqQSeqtRWDRZlCRJKsN7Q0uSJKnyrCxKkiSVkO0OYICYLEqSJJVQlaVzbENLkiSpISuLkiRJJfRGNSa4mCxKkiSVUJVrFm1DS5IkqSEri5IkSSVUZYKLyaIkSVIJVbmDi21oSZIkNWRlUZIkqYSq3O7PZFGSJKkEZ0NLkiSp8qwsSpIklVCVCS4mi5IkSSVUZekc29CSJElqyMqiJElSCVWZ4GKyKEmSVEJVrlm0DS1JkqSGrCxKkiSVUJUJLiaLkiRJJVQlWbQNLUmSpIasLEqSJJWQFZngYrIoSZJUgm1oSZIkVZ6VRUmSpBKqUlk0WZQkSSqhKndwsQ0tSZKkhqwsSpIklVCV2/2ZLEqSJJVQlWsWbUNLkiSpISuLkiRJJVSlsmiyKEmSVIKzoSVJklR5VhYlSZJKcDa0JEmSGqrKNYu2oSVJkkrIftyaEREXR8TsiLi7bmyNiJgYEQ8WX4cX4xER50fElIi4MyJ2qHvN2OL4ByNi7JLOa7IoSZI0OFwC7LfI2BeAGzJzM+CGYh9gf2CzYhsHjIdacgmcDOwC7AycvCDBbMRkUZIkqYRest+2ZmTm74GnFhk+ELi0eHwpcFDd+Pez5hZg9YhYD9gXmJiZT2Xm08BEXpuALsRrFiVJkkrokGsW18nMGcXjmcA6xeORwGN1x00vxhqNN2RlUZIkqc0iYlxETK7bxi3te2Tm0lwC2TQri5IkSSX0Z1aWmROACSVeOisi1svMGUWbeXYx3g2MrjtuVDHWDeyxyPjv+jqBlUVJkqQSevtxex2uAhbMaB4LXFk3fmQxK3pX4NmiXX0dsE9EDC8mtuxTjDXUZ2UxIp6jj8Q5M1dt6mNIkiTpdYmIH1GrCq4VEdOpzWo+C7giIj4CPAIcUhx+LXAAMAV4ETgKIDOfiojTgUnFcadl5qKTZhbSZ7KYmW8ogjsdmAH8AAjgcGC9pfuIkiRJy46BvoNLZh7W4Km9F3NsAsc2eJ+LgYubPW+z1yy+OzO3rdsfHxF/Bb7c7IkkSZKWJc0ueTPYNXvN4gsRcXhEdEXEkIg4HHihlYFJkiSp/ZpNFj9IrQc+q9jeX4xJkiRV0kDf7q9dmmpDZ+Y0aiuBS5IkiY5ZlLvlmqosRsTmEXHDghtXR8Q2EXFSa0OTJElSuzXbhv4OcCIwDyAz7wQObVVQkiRJnW6g7w3dLs3Ohl45M2+NWGiOeE8L4pEkSRoUOjvF6z/NVhbnRMQmFN+XiDiY2rqLkiRJWoY1W1k8ltr9CreIiG7gYeBDLYtKkiSpw1Vlgkuzs6GnAm+PiFWAIZn5XGvDkiRJ6mydfq1hf2kqWYyITy+yD/AscFtm3tH/YUmSJKkTNNuG3qnYri723wncCXwsIv4vM7/WiuAkSZI6VTXqis0ni6OAHTLzeYCIOBn4JfDPwG2AyaIkSaqUqlyz2Oxs6LWBl+v25wHrZOY/FhmXJEnSMqTZyuJlwJ8j4spi/13AD4sJL/e2JDJJkqQOlhVpRDc7G/r0iPg18E/F0Mcyc3Lx+PCWRCZJktTBqtKGbraySGZOiohHgBUBImKDzHy0ZZFJkiSp7ZpdOufdwNeB9YHZwAbA/cDWrQtNkiSpc1VlncVmJ7icDuwKPJCZY4C3A7e0LCpJkqQOl/24dbJmk8V5mfkkMCQihmTmjdTWXZQkSdIyrNlrFp+JiGHA74HLImI28ELrwpIkSepsVWlDN5ssHgi8BJxAbfbzasBprQpKne/ll+cy9tj/YO68eczvmc879nwbx330iNf1nt/5/o/52TXX0TVkCCeecAy77bJjS84jaXDYd589OOec0+gaMoSLv/cjvnb2Be0OSVqIs6HrZOYLABGxKq/e8k8VtvzyQ7n4/LNYeeWVmNfTw5HHfJbdd92Jbd+05RJfu8/7xnL9Ty9daOyhhx/hVzfcxJX/eyGz5zzFR48/kV9e/t3XdR5Jg9eQIUM4/7wz2e+Aw5g+fQa3/Olarr7meu6778F2hyZVTrOzoY8GTqVWXewFgtr1mBu3LjR1sohg5ZVXAqCnp4eenh4ignvuf5CzvzGBF//xEquvtipnfukzjFhrjSW+32//cAv77/0vLL/88oxaf102GLU+d933ANu9acvFnkfSsm3nt2zPQw9N4+GHayu0XXHFlbz7XfuaLKqjuCj3wj4LvCkz57QyGA0u8+fP55B/+ySPdj/OYe99J1u+cVM+fOzn+MZZX2aN4avzq9/cxHkTLuGML356ie81+4kn2eZNW7yyv87aazH7iTmLPc82W2/R6G0kLSPWH7kuj01//JX96d0z2Pkt27cxIum1bEMv7CHgxVYGosGnq6uLn156AX9/7nmOP/F0pj06nSlTp/Hvn/oSAL29vay15nAAvn3pj7j+tzcDMHvOU7xv7LEAbL/NVpz0mWOX6jwPTp3GZhtv1LoPJkmSXtFssngi8P8i4s/AywsGM/OTizs4IsYB4wC+9fUz+OiRh73eONXBVn3DMHbeYRtuuOn/semYDblswrmvOebosYdx9Njav4N93jeWn1668IXqa49Yk5mznnhlf9bsOaw9Yq3FnufmWyabLErLuMe7ZzJ61Pqv7I8auR6PPz6zjRFJr1WVNnSz6yx+G/gttYW4b6vbFiszJ2TmTpm5k4nisumpp5/h7889D8BLL7/Mnybdzhs33ZinnnmWO+6+D4B5PT1MmfpIU++359t25Vc33MTcuXOZ/vhMHp3+OG/ecvPFnmfMhqNb86EkdYxJk+9g003HsNFGoxk6dCiHHHIgV19zfbvDkhbS249bJ2u2sjg0M5d84Zkq44knn+ZLZ/w383t7yd5k3712Z8/dd2W9dUbwlf+5kOdeeIH5PfM54gMHsenGGy7x/TbdeEP23Wt33n340SzX1cWXPv1xurq6FnuePXbbZQA+oaR2mj9/Psd/6iSu/eUP6RoyhEsu/TH33vtAu8OSKikyl1xCjYj/AqZRWzanvg391JJeO2/O1GrUaCW9biutv3u7Q5A0SPTM7W770hhHbPjefstxfvDIz9r+eRpptrK4oJd8Yt2YS+dIkqTKqko1rNlFuce0OhBJkiR1nmYri0TEm4CtgBUXjGXm91sRlCRJUqfz3tB1IuJkYA9qyeK1wP7AzYDJoiRJqiSXzlnYwcDewMzMPArYFlitZVFJkiSpIzTbhv5HZvZGRE9ErArMBlzsTpIkVVanr4/YX5pNFidHxOrAd6gtxv088KdWBSVJktTpvGaxTmZ+vHh4YUT8Glg1M+9sXViSJEnqBH0mixGxQ1/PZeZf+j8kSZKkzleVCS5Lqix+vfi6IrAT8FcggG2AycBbWxeaJElS56rKNYt9zobOzD0zc09gBrBDZu6UmTsC2wPdAxGgJEmS2qfZCS5vzMy7Fuxk5t0RsWWLYpIkSep4mbah690ZEd8F/rfYPxxwgoskSaosZ0Mv7CjgGOD4Yv/3wPiWRCRJkqSO0ezSOS8B5xabJElS5VVlgkuz94beDTgF2LD+NZm5cWvCkiRJ6mwunbOwi4ATqN29ZX7rwpEkSRocvGZxYc9m5q9aGokkSZI6TrPJ4o0RcTbwM+DlBYPewUWSJFWVS+csbJfi647F1wAS2KvfI5IkSRoEnOACRMSni4fXFF8TeAK4OTMfbmVgkiRJar8+b/cHvKHYhhXbG6jdI/pXEXFoi2OTJEnqWNmP/3WyPiuLmXnq4sYjYg3gN8DlrQhKkiSp01VlNvSSKouLlZlPUbtuUZIkScuwUsliROwJPN3PsUiSJA0amdlvWzMiYlpE3BURd0TE5GJsjYiYGBEPFl+HF+MREedHxJSIuDMidij7OZc0weUueE2NdQ3gceDIsieVJEka7NrUht4zM+fU7X8BuCEzz4qILxT7nwf2BzYrtl2A8by6us1SWdLSOe9cZD+BJzPzhTInkyRJUr86ENijeHwp8DtqyeKBwPezVra8JSJWj4j1MnPG0p5gSRNcHlnaN5QkSaqCNsxiTuD6iEjg25k5AVinLgGcCaxTPB4JPFb32unFWP8mi5IkSVq83n68g0tEjAPG1Q1NKJLBem/LzO6IWBuYGBH31z+ZmVkkkv3KZFGSJKnNisRw0eRw0WO6i6+zI+LnwM7ArAXt5YhYD5hdHN4NjK57+ahibKmVmg0tSZJUddmP25JExCoR8YYFj4F9gLuBq4CxxWFjgSuLx1cBRxazoncFni1zvSJYWZQkSSplgGdDrwP8PCKglr/9MDN/HRGTgCsi4iPAI8AhxfHXAgcAU4AXgaPKnthkUZIkqcNl5lRg28WMPwnsvZjxBI7tj3ObLEqSJJVQldv9mSxKkiSV0OydVwY7J7hIkiSpISuLkiRJJdiGliRJUkNtuINLW9iGliRJUkNWFiVJkkqoygQXk0VJkqQSqnLNom1oSZIkNWRlUZIkqQTb0JIkSWrINrQkSZIqz8qiJElSCVVZZ9FkUZIkqYTeilyzaBtakiRJDVlZlCRJKsE2tCRJkhqyDS1JkqTKs7IoSZJUgm1oSZIkNWQbWpIkSZVnZVGSJKkE29CSJElqyDa0JEmSKs/KoiRJUgm2oSVJktRQZm+7QxgQtqElSZLUkJVFSZKkEnptQ0uSJKmRdDa0JEmSqs7KoiRJUgm2oSVJktSQbWhJkiRVnpVFSZKkEqpyuz+TRUmSpBKqcgcX29CSJElqyMqiJElSCVWZ4GKyKEmSVIJL50iSJKmhqlQWvWZRkiRJDVlZlCRJKsGlcyRJktSQbWhJkiRVnpVFSZKkEpwNLUmSpIZsQ0uSJKnyrCxKkiSV4GxoSZIkNZQVuWbRNrQkSZIasrIoSZJUgm1oSZIkNeRsaEmSJFWelUVJkqQSqjLBxWRRkiSpBNvQkiRJ6hgRsV9E/C0ipkTEFwbqvFYWJUmSShjIymJEdAEXAO8ApgOTIuKqzLy31ee2sihJklRC9uPWhJ2BKZk5NTPnApcDB/bbh+mDyaIkSVLnGwk8Vrc/vRhruZa3oYeutXG0+hwafCJiXGZOaHcc6iw9c7vbHYI6kL8v1Kl65nb3W44TEeOAcXVDEzrl372VRbXLuCUfIkmAvy9UAZk5ITN3qtsWTRS7gdF1+6OKsZYzWZQkSep8k4DNImJMRCwPHApcNRAndja0JElSh8vMnog4DrgO6AIuzsx7BuLcJotql464DkPSoODvCwnIzGuBawf6vFGV1cclSZK09LxmUZIkSQ2ZLKqhiJgfEXdExD0R8deI+ExEdPS/mYj4cER8s91xSMuiiNgoIu5eZOyUiPjsUrzH7yJip/6Prv9ExPPtjkHqJF6zqL78IzO3A4iItYEfAqsCJ7czKEmSNHA6ukqkzpGZs6mtdXZc1GwUEX+IiL8U2z8BRMQeEXFTRFwZEVMj4qyIODwibo2IuyJik+K4d0XEnyPi9oj4TUSsU4yPiIiJRTXzuxHxSESsVTz3oeJ97oiIbxf3ySQijoqIByLiVmC3tnyDpIorKoZfLX5GH4iI3YvxlSLi8oi4LyJ+DqxU95rxETG5+Hk/tW58WkR8pfhZnxwRO0TEdRHxUER8rDhmWETcUPz+uSsiDqx7/X9GxN8i4uaI+NGCymdEbBIRv46I24rfX1sU42Mi4k/F+5wxQN8yadAwWVTTMnMqten6awOzgXdk5g7AB4Dz6w7dFvgYsCVwBLB5Zu4MfBf4RHHMzcCumbk9tftbfq4YPxn4bWZuDfwE2AAgIrYszrNbUe2cDxweEesBp1JLEt8GbNX/n1xSk5YrftY/xasdiGOAFzNzy2Jsx7rjv5SZOwHbAP8SEdvUPfdo8bP+B+AS4GBgV2o/7wAvAe8pfgftCXy9+EP2LcD7qP0e2h+ob3lPAD6RmTsCnwW+VYyfB4zPzDcDM17Xd0BaBtmGVllDgW9GxHbUErfN656blJkzACLiIeD6Yvwuar/Uobby/I+LZG954OFi/G3AewAy89cR8XQxvje1/8lMigioVSdmA7sAv8vMJ4rz/XiRWCT1n0bLZywY/1nx9TZgo+LxP1P8MZmZd0bEnXWvO6S4xdlywHrU/thb8PyCxYbvAoZl5nPAcxHxckSsDrwA/FdE/DPQS+0euetQ+8Pxysx8CXgpIq6GWiUS+Cfg/4rfIQArFF93o5ZgAvwA+OoSvxNShZgsqmkRsTG1xHA2tQrBLGp/vQ+h9lf+Ai/XPe6t2+/l1X9z3wDOycyrImIP4JQlnR64NDNPXCSmg5byY0gq70lg+CJja/DqH3sLftbns4T/v0TEGGrVvbdk5tMRcQmwYt0h9b83Fv2dshxwODAC2DEz50XEtEVev6ghwDMLrsNeDNeRkxqwDa2mRMQI4ELgm1lbnHM1YEZm9lJrNXct5Vuuxqv3tBxbN/5H4JDinPvw6v+YbgAOLibaEBFrRMSGwJ+pta/WjIihwPuX+sNJakpmPg/MiIi9oPZzCOxH7bKSRn4PfLA4/k3UWs5Qmyz3AvBscc3y/ksZzmrA7CJR3BPYsBj/I/CuiFixqCa+s4j978DDEfH+IpaIiG3rXnNo8fjwpYxDWuaZLKovKxUXmN8D/IZaO3nB9ULfAsZGxF+BLaj90l8ap1BrB90GzKkbPxXYJ2rLc7wfmAk8l5n3AicB1xdtrInAekW7+xTgT9R+4d+31J9S0tI4EvjPiLgD+C1wamY+1Mfx44FhEXEfcBq1FjWZ+VfgduB+aist/HEp47gM2Cki7ipiur9430nUWth3Ar+i1sZ+tnjN4cBHit9b9wALJsUcDxxbvNfIpYxDWuZ5Bxd1lIhYAZhf3APzrdQuOt+uzWFJGkQiYlhmPh8RK1OrbI7LzL+0Oy5psPKaRXWaDYArorb491zg39scj6TBZ0JEbEXtGsZLTRSl18fKoiRJkhrymkVJkiQ1ZLIoSZKkhkwWJUmS1JDJoiRJkhoyWZQkSVJDJouSJElq6P8DKFH2ssove4gAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 864x504 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_cm_raw = pd.DataFrame(cf_matrix, index=[i for i in labels],\n",
    "                     columns=[i for i in labels])\n",
    "plt.figure(figsize=(12, 7))\n",
    "sn.heatmap(df_cm_raw, annot=True)\n",
    "# plt.save(\"Confusion_matrix_raw.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2930,    0],\n",
       "       [3031,    0]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cf_matrix"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
