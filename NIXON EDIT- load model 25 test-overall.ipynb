{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To note: Running this on different systems (i.e. local, SCW, server) will result in slight changes needing to the code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/scipy/__init__.py:138: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.4)\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion} is required for this version of \"\n"
     ]
    }
   ],
   "source": [
    "# Load libraries\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import sys\n",
    "import torchvision\n",
    "import torchvision.transforms as T\n",
    "import torchvision.models as models\n",
    "from PIL import Image\n",
    "from PIL import ImageEnhance\n",
    "import matplotlib.pyplot as plt\n",
    "import imagesize\n",
    "import subprocess\n",
    "sys.path\n",
    "from IPython.core.debugger import set_trace\n",
    "import scipy.ndimage\n",
    "import matplotlib.patches as patches\n",
    "# plt.rcParams['figure.figsize'] = [12,12]\n",
    "# sys.path.append('/workspace/myFile/Mask_RCNN_Tutorial/')\n",
    "from tqdm import tqdm\n",
    "from torch import nn as nn\n",
    "from torch import optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "import re\n",
    "import time\n",
    "import copy\n",
    "import pylab\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from tempfile import TemporaryDirectory\n",
    "import torch.backends.cudnn as cudnn\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "import seaborn as sn\n",
    "import pandas as pd\n",
    "import glob\n",
    "# Rather than have a messy notebook with a load of functions we can store them in separate .py files and import them\n",
    "\n",
    "cudnn.benchmark = True\n",
    "plt.ion()   # interactive mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "writer = SummaryWriter(\"Experiments/TENSORBOARD\")    # This determines the tensorboard file name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DNADataset(object):\n",
    "    def __init__(self, root, transforms, labels, imDx = False):\n",
    "        self.root, self.transforms, self.labels = root, transforms, labels\n",
    "    \n",
    "        # load all image files, sorting them to ensure they are aligned\n",
    "        self.imgDir = glob.glob(root+\"*/*.tiff\")\n",
    "        Damagednuclei= [x for x in self.imgDir if 'Damaged_nuclei_' in x]\n",
    "        Undamagednuclei= [x for x in self.imgDir if \"No_damage_nuclei\" in x]\n",
    "        #np.random.shuffle(Undamagednuclei)\n",
    "        #Undamagednuclei=Undamagednuclei[:10000]\n",
    "        self.imgDir= Damagednuclei+Undamagednuclei\n",
    "        size80=[]\n",
    "        for x in self.imgDir:\n",
    "            img = Image.open(x) # Open image\n",
    "            w,h=img.size\n",
    "            if w<=80 and h<=80:\n",
    "                size80.append(x)\n",
    "        self.imgDir=size80              \n",
    "        \n",
    "        self.imgs = sorted(self.imgDir) # list of images\n",
    "\n",
    "        \n",
    "\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.imgs[idx]\n",
    "       \n",
    "        # Transform images into tensors\n",
    "        img = Image.open(img_path) # Open image\n",
    "        w,h=img.size\n",
    "        img = np.array(img) # Convert image into an array\n",
    "        img = np.float32(np.divide(img, 2**16)) # Ensure all values are floats\n",
    "        \n",
    "        result=np.zeros((80,80), dtype=np.float32)\n",
    "        x_center = (80 - w) // 2\n",
    "        y_center = (80 - h) // 2 # copy img image into center of result image\n",
    "        result[y_center:y_center+h, x_center:x_center+w] = img\n",
    "        img = result\n",
    "        \n",
    "        targetlab=\"\"\n",
    "        if img_path.find('No_damage_nuclei') != -1:\n",
    "            targetlab= 'Undamaged'\n",
    "        if img_path.find('Damaged_nuclei_') != -1:\n",
    "            targetlab= 'Damaged'  # Find labels corresponding to image\n",
    "        target = self.labels.index(targetlab) # Get the label and assign to a value\n",
    "        \n",
    "        # Convert label to tensor\n",
    "        #torch.to\n",
    "        \n",
    "        if self.transforms is not None:\n",
    "            img = self.transforms(img)\n",
    "#             #print('In the transforms')\n",
    "        imNo = idx\n",
    "        return img, target, imNo\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.imgs)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "imDr = \"/workspace/myFile/Output/17052023/\"  # Image patches directory\n",
    "\n",
    "labels = ['Damaged', 'Undamaged']  # Your labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For data augmentation\n",
    "def get_transform(train):\n",
    "    transforms = []\n",
    "\n",
    "    transforms.append(T.ToTensor())\n",
    "    #transforms.append(T.Normalize([0.0019368887995516483], [0.00672996630111016]))\n",
    "    #transforms.append(T.RandomHorizontalFlip(0.5))\n",
    "    \n",
    "    if train:\n",
    "        transforms.append(T.RandomHorizontalFlip(p=1))\n",
    "        transforms.append(T.RandomVerticalFlip(p=1))\n",
    "    \n",
    "    return T.Compose(transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, scheduler, train, test, num_epochs=25):\n",
    "    since = time.time()\n",
    "    # Create a temporary directory to save training checkpoints\n",
    "    with TemporaryDirectory() as tempdir:\n",
    "        best_model_params_path = os.path.join(tempdir, 'best_model_params.pt')\n",
    "\n",
    "        torch.save(model.state_dict(), best_model_params_path)\n",
    "        best_acc = 0.0\n",
    "        \n",
    "        for epoch in range(num_epochs):\n",
    "            print(f'Epoch {epoch}/{num_epochs - 1}')\n",
    "            print('-' * 10)\n",
    "            dataset_train = torch.utils.data.Subset(dataSetTrain, train[epoch])\n",
    "            dataset_test = torch.utils.data.Subset(dataSetTest, test[epoch])\n",
    "            data_loader_train = torch.utils.data.DataLoader(\n",
    "                dataset_train, batch_size=128, shuffle=True, num_workers=0)\n",
    "\n",
    "            data_loader_test = torch.utils.data.DataLoader(\n",
    "                dataset_test, batch_size=128, shuffle=False, num_workers=0)\n",
    "            # Each epoch has a training and validation phase\n",
    "            for phase in ['val']:\n",
    "                if phase == 'train':\n",
    "                    model.train()  # Set model to training mode\n",
    "                    dataloaders = data_loader_train\n",
    "                else:\n",
    "                    model.eval()   # Set model to evaluate mode\n",
    "                    dataloaders = data_loader_test\n",
    "\n",
    "                running_loss = 0.0\n",
    "                running_corrects = 0\n",
    "                damaged_len=0\n",
    "                damaged_corrects = 0\n",
    "                undamaged_len=0\n",
    "                undamaged_corrects = 0\n",
    "\n",
    "                # Iterate over data.\n",
    "                for inputs, labels, imNo in dataloaders:\n",
    "                    inputs = inputs.to(device)\n",
    "                    labels = labels.to(device)\n",
    "\n",
    "                    # zero the parameter gradients\n",
    "                    optimizer.zero_grad()\n",
    "\n",
    "                    # forward\n",
    "                    # track history if only in train\n",
    "                    with torch.set_grad_enabled(phase == 'train'):\n",
    "                        outputs = model(inputs)\n",
    "                        _, preds = torch.max(outputs, 1)\n",
    "                        loss = criterion(outputs, labels)\n",
    "                        # backward + optimize only if in training phase\n",
    "                        if phase == 'train':\n",
    "                            loss.backward()\n",
    "                            optimizer.step()\n",
    "\n",
    "                    # statistics\n",
    "                    running_loss += loss.item() * inputs.size(0)    # Loss\n",
    "                    nada=torch.tensor(np.zeros(len(labels))).to(device)\n",
    "                    uno=nada+1\n",
    "                    falseneg=preds+1\n",
    "                    falsepos=preds-1\n",
    "                    FPplusTN=torch.sum(labels==nada)\n",
    "                    TPplusFN=torch.sum(labels==uno)\n",
    "                    FN=torch.sum(labels==falseneg)\n",
    "                    FP=torch.sum(labels==falsepos)\n",
    "                    TN=FPplusTN-FP\n",
    "                    TP=TPplusFN-FN\n",
    "                    running_corrects += torch.sum(preds == labels.data) # Accuracy\n",
    "                    damaged_len+=TPplusFN\n",
    "                    damaged_corrects += TP\n",
    "                    undamaged_len+=FPplusTN\n",
    "                    undamaged_corrects += TN\n",
    "                damaged_acc = damaged_corrects / damaged_len\n",
    "                undamaged_acc = undamaged_corrects/undamaged_len\n",
    "                epoch_acc= (damaged_acc+undamaged_acc)/2\n",
    "                proper_acc=(damaged_corrects+undamaged_corrects)/(damaged_len+undamaged_len)\n",
    "                if phase == 'train':\n",
    "                    scheduler.step()\n",
    "\n",
    "                epoch_loss = running_loss / dataset_sizes[phase]    # Loss metric per epoch\n",
    "                #epoch_acc = running_corrects.double() / dataset_sizes[phase]    # Accuracy metric per epoch\n",
    "\n",
    "                if phase == \"train\":    # This is the tensorboard code that writes accuracy and loss metrics\n",
    "                    writer.add_scalar(\"Train/Accuracy\", epoch_acc, epoch)\n",
    "                    writer.add_scalar(\"Train/Loss\", epoch_loss, epoch)\n",
    "                else:\n",
    "                    writer.add_scalar(\"Validation/Accuracy\", epoch_acc, epoch)\n",
    "                    writer.add_scalar(\"Validation/Loss\", epoch_loss, epoch)\n",
    "\n",
    "                print(f'{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n",
    "                print(\"proper accuracy=\")\n",
    "                print(proper_acc)\n",
    "                print(\"damaged accuracy=\")\n",
    "                print(damaged_acc)\n",
    "                print(\"undamaged accuracy=\")\n",
    "                print(undamaged_acc)\n",
    "                con_matter= torch.tensor([[damaged_corrects, damaged_len-damaged_corrects],[undamaged_len-undamaged_corrects,undamaged_corrects]])\n",
    "                con_matter=con_matter.cpu().numpy()\n",
    "                print(con_matter)\n",
    "                # deep copy the model\n",
    "                if phase == 'val' and epoch_acc >= best_acc: \n",
    "                    # This compares validation accuracy to previous bests and adjusts model weights accordingly\n",
    "                    best_acc = epoch_acc\n",
    "                    torch.save(model.state_dict(), best_model_params_path)\n",
    "                    con_mat= torch.tensor([[damaged_corrects, damaged_len-damaged_corrects],[undamaged_len-undamaged_corrects,undamaged_corrects]])\n",
    "\n",
    "            print()\n",
    "\n",
    "        time_elapsed = time.time() - since  # Nice way to measure training time but info also stored (indirectly) by tensorboard\n",
    "        print(\n",
    "            f'Training complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')\n",
    "        print(f'Best val Acc: {best_acc:4f}')\n",
    "        #labels= labels.cpu().numpy()\n",
    "        #preds=preds.cpu().numpy()\n",
    "        model.load_state_dict(torch.load(best_model_params_path))\n",
    "    writer.close()\n",
    "    return model, con_mat   # We want to return the model because its the model, also confusion matrix for later analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is your RESNET\n",
    "# Initialize CNN with kaiming\n",
    "def init_cnn(m):\n",
    "    # Set the weights of the RESNET\n",
    "    if getattr(m, 'bias', None) is not None: nn.init.constant_(m.bias, 0)\n",
    "    if isinstance(m, (nn.Conv2d,nn.Linear)): nn.init.kaiming_normal_(m.weight)\n",
    "    for l in m.children(): init_cnn(l)\n",
    "\n",
    "\n",
    "# noop function for returning nothing\n",
    "def noop(x): return x\n",
    "# activation function(RELU)\n",
    "act_fn = nn.ReLU(inplace=True)\n",
    "\n",
    "# Flatten\n",
    "class Flatten(nn.Module):\n",
    "    def forward(self, x): return x.view(x.size(0), -1)\n",
    "\n",
    "# Make a convolution\n",
    "def conv(ni, nf, ks=3, stride=1, bias=False):\n",
    "    return nn.Conv2d(ni, nf, kernel_size=ks, stride=stride, padding=ks//2, bias=bias)\n",
    "\n",
    "# Create a convuolutional layer with convolution and batch norm\n",
    "def conv_layer(ni, nf, ks=3, stride=1, zero_bn=False, act=True):\n",
    "    bn = nn.BatchNorm2d(nf) # get a 2d batch norm from Pytorhc\n",
    "    nn.init.constant_(bn.weight, 0. if zero_bn else 1.)\n",
    "    layers = [conv(ni, nf, ks, stride=stride), bn]\n",
    "    if act: layers.append(act_fn) # add in the activation function if act is true\n",
    "    return nn.Sequential(*layers)\n",
    "\n",
    "\n",
    "# Resblock\n",
    "class ResBlock(nn.Module):\n",
    "    def __init__(self, expansion, ni, nh, stride = 1):\n",
    "        super().__init__()\n",
    "        # ni - number of inputs channels, nf - number of filters\n",
    "        # nh - number of filters in first conv\n",
    "        # expansion is 1 for resnet 18, 34 and 4 for larger networks\n",
    "        nf, ni = nh*expansion, ni*expansion\n",
    "        layers = [conv_layer(ni, nh, 3, stride = stride), # for resnet < 34 2 convs per resblock\n",
    "                 conv_layer(nh, nf, 3, zero_bn = True, act = False)\n",
    "                 ] if expansion == 1 else [ # for RESNET > 34 then 3 convs per block with bottleneck\n",
    "                            conv_layer(ni, nh, 1),\n",
    "                            conv_layer(nh, nh, 3, stride = stride),\n",
    "                            conv_layer(nh, nf, 1, zero_bn = True, act = False)\n",
    "        ]\n",
    "        self.convs = nn.Sequential(*layers) # Creates the conv layers\n",
    "        self.idconv = noop if ni==nf else conv_layer(ni, nf, 1, act = False) # id convolution ()\n",
    "        self.pool = noop if stride== 1 else nn.AvgPool2d(2, ceil_mode = True) # average pool on \n",
    "        \n",
    "    def forward(self, x): \n",
    "        # Forward function adds the convolution part to the id part \n",
    "        #return act_fn(self.convs(x)) + self.idconv(self.pool(x))\n",
    "        return act_fn(self.convs(x) + self.idconv(self.pool(x)))\n",
    "\n",
    "# XResnet\n",
    "class XResNet(nn.Sequential):\n",
    "    @classmethod\n",
    "    def create(cls, expansion, layers, c_in=3, c_out=1000):\n",
    "        nfs = [c_in, (c_in + 1)*8, 64, 64] # number of filters in stem layer (c_in is number of image channels)\n",
    "        stem = [conv_layer(nfs[i], nfs[i+1], stride=2 if i==0 else 1)\n",
    "            for i in range(3)]\n",
    "\n",
    "        nfs = [64//expansion,64,128,256,512]\n",
    "        res_layers = [cls._make_layer(expansion, nfs[i], nfs[i+1],\n",
    "                                      n_blocks=l, stride=1 if i==0 else 2)\n",
    "                  for i,l in enumerate(layers)]\n",
    "        res = cls(\n",
    "        *stem,\n",
    "        nn.MaxPool2d(kernel_size=3, stride = 2, padding = 1), # then a max pooling layer\n",
    "        *res_layers,\n",
    "        nn.AdaptiveAvgPool2d(1), Flatten(), \n",
    "        nn.Linear(nfs[-1]*expansion, c_out)\n",
    "        )\n",
    "        init_cnn(res)\n",
    "        return res\n",
    "        \n",
    "    @staticmethod\n",
    "    def _make_layer(expansion, ni, nf, n_blocks, stride): # returns a resblock\n",
    "        return nn.Sequential(\n",
    "        *[ResBlock(expansion, ni if i==0 else nf, nf, stride if i==0 else 1)\n",
    "         for i in range(n_blocks)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def xresnet18 (**kwargs): return XResNet.create(1, [2, 2,  2, 2], **kwargs)\n",
    "def xresnet34 (**kwargs): return XResNet.create(1, [3, 4,  6, 3], **kwargs)\n",
    "def xresnet50 (**kwargs): return XResNet.create(4, [3, 4,  6, 3], **kwargs)\n",
    "model = xresnet18(c_in = 1, c_out = 2)\n",
    "#model34 = xresnet34(c_in = 1, c_out = 2)\n",
    "#model50 = xresnet50(c_in = 1, c_out = 2)\n",
    "model.load_state_dict(torch.load(\"/workspace/myFile/Output/17052023/25_epochs_best_model_params.pt\"))\n",
    "model = model.to(device)\n",
    "\n",
    "# Label smoothing cross entropy\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "def reduce_loss(loss, reduction='mean'):\n",
    "    return loss.mean() if reduction=='mean' else loss.sum() if reduction=='sum' else loss\n",
    "\n",
    "class LabelSmoothingCrossEntropy(nn.Module):\n",
    "    def __init__(self, ε:float=0.1, reduction='mean'):\n",
    "        super().__init__()\n",
    "        self.ε,self.reduction = ε,reduction\n",
    "    \n",
    "    def forward(self, output, target):\n",
    "        c = output.size()[-1]\n",
    "        log_preds = F.log_softmax(output, dim=-1)\n",
    "        loss = reduce_loss(-log_preds.sum(dim=-1), self.reduction)\n",
    "        nll = F.nll_loss(log_preds, target, reduction=self.reduction)\n",
    "        return lin_comb(loss/c, nll, self.ε)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions that shows the image, true class, predicted class and degree of prediction\n",
    "\n",
    "def images_to_probs(net, images):\n",
    "    '''\n",
    "    Generates predictions and corresponding probabilities from a trained\n",
    "    network and a list of images\n",
    "    '''\n",
    "    output = net(images)\n",
    "    # convert output probabilities to predicted class\n",
    "    _, preds_tensor = torch.max(output, 1)\n",
    "    preds = np.squeeze(preds_tensor.numpy())\n",
    "    return preds, [F.softmax(el, dim=0)[i].item() for i, el in zip(preds, output)]\n",
    "\n",
    "\n",
    "def plot_classes_preds(net, images, labels):\n",
    "    '''\n",
    "    Generates matplotlib Figure using a trained network, along with images\n",
    "    and labels from a batch, that shows the network's top prediction along\n",
    "    with its probability, alongside the actual label, coloring this\n",
    "    information based on whether the prediction was correct or not.\n",
    "    Uses the \"images_to_probs\" function.\n",
    "    '''\n",
    "    preds, probs = images_to_probs(net, images)\n",
    "    # plot the images in the batch, along with predicted and true labels\n",
    "    fig = plt.figure(figsize=(12, 48))\n",
    "    for idx in np.arange(4):\n",
    "        ax = fig.add_subplot(1, 4, idx+1, xticks=[], yticks=[])\n",
    "        matplotlib_imshow(images[idx], one_channel=True)\n",
    "        ax.set_title(\"{0}, {1:.1f}%\\n(label: {2})\".format(\n",
    "            labels[preds[idx]],\n",
    "            probs[idx] * 100.0,\n",
    "            labels[labels[idx]]),\n",
    "                    color=(\"green\" if preds[idx]==labels[idx].item() else \"red\"))\n",
    "    return fig\n",
    "\n",
    "def matplotlib_imshow(img, one_channel=True):\n",
    "    if one_channel:\n",
    "        img = img.mean(dim=0)\n",
    "    img = img / 2 + 0.5     # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    if one_channel:\n",
    "        plt.imshow(npimg, cmap=\"Greys\")\n",
    "    else:\n",
    "        plt.imshow(np.transpose(npimg, (1, 2, 0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def confusion_matrix_calc(data_loader_test, classes, model_ft):       \n",
    "        y_pred = []\n",
    "        y_true = []\n",
    "        for inputs, labels, imNo in data_loader_test:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "                output = model_ft(inputs) # Feed Network\n",
    "\n",
    "                output = (torch.max(torch.exp(output), 1)[1]).data.cpu().numpy()\n",
    "                y_pred.extend(output) # Save Prediction\n",
    "                \n",
    "                labels = labels.data.cpu().numpy()\n",
    "                y_true.extend(labels) # Save Truth\n",
    "\n",
    "        # constant for classes\n",
    "        # classes = ('Alive', 'Dead')\n",
    "\n",
    "        # Build confusion matrix\n",
    "        cf_matrix = confusion_matrix(y_true, y_pred)\n",
    "        return cf_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': 105347, 'val': 1}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k=5 #NUMBER OF K FOLDS\n",
    "epoch=5 #NUMBER OF EPOCHS\n",
    "\n",
    "torch.manual_seed(10)\n",
    "imIdx = torch.randperm(1).tolist()\n",
    "\n",
    "## Create dataset\n",
    "dataSetTrain = DNADataset(imDr, get_transform(train = True), labels, imDx=imIdx)\n",
    "dataSetTest = DNADataset(imDr, get_transform(train = False), labels, imDx=imIdx)\n",
    "\n",
    "data_loader_train=[]\n",
    "data_loader_test=[]\n",
    "\n",
    "# ## Create dataloaders\n",
    "# Get subset\n",
    "torch.manual_seed(10)\n",
    "indices = torch.randperm(len(dataSetTrain)).tolist()\n",
    "\n",
    "noTrain = int(len(dataSetTrain)*0.7)\n",
    "train=[]\n",
    "test=[]\n",
    "indices = torch.randperm(len(dataSetTrain)).tolist()\n",
    "TotalSet=list(range(len(dataSetTrain)))\n",
    "Kfifth = len(dataSetTrain)//k\n",
    "split= epoch%k\n",
    "train.append(TotalSet[(split+1)*Kfifth:]+TotalSet[:Kfifth*split])\n",
    "\n",
    "indices = torch.randperm(len(dataSetTest)).tolist()\n",
    "TotalSet=list(range(len(dataSetTrain)))\n",
    "test.append(TotalSet)\n",
    "\n",
    "#dataset_train = torch.utils.data.Subset(dataSetTrain, indices[-noTrain:])\n",
    "\n",
    "#dataset_test = torch.utils.data.Subset(dataSetTest, indices[:-noTrain])\n",
    "#len(indices), len(indices[:-50]), len(indices[-50:]), 50/191, type(dataset_test)\n",
    "\n",
    "dataset_sizes = {'train': len(train[0]), 'val': len(test)}\n",
    "dataset_sizes\n",
    "#dataset_train = torch.utils.data.Subset(dataSetTrain, train)\n",
    "#data_loader_train.append(dataset_train)\n",
    "#dataset_testo = torch.utils.data.Subset(dataSetTest, test)\n",
    "#data_loader_test.append(dataset_testo)\n",
    "# define training and validation data loaders\n",
    "\n",
    "\n",
    "# Collate function (gathers together the outputs)\n",
    "# def collate_fn(batch):\n",
    "#     return tuple(zip(*batch))\n",
    "\n",
    "#len(indices[-noTrain:]), dataset_sizes\n",
    "#dataset_test[0][1], dataset_test[3][1], dataset_test[-1][1], dataSetTrain.imgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_weights= [0.924865,0.075135] #1-(#inclass/ #intotal )\n",
    "class_weights = torch.Tensor(class_weights)\n",
    "class_weights=class_weights.to(device)\n",
    "criterion = nn.CrossEntropyLoss(weight = class_weights) \n",
    "\n",
    "# Observe that all parameters are being optimized\n",
    "optimizer_ft = optim.Adam(model.parameters(), weight_decay=1e-2) # standard ADAM optimiser\n",
    "\n",
    "# Decay LR by a factor of 0.1 every 7 epochs\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/0\n",
      "----------\n",
      "val Loss: 33809.4554 Acc: 0.8726\n",
      "proper accuracy=\n",
      "tensor(0.8828, device='cuda:0')\n",
      "damaged accuracy=\n",
      "tensor(0.8846, device='cuda:0')\n",
      "undamaged accuracy=\n",
      "tensor(0.8606, device='cuda:0')\n",
      "[[107740  14049]\n",
      " [  1379   8515]]\n",
      "\n",
      "Training complete in 2m 19s\n",
      "Best val Acc: 0.872634\n"
     ]
    }
   ],
   "source": [
    "model_ft, con_mat = train_model(model, criterion, optimizer_ft, exp_lr_scheduler, \n",
    "                                    train,test,num_epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cf_matrix = confusion_matrix_calc(data_loader_test, labels, model_ft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x504 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "con_mat=con_mat.cpu().numpy()\n",
    "plotlabels=['Undamaged','Damaged']\n",
    "df_cm_ratio = pd.DataFrame(con_mat / np.sum(con_mat, axis=1)[:, None], index=[i for i in plotlabels],\n",
    "                     columns=[i for i in plotlabels])\n",
    "plt.figure(figsize=(12, 7))\n",
    "sn.heatmap(df_cm_ratio, annot=True)\n",
    "# plt.save(\"Confusion_matrix_ratio.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x504 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_cm_raw = pd.DataFrame(con_mat, index=[i for i in plotlabels],\n",
    "                     columns=[i for i in plotlabels])\n",
    "plt.figure(figsize=(12, 7))\n",
    "sn.heatmap(df_cm_raw, annot=True)\n",
    "# plt.save(\"Confusion_matrix_raw.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[107740,  14049],\n",
       "       [  1379,   8515]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "con_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_loader_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotlabels=['Undamaged','Damaged']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
