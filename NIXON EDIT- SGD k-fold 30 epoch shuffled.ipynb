{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To note: Running this on different systems (i.e. local, SCW, server) will result in slight changes needing to the code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/scipy/__init__.py:138: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.4)\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion} is required for this version of \"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.pyplot._IonContext at 0x7fc0cc33df70>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load libraries\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import sys\n",
    "import torchvision\n",
    "import torchvision.transforms as T\n",
    "import torchvision.models as models\n",
    "from PIL import Image\n",
    "from PIL import ImageEnhance\n",
    "import matplotlib.pyplot as plt\n",
    "import imagesize\n",
    "import subprocess\n",
    "sys.path\n",
    "from IPython.core.debugger import set_trace\n",
    "import scipy.ndimage\n",
    "import matplotlib.patches as patches\n",
    "# plt.rcParams['figure.figsize'] = [12,12]\n",
    "# sys.path.append('/workspace/myFile/Mask_RCNN_Tutorial/')\n",
    "from tqdm import tqdm\n",
    "from torch import nn as nn\n",
    "from torch import optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "import re\n",
    "import time\n",
    "import copy\n",
    "import pylab\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from tempfile import TemporaryDirectory\n",
    "import torch.backends.cudnn as cudnn\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "import seaborn as sn\n",
    "import pandas as pd\n",
    "import glob\n",
    "# Rather than have a messy notebook with a load of functions we can store them in separate .py files and import them\n",
    "\n",
    "cudnn.benchmark = True\n",
    "plt.ion()   # interactive mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "writer = SummaryWriter(\"Experiments/TENSORBOARD\")    # This determines the tensorboard file name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DNADataset(object):\n",
    "    def __init__(self, root, transforms, labels, imDx = False):\n",
    "        self.root, self.transforms, self.labels = root, transforms, labels\n",
    "    \n",
    "        # load all image files, sorting them to ensure they are aligned\n",
    "        self.imgDir = glob.glob(root+\"*/*.tiff\")\n",
    "        Damagednuclei= [x for x in self.imgDir if 'Damaged_nuclei_' in x]\n",
    "        Undamagednuclei= [x for x in self.imgDir if \"No_damage_nuclei\" in x]\n",
    "        #np.random.shuffle(Undamagednuclei)\n",
    "        #Undamagednuclei=Undamagednuclei[:10000]\n",
    "        self.imgDir= Damagednuclei+Undamagednuclei\n",
    "        size80=[]\n",
    "        for x in self.imgDir:\n",
    "            img = Image.open(x) # Open image\n",
    "            w,h=img.size\n",
    "            if w<=80 and h<=80:\n",
    "                size80.append(x)\n",
    "        self.imgDir=size80              \n",
    "        \n",
    "        self.imgs = sorted(self.imgDir) # list of images\n",
    "\n",
    "        \n",
    "\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.imgs[idx]\n",
    "       \n",
    "        # Transform images into tensors\n",
    "        img = Image.open(img_path) # Open image\n",
    "        w,h=img.size\n",
    "        img = np.array(img) # Convert image into an array\n",
    "        img = np.float32(np.divide(img, 2**16)) # Ensure all values are floats\n",
    "        \n",
    "        result=np.zeros((80,80), dtype=np.float32)\n",
    "        x_center = (80 - w) // 2\n",
    "        y_center = (80 - h) // 2 # copy img image into center of result image\n",
    "        result[y_center:y_center+h, x_center:x_center+w] = img\n",
    "        img = result\n",
    "        \n",
    "        targetlab=\"\"\n",
    "        if img_path.find('No_damage_nuclei') != -1:\n",
    "            targetlab= 'Undamaged'\n",
    "        if img_path.find('Damaged_nuclei_') != -1:\n",
    "            targetlab= 'Damaged'  # Find labels corresponding to image\n",
    "        target = self.labels.index(targetlab) # Get the label and assign to a value\n",
    "        \n",
    "        # Convert label to tensor\n",
    "        #torch.to\n",
    "        \n",
    "        if self.transforms is not None:\n",
    "            img = self.transforms(img)\n",
    "#             #print('In the transforms')\n",
    "        imNo = idx\n",
    "        return img, target, imNo\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.imgs)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "root=\"/workspace/myFile/Output/17052023/\"\n",
    "p= glob.glob(root+\"*/*.tiff\")\n",
    "Damagednuclei= [x for x in p if 'Damaged_nuclei_' in x]\n",
    "Undamagednuclei= [x for x in p if \"No_damage_nuclei\" in x]\n",
    "#np.random.shuffle(Undamagednuclei)\n",
    "#Undamagednuclei=Undamagednuclei[:10000]\n",
    "#Undamagednuclei"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "imDr = \"/workspace/myFile/Output/17052023/\"  # Image patches directory\n",
    "\n",
    "labels = ['Damaged', 'Undamaged']  # Your labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For data augmentation\n",
    "def get_transform(train):\n",
    "    transforms = []\n",
    "\n",
    "    transforms.append(T.ToTensor())\n",
    "    #transforms.append(T.Normalize([0.0019368887995516483], [0.00672996630111016]))\n",
    "    #transforms.append(T.RandomHorizontalFlip(0.5))\n",
    "    \n",
    "    if train:\n",
    "        transforms.append(T.RandomHorizontalFlip(p=1))\n",
    "        transforms.append(T.RandomVerticalFlip(p=1))\n",
    "    \n",
    "    return T.Compose(transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, scheduler, train, test, num_epochs=25):\n",
    "    since = time.time()\n",
    "    # Create a temporary directory to save training checkpoints\n",
    "    with TemporaryDirectory() as tempdir:\n",
    "        best_model_params_path = os.path.join(tempdir, 'best_model_params.pt')\n",
    "\n",
    "        torch.save(model.state_dict(), best_model_params_path)\n",
    "        best_acc = 0.0\n",
    "        \n",
    "        for epoch in range(num_epochs):\n",
    "            print(f'Epoch {epoch}/{num_epochs - 1}')\n",
    "            print('-' * 10)\n",
    "            dataset_train = torch.utils.data.Subset(dataSetTrain, train[epoch])\n",
    "            dataset_test = torch.utils.data.Subset(dataSetTest, test[epoch])\n",
    "            data_loader_train = torch.utils.data.DataLoader(\n",
    "                dataset_train, batch_size=128, shuffle=True, num_workers=0)\n",
    "\n",
    "            data_loader_test = torch.utils.data.DataLoader(\n",
    "                dataset_test, batch_size=128, shuffle=False, num_workers=0)\n",
    "            # Each epoch has a training and validation phase\n",
    "            for phase in ['train', 'val']:\n",
    "                if phase == 'train':\n",
    "                    model.train()  # Set model to training mode\n",
    "                    dataloaders = data_loader_train\n",
    "                else:\n",
    "                    model.eval()   # Set model to evaluate mode\n",
    "                    dataloaders = data_loader_test\n",
    "\n",
    "                running_loss = 0.0\n",
    "                running_corrects = 0\n",
    "                damaged_len=0\n",
    "                damaged_corrects = 0\n",
    "                undamaged_len=0\n",
    "                undamaged_corrects = 0\n",
    "\n",
    "                # Iterate over data.\n",
    "                for inputs, labels, imNo in dataloaders:\n",
    "                    inputs = inputs.to(device)\n",
    "                    labels = labels.to(device)\n",
    "\n",
    "                    # zero the parameter gradients\n",
    "                    optimizer.zero_grad()\n",
    "\n",
    "                    # forward\n",
    "                    # track history if only in train\n",
    "                    with torch.set_grad_enabled(phase == 'train'):\n",
    "                        outputs = model(inputs)\n",
    "                        _, preds = torch.max(outputs, 1)\n",
    "                        loss = criterion(outputs, labels)\n",
    "                        # backward + optimize only if in training phase\n",
    "                        if phase == 'train':\n",
    "                            loss.backward()\n",
    "                            optimizer.step()\n",
    "\n",
    "                    # statistics\n",
    "                    running_loss += loss.item() * inputs.size(0)    # Loss\n",
    "                    nada=torch.tensor(np.zeros(len(labels))).to(device)\n",
    "                    uno=nada+1\n",
    "                    falseneg=preds+1\n",
    "                    falsepos=preds-1\n",
    "                    FPplusTN=torch.sum(labels==nada)\n",
    "                    TPplusFN=torch.sum(labels==uno)\n",
    "                    FN=torch.sum(labels==falseneg)\n",
    "                    FP=torch.sum(labels==falsepos)\n",
    "                    TN=FPplusTN-FP\n",
    "                    TP=TPplusFN-FN\n",
    "                    running_corrects += torch.sum(preds == labels.data) # Accuracy\n",
    "                    damaged_len+=TPplusFN\n",
    "                    damaged_corrects += TP\n",
    "                    undamaged_len+=FPplusTN\n",
    "                    undamaged_corrects += TN\n",
    "                damaged_acc = damaged_corrects / damaged_len\n",
    "                undamaged_acc = undamaged_corrects/undamaged_len\n",
    "                epoch_acc= (damaged_acc+undamaged_acc)/2\n",
    "                \n",
    "                if phase == 'train':\n",
    "                    scheduler.step()\n",
    "\n",
    "                epoch_loss = running_loss / dataset_sizes[phase]    # Loss metric per epoch\n",
    "                #epoch_acc = running_corrects.double() / dataset_sizes[phase]    # Accuracy metric per epoch\n",
    "\n",
    "                if phase == \"train\":    # This is the tensorboard code that writes accuracy and loss metrics\n",
    "                    writer.add_scalar(\"Train/Accuracy\", epoch_acc, epoch)\n",
    "                    writer.add_scalar(\"Train/Loss\", epoch_loss, epoch)\n",
    "                else:\n",
    "                    writer.add_scalar(\"Validation/Accuracy\", epoch_acc, epoch)\n",
    "                    writer.add_scalar(\"Validation/Loss\", epoch_loss, epoch)\n",
    "\n",
    "                print(f'{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n",
    "\n",
    "                # deep copy the model\n",
    "                if phase == 'val' and epoch_acc >= best_acc: \n",
    "                    # This compares validation accuracy to previous bests and adjusts model weights accordingly\n",
    "                    best_acc = epoch_acc\n",
    "                    torch.save(model.state_dict(), best_model_params_path)\n",
    "                    con_mat= torch.tensor([[damaged_corrects, damaged_len-damaged_corrects],[undamaged_len-undamaged_corrects,undamaged_corrects]])\n",
    "\n",
    "            print()\n",
    "\n",
    "        time_elapsed = time.time() - since  # Nice way to measure training time but info also stored (indirectly) by tensorboard\n",
    "        print(\n",
    "            f'Training complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')\n",
    "        print(f'Best val Acc: {best_acc:4f}')\n",
    "        #labels= labels.cpu().numpy()\n",
    "        #preds=preds.cpu().numpy()\n",
    "        model.load_state_dict(torch.load(best_model_params_path))\n",
    "    writer.close()\n",
    "    return model, con_mat   # We want to return the model because its the model, also confusion matrix for later analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is your RESNET\n",
    "# Initialize CNN with kaiming\n",
    "def init_cnn(m):\n",
    "    # Set the weights of the RESNET\n",
    "    if getattr(m, 'bias', None) is not None: nn.init.constant_(m.bias, 0)\n",
    "    if isinstance(m, (nn.Conv2d,nn.Linear)): nn.init.kaiming_normal_(m.weight)\n",
    "    for l in m.children(): init_cnn(l)\n",
    "\n",
    "\n",
    "# noop function for returning nothing\n",
    "def noop(x): return x\n",
    "# activation function(RELU)\n",
    "act_fn = nn.ReLU(inplace=True)\n",
    "\n",
    "# Flatten\n",
    "class Flatten(nn.Module):\n",
    "    def forward(self, x): return x.view(x.size(0), -1)\n",
    "\n",
    "# Make a convolution\n",
    "def conv(ni, nf, ks=3, stride=1, bias=False):\n",
    "    return nn.Conv2d(ni, nf, kernel_size=ks, stride=stride, padding=ks//2, bias=bias)\n",
    "\n",
    "# Create a convuolutional layer with convolution and batch norm\n",
    "def conv_layer(ni, nf, ks=3, stride=1, zero_bn=False, act=True):\n",
    "    bn = nn.BatchNorm2d(nf) # get a 2d batch norm from Pytorhc\n",
    "    nn.init.constant_(bn.weight, 0. if zero_bn else 1.)\n",
    "    layers = [conv(ni, nf, ks, stride=stride), bn]\n",
    "    if act: layers.append(act_fn) # add in the activation function if act is true\n",
    "    return nn.Sequential(*layers)\n",
    "\n",
    "\n",
    "# Resblock\n",
    "class ResBlock(nn.Module):\n",
    "    def __init__(self, expansion, ni, nh, stride = 1):\n",
    "        super().__init__()\n",
    "        # ni - number of inputs channels, nf - number of filters\n",
    "        # nh - number of filters in first conv\n",
    "        # expansion is 1 for resnet 18, 34 and 4 for larger networks\n",
    "        nf, ni = nh*expansion, ni*expansion\n",
    "        layers = [conv_layer(ni, nh, 3, stride = stride), # for resnet < 34 2 convs per resblock\n",
    "                 conv_layer(nh, nf, 3, zero_bn = True, act = False)\n",
    "                 ] if expansion == 1 else [ # for RESNET > 34 then 3 convs per block with bottleneck\n",
    "                            conv_layer(ni, nh, 1),\n",
    "                            conv_layer(nh, nh, 3, stride = stride),\n",
    "                            conv_layer(nh, nf, 1, zero_bn = True, act = False)\n",
    "        ]\n",
    "        self.convs = nn.Sequential(*layers) # Creates the conv layers\n",
    "        self.idconv = noop if ni==nf else conv_layer(ni, nf, 1, act = False) # id convolution ()\n",
    "        self.pool = noop if stride== 1 else nn.AvgPool2d(2, ceil_mode = True) # average pool on \n",
    "        \n",
    "    def forward(self, x): \n",
    "        # Forward function adds the convolution part to the id part \n",
    "        #return act_fn(self.convs(x)) + self.idconv(self.pool(x))\n",
    "        return act_fn(self.convs(x) + self.idconv(self.pool(x)))\n",
    "\n",
    "# XResnet\n",
    "class XResNet(nn.Sequential):\n",
    "    @classmethod\n",
    "    def create(cls, expansion, layers, c_in=3, c_out=1000):\n",
    "        nfs = [c_in, (c_in + 1)*8, 64, 64] # number of filters in stem layer (c_in is number of image channels)\n",
    "        stem = [conv_layer(nfs[i], nfs[i+1], stride=2 if i==0 else 1)\n",
    "            for i in range(3)]\n",
    "\n",
    "        nfs = [64//expansion,64,128,256,512]\n",
    "        res_layers = [cls._make_layer(expansion, nfs[i], nfs[i+1],\n",
    "                                      n_blocks=l, stride=1 if i==0 else 2)\n",
    "                  for i,l in enumerate(layers)]\n",
    "        res = cls(\n",
    "        *stem,\n",
    "        nn.MaxPool2d(kernel_size=3, stride = 2, padding = 1), # then a max pooling layer\n",
    "        *res_layers,\n",
    "        nn.AdaptiveAvgPool2d(1), Flatten(), \n",
    "        nn.Linear(nfs[-1]*expansion, c_out)\n",
    "        )\n",
    "        init_cnn(res)\n",
    "        return res\n",
    "        \n",
    "    @staticmethod\n",
    "    def _make_layer(expansion, ni, nf, n_blocks, stride): # returns a resblock\n",
    "        return nn.Sequential(\n",
    "        *[ResBlock(expansion, ni if i==0 else nf, nf, stride if i==0 else 1)\n",
    "         for i in range(n_blocks)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def xresnet18 (**kwargs): return XResNet.create(1, [2, 2,  2, 2], **kwargs)\n",
    "def xresnet34 (**kwargs): return XResNet.create(1, [3, 4,  6, 3], **kwargs)\n",
    "def xresnet50 (**kwargs): return XResNet.create(4, [3, 4,  6, 3], **kwargs)\n",
    "model = xresnet18(c_in = 1, c_out = 2)\n",
    "#model34 = xresnet34(c_in = 1, c_out = 2)\n",
    "#model50 = xresnet50(c_in = 1, c_out = 2)\n",
    "model = model.to(device)\n",
    "\n",
    "# Label smoothing cross entropy\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "def reduce_loss(loss, reduction='mean'):\n",
    "    return loss.mean() if reduction=='mean' else loss.sum() if reduction=='sum' else loss\n",
    "\n",
    "class LabelSmoothingCrossEntropy(nn.Module):\n",
    "    def __init__(self, ε:float=0.1, reduction='mean'):\n",
    "        super().__init__()\n",
    "        self.ε,self.reduction = ε,reduction\n",
    "    \n",
    "    def forward(self, output, target):\n",
    "        c = output.size()[-1]\n",
    "        log_preds = F.log_softmax(output, dim=-1)\n",
    "        loss = reduce_loss(-log_preds.sum(dim=-1), self.reduction)\n",
    "        nll = F.nll_loss(log_preds, target, reduction=self.reduction)\n",
    "        return lin_comb(loss/c, nll, self.ε)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions that shows the image, true class, predicted class and degree of prediction\n",
    "\n",
    "def images_to_probs(net, images):\n",
    "    '''\n",
    "    Generates predictions and corresponding probabilities from a trained\n",
    "    network and a list of images\n",
    "    '''\n",
    "    output = net(images)\n",
    "    # convert output probabilities to predicted class\n",
    "    _, preds_tensor = torch.max(output, 1)\n",
    "    preds = np.squeeze(preds_tensor.numpy())\n",
    "    return preds, [F.softmax(el, dim=0)[i].item() for i, el in zip(preds, output)]\n",
    "\n",
    "\n",
    "def plot_classes_preds(net, images, labels):\n",
    "    '''\n",
    "    Generates matplotlib Figure using a trained network, along with images\n",
    "    and labels from a batch, that shows the network's top prediction along\n",
    "    with its probability, alongside the actual label, coloring this\n",
    "    information based on whether the prediction was correct or not.\n",
    "    Uses the \"images_to_probs\" function.\n",
    "    '''\n",
    "    preds, probs = images_to_probs(net, images)\n",
    "    # plot the images in the batch, along with predicted and true labels\n",
    "    fig = plt.figure(figsize=(12, 48))\n",
    "    for idx in np.arange(4):\n",
    "        ax = fig.add_subplot(1, 4, idx+1, xticks=[], yticks=[])\n",
    "        matplotlib_imshow(images[idx], one_channel=True)\n",
    "        ax.set_title(\"{0}, {1:.1f}%\\n(label: {2})\".format(\n",
    "            labels[preds[idx]],\n",
    "            probs[idx] * 100.0,\n",
    "            labels[labels[idx]]),\n",
    "                    color=(\"green\" if preds[idx]==labels[idx].item() else \"red\"))\n",
    "    return fig\n",
    "\n",
    "def matplotlib_imshow(img, one_channel=True):\n",
    "    if one_channel:\n",
    "        img = img.mean(dim=0)\n",
    "    img = img / 2 + 0.5     # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    if one_channel:\n",
    "        plt.imshow(npimg, cmap=\"Greys\")\n",
    "    else:\n",
    "        plt.imshow(np.transpose(npimg, (1, 2, 0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def confusion_matrix_calc(data_loader_test, classes, model_ft):       \n",
    "        y_pred = []\n",
    "        y_true = []\n",
    "        for inputs, labels, imNo in data_loader_test:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "                output = model_ft(inputs) # Feed Network\n",
    "\n",
    "                output = (torch.max(torch.exp(output), 1)[1]).data.cpu().numpy()\n",
    "                y_pred.extend(output) # Save Prediction\n",
    "                \n",
    "                labels = labels.data.cpu().numpy()\n",
    "                y_true.extend(labels) # Save Truth\n",
    "\n",
    "        # constant for classes\n",
    "        # classes = ('Alive', 'Dead')\n",
    "\n",
    "        # Build confusion matrix\n",
    "        cf_matrix = confusion_matrix(y_true, y_pred)\n",
    "        return cf_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "k=5 #NUMBER OF K FOLDS\n",
    "epoch=range(30) #NUMBER OF EPOCHS\n",
    "\n",
    "torch.manual_seed(10)\n",
    "imIdx = torch.randperm(1).tolist()\n",
    "\n",
    "## Create dataset\n",
    "dataSetTrain = DNADataset(imDr, get_transform(train = True), labels, imDx=imIdx)\n",
    "dataSetTest = DNADataset(imDr, get_transform(train = False), labels, imDx=imIdx)\n",
    "\n",
    "data_loader_train=[]\n",
    "data_loader_test=[]\n",
    "\n",
    "# ## Create dataloaders\n",
    "# Get subset\n",
    "torch.manual_seed(10)\n",
    "TotalSetTrain=list(range(len(dataSetTrain)))\n",
    "np.random.shuffle(TotalSetTrain)\n",
    "TotalSetTest=list(range(len(dataSetTest)))\n",
    "np.random.shuffle(TotalSetTest)\n",
    "\n",
    "train=[]\n",
    "test=[]\n",
    "for epoch in epoch:\n",
    "    \n",
    "    Kfifth = len(dataSetTrain)//k\n",
    "    split= epoch%k\n",
    "    train.append(TotalSetTrain[(split+1)*Kfifth:]+TotalSetTrain[:Kfifth*split])\n",
    "    test.append(TotalSetTest[split*Kfifth:(split+1)*Kfifth])\n",
    "\n",
    "#dataset_train = torch.utils.data.Subset(dataSetTrain, indices[-noTrain:])\n",
    "\n",
    "#dataset_test = torch.utils.data.Subset(dataSetTest, indices[:-noTrain])\n",
    "#len(indices), len(indices[:-50]), len(indices[-50:]), 50/191, type(dataset_test)\n",
    "\n",
    "dataset_sizes = {'train': len(train[0]), 'val': len(test[0])}\n",
    "\n",
    "#dataset_train = torch.utils.data.Subset(dataSetTrain, train)\n",
    "#data_loader_train.append(dataset_train)\n",
    "#dataset_testo = torch.utils.data.Subset(dataSetTest, test)\n",
    "#data_loader_test.append(dataset_testo)\n",
    "# define training and validation data loaders\n",
    "\n",
    "\n",
    "# Collate function (gathers together the outputs)\n",
    "# def collate_fn(batch):\n",
    "#     return tuple(zip(*batch))\n",
    "\n",
    "#len(indices[-noTrain:]), dataset_sizes\n",
    "#dataset_test[0][1], dataset_test[3][1], dataset_test[-1][1], dataSetTrain.imgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_weights= [0.924865,0.075135] #1-(#inclass/ #intotal )\n",
    "class_weights = torch.Tensor(class_weights)\n",
    "class_weights=class_weights.to(device)\n",
    "criterion = nn.CrossEntropyLoss(weight = class_weights) \n",
    "\n",
    "# Observe that all parameters are being optimized\n",
    "optimizer_ft = optim.SGD(model.parameters(), lr=0.1, momentum=0.9) # standard ADAM optimiser\n",
    "\n",
    "# Decay LR by a factor of 0.1 every 7 epochs\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/29\n",
      "----------\n",
      "train Loss: 0.5635 Acc: 0.7461\n",
      "val Loss: 1.2305 Acc: 0.5027\n",
      "\n",
      "Epoch 1/29\n",
      "----------\n",
      "train Loss: 0.4471 Acc: 0.8003\n",
      "val Loss: 0.7788 Acc: 0.5889\n",
      "\n",
      "Epoch 2/29\n",
      "----------\n",
      "train Loss: 0.4345 Acc: 0.8035\n",
      "val Loss: 0.4162 Acc: 0.8166\n",
      "\n",
      "Epoch 3/29\n",
      "----------\n",
      "train Loss: 0.4212 Acc: 0.8113\n",
      "val Loss: 3.0829 Acc: 0.4998\n",
      "\n",
      "Epoch 4/29\n",
      "----------\n",
      "train Loss: 0.4053 Acc: 0.8222\n",
      "val Loss: 0.4311 Acc: 0.7966\n",
      "\n",
      "Epoch 5/29\n",
      "----------\n",
      "train Loss: 0.3985 Acc: 0.8243\n",
      "val Loss: 0.3910 Acc: 0.8268\n",
      "\n",
      "Epoch 6/29\n",
      "----------\n",
      "train Loss: 0.3872 Acc: 0.8315\n",
      "val Loss: 0.5763 Acc: 0.7447\n",
      "\n",
      "Epoch 7/29\n",
      "----------\n",
      "train Loss: 0.3588 Acc: 0.8435\n",
      "val Loss: 0.7645 Acc: 0.6860\n",
      "\n",
      "Epoch 8/29\n",
      "----------\n",
      "train Loss: 0.3536 Acc: 0.8495\n",
      "val Loss: 0.4049 Acc: 0.8169\n",
      "\n",
      "Epoch 9/29\n",
      "----------\n",
      "train Loss: 0.3444 Acc: 0.8500\n",
      "val Loss: 0.4604 Acc: 0.7871\n",
      "\n",
      "Epoch 10/29\n",
      "----------\n",
      "train Loss: 0.3448 Acc: 0.8514\n",
      "val Loss: 0.3600 Acc: 0.8450\n",
      "\n",
      "Epoch 11/29\n",
      "----------\n",
      "train Loss: 0.3409 Acc: 0.8534\n",
      "val Loss: 0.3724 Acc: 0.8410\n",
      "\n",
      "Epoch 12/29\n",
      "----------\n",
      "train Loss: 0.3376 Acc: 0.8559\n",
      "val Loss: 0.3608 Acc: 0.8460\n",
      "\n",
      "Epoch 13/29\n",
      "----------\n",
      "train Loss: 0.3356 Acc: 0.8556\n",
      "val Loss: 0.3670 Acc: 0.8434\n",
      "\n",
      "Epoch 14/29\n",
      "----------\n",
      "train Loss: 0.3161 Acc: 0.8661\n",
      "val Loss: 0.4020 Acc: 0.8235\n",
      "\n",
      "Epoch 15/29\n",
      "----------\n",
      "train Loss: 0.3172 Acc: 0.8664\n",
      "val Loss: 0.3837 Acc: 0.8381\n",
      "\n",
      "Epoch 16/29\n",
      "----------\n",
      "train Loss: 0.3142 Acc: 0.8654\n",
      "val Loss: 0.3700 Acc: 0.8441\n",
      "\n",
      "Epoch 17/29\n",
      "----------\n",
      "train Loss: 0.3142 Acc: 0.8677\n",
      "val Loss: 1.8077 Acc: 0.5277\n",
      "\n",
      "Epoch 18/29\n",
      "----------\n",
      "train Loss: 0.3150 Acc: 0.8659\n",
      "val Loss: 0.3796 Acc: 0.8368\n",
      "\n",
      "Epoch 19/29\n",
      "----------\n",
      "train Loss: 0.3079 Acc: 0.8690\n",
      "val Loss: 0.3661 Acc: 0.8443\n",
      "\n",
      "Epoch 20/29\n",
      "----------\n",
      "train Loss: 0.3098 Acc: 0.8696\n",
      "val Loss: 0.5173 Acc: 0.7755\n",
      "\n",
      "Epoch 21/29\n",
      "----------\n",
      "train Loss: 0.3061 Acc: 0.8711\n",
      "val Loss: 0.4087 Acc: 0.8261\n",
      "\n",
      "Epoch 22/29\n",
      "----------\n",
      "train Loss: 0.3088 Acc: 0.8702\n",
      "val Loss: 2.0760 Acc: 0.5214\n",
      "\n",
      "Epoch 23/29\n",
      "----------\n",
      "train Loss: 0.3087 Acc: 0.8682\n",
      "val Loss: 0.4248 Acc: 0.8181\n",
      "\n",
      "Epoch 24/29\n",
      "----------\n",
      "train Loss: 0.3017 Acc: 0.8721\n",
      "val Loss: 0.3627 Acc: 0.8466\n",
      "\n",
      "Epoch 25/29\n",
      "----------\n",
      "train Loss: 0.3072 Acc: 0.8701\n",
      "val Loss: 0.7172 Acc: 0.6993\n",
      "\n",
      "Epoch 26/29\n",
      "----------\n",
      "train Loss: 0.3039 Acc: 0.8717\n",
      "val Loss: 2.6932 Acc: 0.5122\n",
      "\n",
      "Epoch 27/29\n",
      "----------\n",
      "train Loss: 0.3061 Acc: 0.8710\n",
      "val Loss: 0.3835 Acc: 0.8372\n",
      "\n",
      "Epoch 28/29\n",
      "----------\n",
      "train Loss: 0.3067 Acc: 0.8691\n",
      "val Loss: 0.3839 Acc: 0.8372\n",
      "\n",
      "Epoch 29/29\n",
      "----------\n",
      "train Loss: 0.3014 Acc: 0.8725\n",
      "val Loss: 0.3793 Acc: 0.8364\n",
      "\n",
      "Training complete in 86m 8s\n",
      "Best val Acc: 0.846565\n"
     ]
    }
   ],
   "source": [
    "model_ft, con_mat = train_model(model, criterion, optimizer_ft, exp_lr_scheduler, \n",
    "                                    train,test,num_epochs=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cf_matrix = confusion_matrix_calc(data_loader_test, labels, model_ft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x504 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "con_mat=con_mat.cpu().numpy()\n",
    "df_cm_ratio = pd.DataFrame(con_mat / np.sum(con_mat, axis=1)[:, None], index=[i for i in labels],\n",
    "                     columns=[i for i in labels])\n",
    "plt.figure(figsize=(12, 7))\n",
    "sn.heatmap(df_cm_ratio, annot=True)\n",
    "# plt.save(\"Confusion_matrix_ratio.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x504 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_cm_raw = pd.DataFrame(con_mat, index=[i for i in labels],\n",
    "                     columns=[i for i in labels])\n",
    "plt.figure(figsize=(12, 7))\n",
    "sn.heatmap(df_cm_raw, annot=True)\n",
    "# plt.save(\"Confusion_matrix_raw.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[20321,  3995],\n",
       "       [  288,  1732]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "con_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_loader_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
